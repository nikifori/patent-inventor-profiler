{"lens_id":"144-040-440-921-275","jurisdiction":"US","doc_number":"12367240","kind":"B1","date_published":"2025-07-22","doc_key":"US_12367240_B1_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12367240","kind":"B1","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"17852945","date":"2022-06-29"},"priority_claims":{},"invention_title":[{"text":"Systems and methods for multimodal indexing of video using machine learning","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"2699","extracted_name":{"value":"Mekonen T Bekele"}}},"applicants":[{"residence":"US","extracted_name":{"value":"Amazon Technologies, Inc."},"extracted_address":"Seattle, WA"}],"inventors":[{"residence":"US","sequence":1,"extracted_name":{"value":"Wentao Zhu"},"extracted_address":"Redmond, WA"},{"residence":"US","sequence":2,"extracted_name":{"value":"Mohamed Kamal Omar"},"extracted_address":"Seattle, WA"},{"residence":"US","sequence":3,"extracted_name":{"value":"Han-Kai Hsu"},"extracted_address":"Seattle, WA"},{"residence":"US","sequence":4,"extracted_name":{"value":"Xiaohang Sun"},"extracted_address":"Bellevue, WA"},{"residence":"US","sequence":5,"extracted_name":{"value":"Ashutosh Sanan"},"extracted_address":"Seattle, WA"}],"agents":[{"extracted_name":{"value":"Eversheds Sutherland (US) LLP"}}]},"classifications_ipcr":{"classifications":[{"symbol":"G06F16/75","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G06F16/71","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06F16/783","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06N3/08","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"G06F16/75","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G06F16/71","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06F16/7834","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06N3/08","classification_value":"I","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"nplcit":{"text":"Arsha Nasrani et al., “Attention Bottlenecks for Multimodal Fusion”, pub. 2021 (Year: 2021)."}}],"npl_count":1},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367240","kind":"B1","date":"2025-07-22"},"lens_id":"144-040-440-921-275"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367240","kind":"B1","date":"2025-07-22"},"lens_id":"144-040-440-921-275"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"Systems, methods, and computer-readable media are disclosed for systems and methods multimodal indexing of video using machine learning. An example method may include deceiving, by a video encoder of an audio-video transformer neural network comprising one or more computer processors coupled to memory, a first frame and a second frame associated with a first segment of a video. The example method may also include receiving, by an audio encoder of the audio-video transformer neural network, an audio spectrogram comprising first audio data associated with the first segment of the video. generating, by the video encoder, a first video embedding. The example method may also include generating, by the audio encoder, a first audio embedding. The example method may also include determining a fusion of the first video embedding and the first audio embedding using a multimodal bottleneck token. The example method may also include determining an output including the first video embedding and the first audio embedding. The example method may also include determining a classification of the first portion of the video based on the output.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A method comprising: receiving, by a video encoder of an audio-video transformer neural network comprising one or more computer processors coupled to memory, a first frame and a second frame associated with a first segment of a video; receiving, by an audio encoder of the audio-video transformer neural network, an audio spectrogram comprising first audio data associated with the first segment of the video; generating, by the video encoder, a first video embedding, the first video embedding including a first video token and a second video token, the first video token including a first portion of pixels included in the first frame, and the second video token including a first classification token; generating, by the audio encoder, a first audio embedding, the first audio embedding including a first audio token and a second audio token, the first audio token including a first portion of the first audio data included in the audio spectrogram, and the second audio token including a second classification token; receiving, by a first loss function, the first video embedding; receiving, by a second loss function, the first video embedding and the first audio embedding; generating, by a multimodal bottleneck transformer of the audio-video transformer, a multimodal bottleneck token used for cross-modality fusion of the first video embedding and the first audio embedding; combining the multimodal bottleneck token with the first video embedding and the first audio embedding to perform multimodal fusion of the first video embedding and the first audio embedding; determining an output including the first video embedding and the first audio embedding; receiving, by a third loss function and a fourth loss function, the output; and determining a classification of the first portion of the video based on the output."]},{"claim_text":["2. The method of claim 1 , further comprising: training the audio-video transformer neural network based on one or more outputs of the first loss function, the second loss function, the third loss function, and the fourth loss function, wherein the first loss function determines an alignment of the first frame, second frame, and first audio data, wherein the second loss function determines an accuracy of the classification of the first portion of the video based on the first classification token, wherein the third loss function determines an accuracy of the classification of the first portion of the video based on the first classification token and the second classification token, and wherein the fourth loss function determines a difference between the first classification token and the second classification token."]},{"claim_text":["3. The method of claim 1 , further comprising: training the audio-video transformer neural network by masking a first portion of the first audio data, wherein masking the first portion of the audio spectrogram comprises: determining second audio data, the second audio data comprising a smoothed version of the first audio data to remove noise from the first audio data; determining third audio data, the third audio data comprising a gradient of the second audio data; determining fourth audio data, the fourth audio data comprising an absolute value of the third audio data; determining fifth audio data, the fifth audio data comprising an average of the fourth audio data; and determining a segment transition based on the fifth audio data."]},{"claim_text":["4. The method of claim 1 , further comprising: performing, based on the classification of the first portion of the video, an action comprising at least one of: video indexing, video search, video retrieval, action localization, action clustering, or video clustering."]},{"claim_text":["5. A method comprising: receiving, by a video encoder of an audio-video transformer neural network comprising one or more computer processors coupled to memory, a first frame and a second frame associated with a first segment of a video; receiving, by an audio encoder of the audio-video transformer neural network, an audio spectrogram comprising first audio data associated with the first segment of the video; generating, by the video encoder, a first video embedding; generating, by the audio encoder, a first audio embedding; determining a fusion of the first video embedding and the first audio embedding using a multimodal bottleneck token; determining an output including the first video embedding and the first audio embedding; determining a classification of the first segment of the video based on the output; receiving, by a plurality of loss functions, the first video embedding; receiving, by the plurality of loss functions, the first video embedding and the first audio embedding; receiving, by the plurality of loss functions, the output; and training the audio-video transformer neural network based on one or more outputs of the one or more loss functions."]},{"claim_text":["6. The method of claim 5 , wherein the plurality of loss functions comprise a first loss function, second loss function, third loss function, and fourth loss function."]},{"claim_text":["7. The method of claim 6 , further comprising: determining, using the first loss function, an alignment of the first frame, second frame, and first audio data."]},{"claim_text":["8. The method of claim 6 , further comprising: comparing, using the second loss function and based on a first classification token, a first classification probability and a known classification associated with the first segment of the video."]},{"claim_text":["9. The method of claim 6 , further comprising: comparing, using the third loss function, a first classification probability based on a first classification token and a second classification probability based on a second classification token."]},{"claim_text":["10. The method of claim 6 , further comprising: determining, using the fourth loss function, a difference between a first classification token and a second classification token."]},{"claim_text":["11. The method of claim 5 , further comprising training the audio-video transformer neural network by masking a first portion of the first audio data, wherein masking the first portion of the audio spectrogram comprises: determining second audio data, the second audio data comprising a smoothed version of the first audio data to remove noise from the first audio data; determining third audio data, the third audio data comprising a gradient of the second audio data; determining fourth audio data, the fourth audio data comprising an absolute value of the third audio data; determining fifth audio data, the fifth audio data comprising an average of the fourth audio data; and determining a segment transition based on the fifth audio data."]},{"claim_text":["12. The method of claim 5 , further comprising: performing, based on the classification of the first segment of the video, an action comprising at least one of: video indexing, video search, video retrieval, action localization, action clustering, or video clustering."]},{"claim_text":["13. A system comprising: at least one memory that stores computer-executable instructions; and at least one processor configured to access the memory and execute the computer-executable instructions to: receive, by a video encoder of an audio-video transformer neural network comprising one or more computer processors coupled to memory, a first frame and a second frame associated with a first segment of a video; receive, by an audio encoder of the audio-video transformer neural network, an audio spectrogram comprising first audio data associated with the first segment of the video; generate a mask of a first portion of the first audio data, wherein the mask is non-random and includes a portion of the first portion of the first audio data indicative of a change in audio activity; train the audio-video transformer neural network using the mask; generate, by the video encoder, a first video embedding, the first video embedding including a first video token and a second video token, the first video token including a first portion of pixels included in the first frame, and the second video token including a first classification token; generate, by the audio encoder, a first audio embedding, the first audio embedding including a first audio token and a second audio token, the first audio token including the first portion of the first audio data included in the audio spectrogram, and the second audio token including a second classification token; combine a multimodal bottleneck token associated with a second transformer with the first video embedding and the first audio embedding; determine an output including the first video embedding and the first audio embedding; and determine a classification of the first portion of the video based on the output."]},{"claim_text":["14. The system of claim 13 , wherein the at least one processor is further configured to access the memory and execute the computer-executable instructions to: receive, by a first loss function, the first video embedding; receive, by a second loss function, the first video embedding and the first audio embedding; receive, by a third loss function and a fourth loss function, the output; and train the audio-video transformer neural network based on one or more outputs of the first loss function, the second loss function, the third loss function, and the fourth loss function."]},{"claim_text":["15. The system of claim 14 , wherein the at least one processor is further configured to access the memory and execute the computer-executable instructions to: determine, using the first loss function, an alignment of the first frame, second frame, and first audio data."]},{"claim_text":["16. The system of claim 14 , wherein the at least one processor is further configured to access the memory and execute the computer-executable instructions to: compare, using the second loss function and based on a first classification token, a first classification probability and a known classification associated with the first segment of the video."]},{"claim_text":["17. The system of claim 14 , wherein the at least one processor is further configured to access the memory and execute the computer-executable instructions to: compare, using the third loss function, a first classification probability based on a first classification token and a second classification probability based on a second classification token."]},{"claim_text":["18. The system of claim 14 , wherein the at least one processor is further configured to access the memory and execute the computer-executable instructions to: determine, using the fourth loss function, a difference between the first classification token and the second classification token."]},{"claim_text":["19. The system of claim 13 , wherein masking the first portion of the audio spectrogram comprises: determine second audio data, the second audio data comprising a smoothed version of the first audio data to remove noise from the first audio data; determine third audio data, the third audio data comprising a gradient of the second audio data; determine fourth audio data, the fourth audio data comprising an absolute value of the third audio data; determine fifth audio data, the fifth audio data comprising an average of the fourth audio data; and determine a segment transition based on the fifth audio data."]},{"claim_text":["20. The system of claim 13 , wherein the at least one processor is further configured to access the memory and execute the computer-executable instructions to: perform, based on the classification of the first portion of the video, an action comprising at least one of: video indexing, video search, video retrieval, action localization, action clustering, or video clustering."]}],"lang":"en"}],"description":{"text":"BACKGROUND Computer-based video understanding is beneficial for a variety of use cases, such as cashier-less stores, autonomous robot functionality, video advertisements, verifying compliance of videos with video-hosting platform terms, and providing users with information about the contents of videos, among many other uses cases. One important task associated with computer-based video understanding is action recognition, which involves computer-based identification of certain types of actions within video clips. For example, action recognition may involve identifying if a user within a video clip is drinking, driving a vehicle, etc. Deep learning-based action recognition methods have been widely explored since the great success of AlexNet on image classification. Conventional deep learning-based action recognition may be mainly divided into two aspects: (1) methods involving the use of deep ConvNets and (2) methods involving the use of deep sequential learning. Deep ConvNets methods primarily involve integrated various factorization techniques or a priori for efficient video understanding. Some works focus on extracting effective spatio-temporal features or capturing complicated long-range dependencies. Deep sequential learning methods attempt to formulate spatial and temporal relationships through advanced deep sequential models or attention mechanisms. Some attempts at action recognition in videos have been made using transformers. A transformer is a type of neural network that is often used for processing sequential data, such as natural language text. A transformer learns context and meaning by tracking relationships in the sequential data. The transformer is beneficial over traditional neural networks because input sequences can be processed in parallel using multiple graphics processing units (GPUs), which increases the training and processing speed of the model. However, simply applying a transformer to the three-dimensional (3D) video domain is computationally intensive. Consequentially, most of the efforts focus on designing efficient transformer models to reduce computation and memory consumption. Video vision transformers (ViViT) and TimeS study various factorization methods along spatial and temporal dimensions. Multiscale vision transformers (MViT) conduct a trade-off between resolution and the number of channels and construct a multi-scale transformer to learn a hierarchy from simple dense resolution and fine-grained features to complex coarse features. Multiview transformers further employ multiple branches to efficiently learn from various granularities of video views. Video-audio-text transformers (VATT) conduct unsupervised multi-modality self-supervised learning with a pure-transformer structure. Multimodal bottleneck transformers (MBT) construct multimodal bottleneck tokens to learn multimodal features alternatively from an image transformer and an audio transformer. BRIEF DESCRIPTION OF THE DRAWINGS The detailed description is set forth with reference to the accompanying drawings. The drawings are provided for purposes of illustration only and merely depict example embodiments of the disclosure. The drawings are provided to facilitate understanding of the disclosure and shall not be deemed to limit the breadth, scope, or applicability of the disclosure. In the drawings, the left-most digit(s) of a reference numeral may identify the drawing in which the reference numeral first appears. The use of the same reference numerals indicates similar, but not necessarily the same or identical components. However, different reference numerals may be used to identify similar components as well. Various embodiments may utilize elements or components other than those illustrated in the drawings, and some elements and/or components may not be present in various embodiments. The use of singular terminology to describe a component or element may, depending on the context, encompass a plural number of such components or elements and vice versa. FIG. 1 is a schematic illustration of an example use case for multimodal indexing of video using machine learning in accordance with one or more example embodiments of the disclosure. FIG. 2 is a schematic illustration of an example process flow for multimodal indexing of video using machine learning in accordance with one or more example embodiments of the disclosure. FIGS. 3A-3B are schematic illustrations of an example process flow for multimodal indexing of video using machine learning in accordance with one or more example embodiments of the disclosure. FIGS. 4A-4F schematically illustrate an example audio spectrogram masking process flow in accordance with one or more example embodiments of the disclosure. FIG. 5 is a schematic block diagram of an illustrative device in accordance with one or more example embodiments of the disclosure. DETAILED DESCRIPTION Overview This disclosure relates to, among other things, devices, systems, methods, computer-readable media, techniques, and methodologies for multimodal indexing of video using machine learning. In certain example embodiments described herein, the multimodal indexing of video may be applied to a multimedia platform. A multimedia platform may be a system that may host different types of multimedia content, such as movies and television shows, music, and/or any other types of content. The multimedia platform may allow users to access and view this content, oftentimes from user devices such as smartphones, desktop and laptop computers, smart televisions, and/or any other type of device. However, the multimodal indexing of video may also be applied in any other context as well, and the example of a multimedia platform is not intended to be limiting. Videos (for example, television shows and movies, among other types of video content) may be one of the core assets on a multimedia platform. Therefore, it is important for the platform to understand the content of any video in order to inform any users of such content. This may allow the users to make informed decisions about what specific videos they desire to view without having to play the video to preview the content. This may also allow for the removal of any content that violates quality standards and/or any other standards associated with the platform. Such information may also be used for any other number of purposes as well, such as categorizing videos, providing more effective video searching functionality to users, etc. To this end, the multimodal video indexing system may employ a machine learning model (although reference is made to a machine learning model, any other type of model may also be applicable) that is trained to more effectively classify videos or segments of videos based on their contents. Particularly, the machine learning model includes a multimodal transformer that may receive multiple different types of data as inputs to more effectively perform computer-based video understanding (rather than simply relying on the data associated with the video frames themselves. In one or more embodiments, the multimodal transformer may be in the form of an audio-video transformer (AVT), which may be a type of neural network. This is in contrast to other types of existing transformers, which may use image and audio data. These existing transformers may not be as effective as the AVT because, among other reasons described herein, such prior transformer models rely on image transformers and may not be able to capture the fundamental temporal data that may be otherwise gleaned from video. The AVT may receive video frames corresponding to a segment of a video (or a full video) and an audio spectrogram associated with audio corresponding to the segment of the video. Using these inputs, the AVT may be trained to perform action recognition (or any other task associated with computer-based video understanding). The AVT may also leverage a multimodal bottleneck transformer, which may be used for the fusion of the video and audio data for more effective video understanding. Although reference is made herein to an AVT involving the use of video and audio as inputs, any other combinations of different types of data may also be used as well (for example, any combination of audio, video, image, text, etc.). In this manner, the AVT may also be generally referred to as a “multimodal transformer.” Additional details about the structure of the multimodal transformer may be provided at least with respect to FIGS. 3A-3B , which are described below. The multimodal transformer may also employ a unique hybrid loss objective that may involve a combination of one or more different types of loss functions. These loss functions may be used to train the model to more effectively process any data that is received. In one or more embodiments, four loss functions may be employed, which may include at least a modality alignment loss function, a video classification loss function, an audio-video match cross-entropy loss function (if audio and video are used as the multiple modalities), and a multimodal classification loss function. However, any other number of loss functions may also be employed as well. These loss functions are also described in additional detail with respect to at least FIGS. 3A-3B . Additionally, to fully explore the structural information in the audio spectrogram, a unique masked audio model may be employed. Masking may refer to removing or otherwise hiding certain portions of audio data such that they may not be ascertainable. The model may then be provided with the audio data including the masked portions and may be tasked with determining the original audio data that was included in the masked areas. This may allow the model to be trained based on any distinctions between the determined model output and the known audio data that was included in the masked portions. Traditional audio masking may involve masking random portions of audio data. In contrast with these traditional methods that involve simple, random masking, the systems described herein involve a more focused masking method that, at a high level, selects portions of the audio spectrogram to mask that include actual audio data (for example, a person speaking, a vehicle driving, background noise, etc.). This prevents the scenario that may arise in traditional audio masking where a portion of the audio data that does not include is masked. Additional details about this audio masking method are provided with respect to FIGS. 4B-4F . The output of the AVT may be one or more classifications associated with the segment of video that was provided as an input to the AVT. In some cases, classifications may be provided on a more granular level, such as on a frame-by-frame level as well (for example, each frame may be associated with one or more classifications). Each of the modalities that were provided as inputs (for example, video data, audio data, and/or any other types of data) may have their own associated classification outputs, which may be provided in the form of classification tokens. The combination of these classification outputs provided for the different modalities may be used to determine the overall classification for the video segment (or whole video). Once the output of the AVT is obtained, the output may be used for any number of different purposes. For example, the video classification may allow for more effective video indexing, video searching, video retrieval, action localization, action clustering, video clustering, and/or any other purpose. For example, a frame within a video may be classified as depicting a race car. Based on this classification, a search function of the multimedia platform may be improved such that the multimedia platform may be able to make more effective video recommendations when a user inputs a search for “car,” or similar subject matter. This is merely one example, and the classification may be used for any other number of purposes. Referring to FIG. 1 , an example use case 100 for multimodal indexing of video using machine learning is depicted in accordance with one or more example embodiments of the disclosure. For example, the use case may illustrate one or more multimodal indexing machine learning model(s) 120 may be stored at a remote server and may be executed to perform video classification and/or any other types of functions described herein. In one or more embodiments, the machine learning model(s) 120 may include a multimodal transformer, such as the AVT described herein. The multimodal indexing machine learning model(s) 120 may receive as inputs any combination of different data modalities associated with any content included within the multimedia platform. The inputs may include any number of different types of combinations of a video input 110 , an audio input 112 , and/or a text input 114 (and/or any other types of data). For example, the video input 110 may include a segment of a video included within the multimedia platform (the frames that a user may see while viewing the segment of the video). The audio input 112 may include any audio associated with the particular video segment (the audio that the user may hear while viewing the segment of the video). The text input 114 may include any text associated with the same video segment (any text that may be displayed to the user while viewing the segment of the video, such as captions, for example). The inputs may also include any other type of modality as well. Additionally, while reference is made to a “segment” of video, this may also refer to the video in its entirety as well. The output of the multimodal indexing machine learning model(s) 120 may be one or more classifications associated with the segment of video that was provided as an input to the multimodal transformer. These outputs may then be used to present information to a user. For example, the information may be presented through a user interface 130 . The user interface 130 may be associated with a device that a user is using to access the multimedia platform that is hosting the video content. The outputs may also be used to allow the user to more effectively interact with the multimedia platform (for example, search the platform for specific types of videos, etc.). Other embodiments may have additional, fewer, or different types of outputs and/or information presented. As one non-limiting example, the user interface 130 depicted in the figure shows a search function being performed by a user, where the videos that are recommended through the search function may be based in part on the classifications output by the multimodal indexing machine learning model(s) 120 . To perform multimodal indexing based on the multimodal indexing machine learning model(s) 120 , an example process flow 140 is presented and may be performed, for example, by one or more remote servers. The remote server and/or computer system may include at least one memory that stores computer-executable instructions and at least one processor configured to access the at least one memory and execute the computer-executable instructions to perform various actions or operations, such as one or more of the operations in the process flow 140 of FIG. 1 . The process flow 140 is merely intended to provide a high-level example of the use of the multimodal indexing machine learning model(s) 120 and is not intended to be limiting in any way. At a first block 150 , video data and audio data associated with a video segment may be received. For example, if a television series about race cars is being analyzed by the multimodal indexing machine learning model(s) 120 , then the inputs may include frames associated with a video segment relating to a five second clip of a car driving around a corner on a track. The inputs may also include an audio spectrogram including audio data relating to that same five second segment. However, the relative amount of the overall video that is provided as an input to be classified at any given time may vary. For example, segments of one second, one minute, ten minutes, and/or the entire video may also be provided as inputs. Additionally, while one five second segment is provided for analysis at one time, additional segments comprising the overall video may also be analyzed sequentially or in parallel with the first segment as well. Analyzing certain segments of the entire video may allow for more granular data about the contents of the video to be determined in a more effective manner. For example, it may be determined that one segment includes a race car, and a second segment includes a driver speaking to a camera. At a second block 160 , information may be extracted from the video data and the audio data. For example, at a high level, the AVT may break down the frames of the video input 110 into smaller portions referred to as tokens. Each video token may include a “patch” of pixels from the frame. The AVT may similarly break down any other types of input modalities into smaller components for more effective processing of the data as well. Additional details about the specific operations performed with respect to this information extraction, as well as any other operations described with respect to process flow 140 , may be described in association with at least FIGS. 2 and 3A-3B . At a third block 170 , fusion modality may be performed using the video and audio data. Fusion modality may allow the multimodal indexing machine learning model(s) 120 to consider information included in the video data 110 , audio data 112 , and/or text data 114 (as well as any other types of data) in combination, rather than simply analyzing all of these different modalities separately. This may allow the multimodal indexing machine learning model(s) 120 to perform more effective classification because all the information associated with these different modalities may be considered in conjunction at an early stage in the process. At a fourth block 180 , one or more classifications for the video segment may be determined. For example, the multimodal indexing machine learning models(s) 120 may produce a classification indicating that the video segment relates to “cars,” or “racing,” or “drama,” and/or any other number of different types of classifications and/or combinations of classifications. Generally, a classification may simply refer to information that may be associated with a video segment that may provide context into the contents of the video segment. For example, classifications may also include actions, such as “spirited driving” or “arguing.” In some cases, the classifications may be selected from a list of pre-determined types of classifications. These classifications may be automatically generated by the indexing machine learning models(s) 120 , accessed from a listing stored in a database, manually provided by a user, and/or may be determined in any other suitable manner. However, the classifications do not necessarily need to be pre-determined and may also be uniquely generated by the multimodal indexing machine learning model(s) as well. At a fifth block 190 , a search function may be performed using the classification output from the multimodal indexing machine learning model(s) 120 . For example, a user who desires to view a television series about cars may open a search bar of the multimedia platform and enter a text string “cars.” Based on the classification of the video segment made by the multimodal indexing machine learning model(s) 120 , the system may have information that the television series includes car races. Given this, the platform may then recommend the television series to the user for viewing. This is just one example of a use case in which the classification may be applied to improve the function of the multimedia platform. For example, the platform may also automatically generate listings of content for the user to scroll through that may be categorized based on genre or any other type of categorization. For example, the race television series may be presented in a category entitled “racing” that may include other similar types of content. At a sixth block 195 , the multimodal indexing machine learning model(s) 120 may be trained based on a number of different types of loss functions. In one or more embodiments, the loss functions may include modality alignment loss function, a video classification loss function, an audio-video match cross entropy loss function (if audio and video are used as the multiple modalities), and a multimodal classification loss function. These loss functions may be employed at various stages throughout the process. For example, the alignment loss function may determine if the video data and the audio data being provided to the multimodal transformer are from the same video segment. The video classification loss function may determine the accuracy of the video classification itself, whereas the multimodal classification loss function may determine if the video and audio classifications being produced are similar or different. The cross entropy loss function may be used to determine the accuracy of the overall classification based on the video classification and the audio classification. All of these loss functions may be employed to train the multimodal indexing machine learning model(s) 120 to more effectively process input data in future iterations. One or more illustrative embodiments of the disclosure have been described above. The above-described embodiments are merely illustrative of the scope of this disclosure and are not intended to be limiting in any way. Accordingly, variations, modifications, and equivalents of embodiments disclosed herein are also within the scope of this disclosure. The above-described embodiments and additional and/or alternative embodiments of the disclosure will be described in detail hereinafter through reference to the accompanying drawings. Illustrative Process and Use Cases FIG. 2 depicts an example process flow 200 for multimodal indexing of video using machine learning in accordance with one or more example embodiments of the disclosure. The process flow 200 may provide a more detailed illustration of the processes associated with the AVT than the process flow 140 of FIG. 1 . While example embodiments of the disclosure may be described in the context of movies or other video content, it should be appreciated that the disclosure is more broadly applicable to any type of digital content. Some or all the blocks of the process flows in this disclosure may be performed in a distributed manner across any number of devices. The operations of the process flow 200 may be optional and may be performed in a different order. At block 210 of the process flow 200 , computer-executable instructions stored on a memory of a device, such as a remote server or a user device, may be executed to receive, by a video encoder of an audio-video transformer neural network comprising one or more computer processors coupled to memory, a first frame and a second frame associated with a first segment of a video. That is, the video encoder may be configured to receive video data that is used by the audio-video transformer to perform classification of a given segment of a video (or an entire video). For example, the video encoder may receive a series of frames corresponding with a scene of a race television series depicting race cars driving a lap around a course. At block 220 of the process flow 200 , computer-executable instructions stored on a memory of a device, such as a remote server or a user device, may be executed to receive, by an audio encoder of the audio-video transformer neural network, an audio spectrogram comprising first audio data associated with the first segment of the video. That is, the audio encoder may be configured to receive audio data that is used by the audio-video transformer to perform classification of the same segment of the video (or an entire video). For example, the audio encoder may receive an audio spectrogram including audio data corresponding with the same scene of the race television series depicting race cars driving the lap around the course. For example, the audio data may include the sounds of the car engines, the cheering of the crowd, the shouting of the pit crews, etc. It should be noted that while the process flow 200 describes a combination of video and audio data as being used to perform the classification of the video segment, any other combination of different types of data may also be used as well. At block 230 of the process flow 200 , computer-executable instructions stored on a memory of a device, such as a remote server or a user device, may be executed to generate, by the video encoder, a first video embedding. The first video embedding may include a first video token and a second video token. The first video token may be a first portion of pixels included in the first frame, and the second video token may include a first classification token. The video encoder may also generate any other number of tokens as well. For example, if a given frame of the video segment includes 200×200 pixels, the video encoder may generate 20 tokens including 10×10 of the pixels. The video encoder may generate tokens in this manner for any of the frames comprising the video segment. This may allow the larger frames to be separated into smaller portions of data for more efficient processing. The classification token may be an additional token that is generated that is associated with the other tokens including the pixels associated with the frames of the video segment. For example, the CLS token may provide a label associated with a given set of frames comprising a portion of the video, such as “driving car,” “drinking alcohol,” “arguing,” etc. At block 240 of the process flow 200 , computer-executable instructions stored on a memory of a device, such as a remote server or a user device, may be executed to generate, by the audio encoder, a first audio embedding. Similar to the first video embedding, the first audio embedding may include a first audio token and a second audio token. The first audio token may be a first portion of the audio data included in the audio spectrogram, and the second audio token may include a first classification token. The audio encoder may also generate any other number of tokens as well (similar to the video encoder). It should be noted that while reference is made to a “first video embedding” and “first audio embedding,” any number of embeddings may be generated. At block 250 of the process flow 200 , computer-executable instructions stored on a memory of a device, such as a remote server or a user device, may be executed to determine a fusion of the first video embedding and the first audio embedding using a multimodal bottleneck token (or multiple multimodal bottleneck tokens). These multimodal bottleneck tokens may be combined with the video tokens through a conventional transformer. In this way, the tokens learn the information from video features, which may share with audio tokens in the next layer. The tokens may also combine with audio tokens, share information with audio tokens, and learn audio-video features through another layer of the transformer. The multiple modality fusion can be stacked any number of additional times as well. At block 260 of the process flow 200 , computer-executable instructions stored on a memory of a device, such as a remote server or a user device, may be executed to determining an output including the first video embedding and the first audio embedding. The output of the AVT may be one or more classifications associated with the segment of video that was provided as an input to the AVT. In some cases, classifications may be provided on a more granular level, such as on a frame-by-frame level as well (for example, each frame may be associated with one or more classifications). Each of the modalities that were provided as inputs (for example, video data, audio data, and/or any other types of data) may have their own associated classification outputs, which may be provided in the form of classification tokens. The combination of these classification outputs provided for the different modalities may be used to determine the overall classification for the video segment (or whole video). At block 270 of the process flow 200 , computer-executable instructions stored on a memory of a device, such as a remote server or a user device, may be executed to determine a classification of the first portion of the video based on the output. The classification may be used for any number of different purposes. For example, the classification may be used for video indexing, video search, video retrieval, action localization, action clustering, video clustering, and/or any other purpose. These uses of the classification may allow a user to have a more beneficial multimedia platform experience. For example, the may allow the users to make informed decisions about what specific videos they desire to view without having to play the video to preview the content. This may also allow a user to more easily find videos including particular types of content to watch. For example, the classification may allow for a user to more effectively search the multimedia platform for movies and TV shows including racing. This may also allow for the removal of any content that violates quality standards and/or any other standards associated with the platform. This may also provide any other number of benefits to the user as well. FIGS. 3A-3B depict an example process flow 300 for multimodal indexing of video using machine learning in accordance with one or more example embodiments of the disclosure. The process flow 300 may generally illustrate an example AVT that may be used for computer-based video understanding as described herein. Beginning with FIG. 3A , the process flow 300 may generally involve one or more modality encoders, a multimodal bottleneck transformer 318 , and/or one or more loss functions (for example, alignment contrastive loss L AL for modality encoder, audio-video matching loss L AVM M after multimodal fusion, masked audio-video loss L MAV , and video classification loss L CLS V as and multimodal classification loss L CLS AV ) used to train the AVT. The process flow 300 may begin with different types of data being received. The data may be any type of data of any modality. FIG. 3A depicts one specific example in which a combination of video data 302 and audio data 304 are used. The video data 302 may represent a segment of a video (or all of the video) for which action recognition (and/or any other video understanding task) is desired to be performed. The audio data 304 may be audio associated with that particular video segment. The video data 302 may be in the form of a sequence of frames, V i . The audio data 304 may be in form of an audio spectrogram, A i . Although the process flow 300 specifically depicts a combination of video data 302 and audio data 304 being received, this is merely for exemplification purposes, and any other combination of different types of data may also be received as well. For example, video data, audio data, and text data may be received, video data and text data may be received, audio data and text data may be received, and/or any other combination of different types of data, including data other than video, audio, and/or text data as well. That is, as aforementioned, any reference to aspects of an AVT may also be generally applicable to a multimodal transformer involving data combinations other than video and audio. The data may be received by one or more different types of encoders that correspond with the types of data. An encoder may generally refer to a portion of a transformer architecture that may be used to extract features from the data that is received. In this manner, the data may be broken down into feature components that may allow the data to be processed by the transformer. The specific types of encoders that are employed may depend on the types of data being received. For example, at a high level, a video encoder (such as video encoder 306 ) may break down a frame of a series of frames included in video data 302 into video embeddings. The video embeddings may include one or more different types of tokens, for example. Each video token may include a “patch” of pixels from the frame. For example, if a frame comprises 224×224 pixels, then a collection of 16×16 patches may be extracted as tokens. The number of patches increases as frame resolution increases, which results in greater memory usage. Each token may be associated with a corresponding “positional embedding,” which may identify the position of the token in the sequence of tokens. This is one aspect of a transformer model that allows for an improved understanding of relationships in sequential data. Additionally, a classification (CLS) token may be associated with a series of tokens. The CLS token may serve as a classification of that particular series of tokens. For example, the CLS token may provide a label associated with a given set of frames comprising a portion of the video, such as “driving car,” “drinking alcohol,” “shoot,” etc. Continuing the example presented in FIG. 3A , the video data 302 is received by a video encoder 306 and audio data 304 is received by an audio encoder 308 . The video encoder 306 , and audio encoder 308 may be used to extract video embeddings, {E CLS V , E 1 V , . . . , E N V }, and audio embeddings 312 , {E CLS A , E 1 A , . . . , E M A }, respectively, where N is the total number of tokens in the final layer of video embeddings, and M is the total number of tokens in the final layer of audio embeddings. In one or more embodiments, an audio spectrogram transformer (AST) may be used as the audio encoder, and a MViT or Video Swin transformer may be used as the video encoder. For the modality encoders, the first 20 layers of MViT may be used to extract the feature for video, and the first 12 layers of AST may be used to extract the feature for audio. However, any other types of audio, video, and/or any other types of modality encoders may also be used as well. The number of layers can also be generalized to other numbers. Once the video embeddings 310 and audio embeddings 312 are extracted, two different loss functions may be employed (for example, video classification loss function 316 and alignment contrastive loss function 314 ). These two loss functions may generally be used to train the transformer. For example, as may be the case with any type of loss function, the video classification loss function 316 and alignment contrastive loss function 314 may be used to minimize the amount of error that is produced. In the specific case of the video classification loss function 316 and alignment contrastive loss function 314 , the loss functions may be used to determine a difference between the actual outputs being produced by the encoders and the expected outputs. The video classification loss function 316 may be used to retain the competitiveness of video encoder. Particularly, the video classification loss function 316 may compare a classification produced by the video encoder 306 to a known classification associated with the video data 302 that is received by the video encoder 306 . In this manner, the video encoder 306 may be trained to produce more accurate classifications based on any future video data that is received. The alignment contrastive loss function 314 may be used to train the model to better align the video embeddings produced by the video encoder 306 and the audio embeddings produced by the audio encoder 308 . That is, the alignment contrastive loss function 314 may train the model to better ensure that audio segments are processed with respect to their corresponding video segments (this is also applicable to ensure that any other type of data modality aligns with other data of the same segment). Multimodal video inputs, audio and video, may be paired and aligned naturally. Video and audio from the same sample (for example, associated with the same video segment) may be treated as a sample pair. Otherwise, data may be treated as a negative sample pair. Then, contrastive loss and InfoNCE loss may be used to penalize the similarity of negative sample pairs and enlarge the similarity of positive sample pairs. The alignment loss is denoted as L_align or L AL . The alignment contrastive loss function 314 may be shown below in Equation 1. where D is the multimodal input and may include audio A and video V, y AV is the indicator that the current A and V are from the same sample or not, t is a temperature parameter and set as 0.07 (or any other value), g A and g V are linear embedding layers of dimension 256 for audio representation, EA, and video representation, EV, respectively. The dot product g A (*) T g V (*) measures the similarity of audio and video embedding, and the alignment contrastive loss function 314 decreases the divergence of audio and video features for the same sample, which enhances the following cross-modality feature learning. Following the video classification loss function 316 and the alignment contrastive loss function 314 , a multimodal bottleneck transformer 318 may be employed to allow for the fusion of the video and audio data. This may involve generating multimodal bottleneck tokens {E 1 F . . . , E L F } to efficiently learn the cross-modality fusion. The multimodal classification may be achieved by concatenating the CLS embedding followed by a linear layer to yield the classification logits. A common approach for building multimodal models is to simply combine multiple of these modality-specific architectures using late-stage fusion of final representations or predictions. In contrast, the multimodal bottleneck transformer 318 architecture uses “attention bottlenecks” for modality fusion at multiple layers. Compared to traditional pairwise self-attention, these bottlenecks may force information between different modalities to pass through a small number of “bottleneck” latent units, which may require the model to collate and condense the most relevant information in each modality and only share what is necessary. For the multiple modality fusion, an intermediate structure may be constructed that may include a given number of tokens (for example, four tokens or any other number of tokens). These tokens may then be combined with the video tokens through a conventional transformer. In this way, the tokens learn the information from video features, which may share with audio tokens in the next layer. The tokens may also combine with audio tokens, share information with audio tokens, and learn audio-video features through another layer of the transformer. The multiple modality fusion can be stacked any number of additional times as well. Prior cross-modality transformers have involved simple concatenations of multimodal embedding, or key exchanges, value matrices between two modalities. Due to the large GPU memory consumption of these existing video transformers, the multimodal bottleneck transformer 318 in the audio-video transformer is used, which handles varied lengths of modality tokens efficiently. The multimodal tokens {E 1 F . . . , E L F } are initialized, where L may be any number. One multimodal bottleneck transformer block may be formulated as: E VF =[E CLS V ,E 1 V , . . . ,E N V ,E 1 F , . . . ,E L F ],{tilde over (E)} VF =MSA ( LN ( E VF ))+ E VF ÊVF=MLP ( LN ( E VF ))+ {tilde over (E)} AF ,E AF =[E CLS A ,E 1 A , . . . ,E M A ,Ê 1 F , . . . ,Ê L F ] {tilde over (E)} AF =MSA ( LN ( E AF ))+ E AF ,Ê AF =MLP ( LN ( {tilde over (E)} AF ))+ {tilde over (E)} AF where multimodal tokens may be updated by averaging the multimodal tokens along each block. The multimodal bottleneck transformer 318 can be stacked into K blocks. The multimodal bottleneck transformer 318 may reduce the computing complexity from O((M+N) 2 ) in merged attention to O((M+L) 2 )+O((N+L) 2 )≈O(M 2 )+O(N 2 ) since L<<M, N. Following the multimodal bottleneck transformer 318 , two additional loss functions may be used to further train the AVT. These two loss functions may include a cross entropy loss function 320 and a multimodal classification loss function 324 . The cross-entropy loss function 320 may be used to train the classification performed by the audio-video transformer. That is, based on audio and video data that is received, the audio-video transformer may produce one or more classifications for the video segment associated with the video and audio data. For example, the audio-video transformer may indicate that the video includes five frames showing a person drinking alcohol. These types of classifications may be produced for each type of modality and the cross-entropy loss function 320 may be used to determine if the classifications produced by the different modalities match (for example, if any classifications produced with respect to the video data match any classifications produced with respect to the audio data). The tasks and data may be multi-labeled with missing annotations and masked multilabel loss may be employed using Equation 2: where n is the batch size in the stochastic gradient descent, C i is the annotated label set for current i-th sample, and p v (c) is the video classification probability for label c, which is implemented by a linear layer after E CLS V with a sigmoid activation function. The audio-video match cross-entropy loss function 320 may be applied to video and audio embeddings after the multimodal bottleneck transformer 318 and may force the multimodal bottleneck transformer 318 to learn high-level semantic labels precisely. The audio-video match cross-entropy loss function 320 may be shown below in Equation 3. L AVM =− (A,V)∈D [y AV log p AVM ( y AV )+(1− y AV )log(1− p AVM ( y AV ))] (Equation 3) where y AV is the same as the alignment loss, and pAVM(yAV) is implemented by concatenating the video and audio embedding [E CLS V ,E CLS A ] followed by a binary classification to determine the sampled audio-video pair (A, V) are from the same sample or not. To construct the audio-video loss, any video CLS embeddings and audio CLS embeddings may be concatenated, and a fully connected layer may be used with a binary classification cross entropy loss function. The positive pair can be constructed directly by concatenating the CLS embeddings of the video and the audio from the same sample. The negative pair can be constructed by fixing audio CLS embeddings, and sampling one of the non-same indexed video CLS embeddings for each audio CLS embeddings in one batch of the stochastic gradient descent back propagation training. The negative pair may also be constructed by fixing the video CLS embedding and sampling one of the non-same indexed audio CLS embeddings for each video CLS embeddings in one batch of the stochastic gradient descent back propagation training. The audio-video match loss may be denoted as L_avm. To constrain non-CLS embeddings, a masked audio-video loss may be used, where the multimodal bottleneck transformer 318 may be forced to learn high-level complete audio activity segments as illustrated in further detail in FIGS. 4A-4F . The audio activity segment may be detected by second-order smooth to remove noise, gradient to detect signal change along the time dimension, absolute gradient to detect changes in both direction, and average the absolute gradient along the feature dimension with smooth to avoid a trivial activity segment. The top significant change points may then be selected as the transition points to segment different audio activities. In the training, we randomly mask a proportion of whole complete audio activity segments. where {dot over (V)} i is the randomly masked video input, {dot over (A)} i is the structured (audio complete activity segment) masked audio input, {circumflex over (V)} i and Â i are reconstructions from the masked input through the multimodal model, and the decoder can be easily constructed by re-arrange the tokens into two and/or three-dimensional matrix followed by one layer of transposed convolution to match the input dimension. To construct the masked multimodal model, the same network of multimodal network may be used before the task heads as the encoder. The one dimensional (1D) tokens may be rearranged to 2D for audio and 3D for the video and construct a simple decoder which only includes one layer of 2D convolutional layer for audio reconstruction and 3D convolutional layer for video reconstruction. L1 pixel-wise reconstruction loss may then be used to calculate the masked multimodal model loss. Similar to the cross-entropy loss function 320 , the multimodal classification loss function 324 may involve determining the accuracy of the classifications produced by the transformer. However, the multimodal classification loss function 324 may involve training the transformer with respect to any overall classifications produced by the transformer based on the individual classifications of the different modalities (rather than determining the similarities of the classifications produced by the different modalities). In some cases, this may be achieved by concatenating the video and audio embedding [E CLS V ,E CLS A ] (for example, the same as audio-video match loss). A fully connected layer may be constructed to yield the final action classification logits. The multimodal classification loss function 324 may be the same as video classification loss function 316 and is shown below in Equation 5. Any of the classifications produced by the multimodal transformer (and/or any other element of the system described herein) may also be in the form of one or more probabilities of different classifications. For example, a classification may include a probability that a segment of video includes a particular type of classification. Additional probabilities that the segment of video includes other classifications may also be provided as well. Thus, any loss functions that may involve comparisons of classifications produced by the multimodal transformer may refer to comparing these probabilities to known classifications associated with the segments of video. The combination of the four different loss functions that are employed with respect to the audio-video transformer may result in an overall hybrid loss objective. This hybrid loss objective may consider video classification and various levels of self-supervised loss forces the multimodal transformer to learn effectively from the training data, which greatly alleviates the data hungry pitfall to fit large model capacity in the transformer. The hybrid loss objective may be shown below in Equation 6. L=L CLS AV +L CLS V +λ 1 L AL +λ 2 L AL +λ 3 L AL (Equation 6) where λ 1 , λ 2 , and λ 3 are hyper-parameters to balance the loss terms in the training. In some cases, the average of video classification and multimodal classification may achieve the best accuracy on a 28 attributes dataset, however, this is not intended to be limiting. In terms of video categorization, after training is performed using the AVT, videos may be automatically categorized into different classes. For a new search and retrieval task, which is not falling into the current trained attribute set, the combined CLS embedding from different modalities may be used as the feature of the current video. An independent text embedding may be used to extract the feature from the query. A similarity or metric function can be easily learned. Additionally, video localization tasks may be considered as a frame-wise or shot-wise classification task. The shot can be obtained by pre-processing using the shot boundary detection algorithm. The multimodal transformer may learn features for each frame or shot and conduct classification for each frame or shot. In this way, the multimodal video localization can absorb different aspects, of the video, such as audio, text, and vision, which provides a more comprehensive set of information. FIG. 3B illustrates additional details pertaining to the process flow 300 of FIG. 3A . For example, FIG. 3B illustrates example outputs of the multimodal transformer (video classification embedding 326 and audio classification embedding 328 ). FIG. 3B also illustrates that these outputs may be used for various purposes, such as reconstruction of the original raw video and audio at operation 332 , the audio-video match loss function 324 , and the cross-entropy loss function 320 . The figure also shows that the video classification embedding 326 and audio classification embedding 328 may be concatenated to perform the cross-entropy loss. FIG. 3B also illustrates more specific example in which the video encoder 306 is a MVIT and receives a five second video segment comprising 32 frames and the audio encoder 308 is an AST. Finally, FIG. 3B illustrates the multimodal fusion that may occur within the multimodal bottleneck transformer 318 . Any of the additional details provided in FIG. 3B (as well as any details included in FIG. 3A ) are merely exemplary and are not intended to be limiting in any way. For the multiple modality fusion, an intermediate structure may be constructed that may include a given number of tokens (for example, four tokens or any other number of tokens). These tokens may then be combined with the video tokens through a conventional transformer. In this way, the tokens learn the information from video features, which may share with audio tokens in the next layer. The tokens may also combine with audio tokens, share information with audio tokens, and learn audio-video features through another layer of transformer. The multiple modality fusion can be stacked any number of additional times as well. FIGS. 4A-4F schematically illustrate an example audio spectrogram masking process flow in accordance with one or more example embodiments of the disclosure. Different embodiments may include different, additional, or fewer inputs or outputs than those illustrated in the examples of FIGS. 4A-4F . FIGS. 4A-4B illustrate a comparison of a traditional approach to audio masking ( FIG. 4A ) and the improved approach associated with the multimodal transformer described herein ( FIG. 4B ). Beginning with FIG. 4A , a process flow 400 for performing audio masking in traditional transformers is illustrated. The process flow 400 may involve performing random masking of audio data in the audio spectrogram 401 . In other words, random portions of the audio spectrogram are masked (for example, first portion 406 , second portion 408 , etc.). This masked spectrogram is then provided to the transformer and the transformer is tasked with attempting to determine the audio data that is associated with the masked portions of the spectrogram. The transformer is then trained based on its performance in determining the audio data that was originally included in the masked portions of the audio spectrogram. For example, if the audio data includes an audio clip of a person speaking the statement “I have a car.” If the portion of the spectrogram associated with the person speaking the word “car” is masked, then the accuracy of the transformer in being able to determine that the person speaking the word “car” should be included in the masked portion of the audio data may be determined. In contrast with the approach illustrated in FIG. 4A , FIG. 4B illustrates a second process flow 450 . This process flow 450 , instead of masking random segments of the audio spectrogram as is performed in process flow 400 , identifies portions of the audio spectrogram 401 that include actual audio (for example, portions of the spectrogram where a person is speaking in the video segment, etc.) to mask. This prevents a scenario that may occur in the process flow 400 where a randomly masked portion of the audio spectrogram includes no audio being produced (for example, no person is speaking in the audio clip at that portion, etc.). Particularly, the process flow 450 may involve at least the following operations. Operation 452 may involve receiving the audio spectrogram. The audio spectrogram may include audio data that is associated with a particular video segment that is being processed. Operation 454 may involve smoothing the audio spectrogram data. As one non-limiting example, a second order smooth function may be applied to the audio spectrogram along the time dimension. This may be performed to remove noise in the data. Operations 452 and 454 are illustrated in greater detail within FIG. 4C . For example, FIG. 4C shows the audio spectrogram 466 . The audio spectrogram 466 may include portions with audio data (for example, portion 467 and portion 468 ) and portions with no audio data (for example, portion 469 ). Operation 456 may involve determining a gradient of the smoothed audio spectrogram data along the time dimension. The gradient may be determined in order to identify portions of the audio spectrogram data in which there is a significant enough difference in amplitude between two points in time on the spectrogram to indicate a change in audio activity. Operation 458 may involve determining the absolute value of the gradient of the spectrogram determined in operation 456 . The absolute value may be taken because there may be negative changes in audio activity resulting from the gradient. For example, if audio activity transitions from high to low, then there may be a negative gradient. The absolute value ensures that all transitions are treated as positive values for more effective processing of the data. Operations 456 and 458 are illustrated in greater detail within FIG. 4D . Operation 462 may involve determining segment transition points in the audio data. Operation 462 is illustrated in greater detail within FIG. 4E . For example, operation 462 may comprise operations 470 , 472 , and 473 . Operation 470 may involve averaging the absolute gradient along the feature dimension to obtain the change along the time domain. For example, plot 470 shows the average absolute gradient of the spectrogram on the y-axis of the plot and time on the x-axis of the plot. To obtain nontrivial audio segments, operation 472 may also involve may involve smoothing the average absolute gradient. Further, operation 473 may also involve identifying segment transition points. For example, transitions points may include at least transition point 474 , transition point 475 , transition point 476 , and/or transition point 477 . Finally, operation 464 may involve performing the masking of different portions of the audio data based on the prior operations. For example, FIG. 4F illustrates masked portion 480 and masked portion 482 . One or more operations of the methods, process flows, or use cases of FIGS. 1-4 may have been described above as being performed by a user device, or more specifically, by one or more program module(s), applications, or the like executing on a device. It should be appreciated, however, that any of the operations of the methods, process flows, or use cases of FIGS. 1-4 may be performed, at least in part, in a distributed manner by one or more other devices, or more specifically, by one or more program module(s), applications, or the like executing on such devices. In addition, it should be appreciated that the processing performed in response to the execution of computer-executable instructions provided as part of an application, program module, or the like may be interchangeably described herein as being performed by the application or the program module itself or by a device on which the application, program module, or the like is executing. While the operations of the methods, process flows, or use cases of FIGS. 1-4 may be described in the context of the illustrative devices, it should be appreciated that such operations may be implemented in connection with numerous other device configurations. The operations described and depicted in the illustrative methods, process flows, and use cases of FIGS. 1-4 may be carried out or performed in any suitable order as desired in various example embodiments of the disclosure. Additionally, in certain example embodiments, at least a portion of the operations may be carried out in parallel. Furthermore, in certain example embodiments, less, more, or different operations than those depicted in FIGS. 1-4 may be performed. Although specific embodiments of the disclosure have been described, one of ordinary skill in the art will recognize that numerous other modifications and alternative embodiments are within the scope of the disclosure. For example, any of the functionality and/or processing capabilities described with respect to a particular device or component may be performed by any other device or component. Further, while various illustrative implementations and architectures have been described in accordance with embodiments of the disclosure, one of ordinary skill in the art will appreciate that numerous other modifications to the illustrative implementations and architectures described herein are also within the scope of this disclosure. Certain aspects of the disclosure are described above with reference to block and flow diagrams of systems, methods, apparatuses, and/or computer program products according to example embodiments. It will be understood that one or more blocks of the block diagrams and flow diagrams, and combinations of blocks in the block diagrams and the flow diagrams, respectively, may be implemented by execution of computer-executable program instructions. Likewise, some blocks of the block diagrams and flow diagrams may not necessarily need to be performed in the order presented or may not necessarily need to be performed at all, according to some embodiments. Further, additional components and/or operations beyond those depicted in blocks of the block and/or flow diagrams may be present in certain embodiments. Accordingly, blocks of the block diagrams and flow diagrams support combinations of means for performing the specified functions, combinations of elements or steps for performing the specified functions, and program instruction means for performing the specified functions. It will also be understood that each block of the block diagrams and flow diagrams, and combinations of blocks in the block diagrams and flow diagrams, may be implemented by special-purpose, hardware-based computer systems that perform the specified functions, elements or steps, or combinations of special-purpose hardware and computer instructions. Illustrative Device Architecture FIG. 5 is a schematic block diagram of an illustrative remote server 500 in accordance with one or more example embodiments of the disclosure. The remote server 500 may include any suitable computing device capable of receiving and/or generating data including, but not limited to, a mobile device such as a smartphone, tablet, e-reader, wearable device, or the like; a desktop computer; a laptop computer; a content streaming device; a set-top box; or the like. The remote server 500 may correspond to an illustrative device configuration for the devices of FIGS. 1-4 . The remote server 500 may be configured to communicate via one or more networks with one or more servers, search engines, user devices, or the like. In some embodiments, a single remote server or single group of remote servers may be configured to perform more than one type of content rating and/or machine learning functionality. Example network(s) may include, but are not limited to, any one or more different types of communications networks such as, for example, cable networks, public networks (e.g., the Internet), private networks (e.g., frame-relay networks), wireless networks, cellular networks, telephone networks (e.g., a public switched telephone network), or any other suitable private or public packet-switched or circuit-switched networks. Further, such network(s) may have any suitable communication range associated therewith and may include, for example, global networks (e.g., the Internet), metropolitan area networks (MANs), wide area networks (WANs), local area networks (LANs), or personal area networks (PANs). In addition, such network(s) may include communication links and associated networking devices (e.g., link-layer switches, routers, etc.) for transmitting network traffic over any suitable type of medium including, but not limited to, coaxial cable, twisted-pair wire (e.g., twisted-pair copper wire), optical fiber, a hybrid fiber-coaxial (HFC) medium, a microwave medium, a radio frequency communication medium, a satellite communication medium, or any combination thereof. In an illustrative configuration, the remote server 500 may include one or more processors (processor(s)) 502 , one or more memory devices 504 (generically referred to herein as memory 504 ), one or more input/output (I/O) interface(s) 506 , one or more network interface(s) 508 , one or more sensors or sensor interface(s) 510 , one or more transceivers 512 , one or more optional speakers 514 , one or more optional microphones 516 , and data storage 520 . The remote server 500 may further include one or more buses 518 that functionally couple various components of the remote server 500 . The remote server 500 may further include one or more antenna (e) 534 that may include, without limitation, a cellular antenna for transmitting or receiving signals to/from a cellular network infrastructure, an antenna for transmitting or receiving Wi-Fi signals to/from an access point (AP), a Global Navigation Satellite System (GNSS) antenna for receiving GNSS signals from a GNSS satellite, a Bluetooth antenna for transmitting or receiving Bluetooth signals, a Near Field Communication (NFC) antenna for transmitting or receiving NFC signals, and so forth. These various components will be described in more detail hereinafter. The bus(es) 518 may include at least one of a system bus, a memory bus, an address bus, or a message bus, and may permit exchange of information (e.g., data (including computer-executable code), signaling, etc.) between various components of the remote server 500 . The bus(es) 518 may include, without limitation, a memory bus or a memory controller, a peripheral bus, an accelerated graphics port, and so forth. The bus(es) 518 may be associated with any suitable bus architecture including, without limitation, an Industry Standard Architecture (ISA), a Micro Channel Architecture (MCA), an Enhanced ISA (EISA), a Video Electronics Standards Association (VESA) architecture, an Accelerated Graphics Port (AGP) architecture, a Peripheral Component Interconnects (PCI) architecture, a PCI-Express architecture, a Personal Computer Memory Card International Association (PCMCIA) architecture, a Universal Serial Bus (USB) architecture, and so forth. The memory 504 of the remote server 500 may include volatile memory (memory that maintains its state when supplied with power) such as random-access memory (RAM) and/or nonvolatile memory (memory that maintains its state even when not supplied with power) such as read-only memory (ROM), flash memory, ferroelectric RAM (FRAM), and so forth. Persistent data storage, as that term is used herein, may include nonvolatile memory. In certain example embodiments, volatile memory may enable faster read/write access than nonvolatile memory. However, in certain other example embodiments, certain types of nonvolatile memory (e.g., FRAM) may enable faster read/write access than certain types of volatile memory. In various implementations, the memory 504 may include multiple different types of memory such as various types of static random-access memory (SRAM), various types of dynamic random-access memory (DRAM), various types of unalterable ROM, and/or writeable variants of ROM such as electrically erasable programmable read-only memory (EEPROM), flash memory, and so forth. The memory 504 may include main memory as well as various forms of cache memory such as instruction cache(s), data cache(s), translation lookaside buffer(s) (TLBs), and so forth. Further, cache memory such as a data cache may be a multilevel cache organized as a hierarchy of one or more cache levels (L1, L2, etc.). The data storage 520 may include removable storage and/or nonremovable storage including, but not limited to, magnetic storage, optical disk storage, and/or tape storage. The data storage 520 may provide nonvolatile storage of computer-executable instructions and other data. The memory 504 and the data storage 520 , removable and/or nonremovable, are examples of computer-readable storage media (CRSM) as that term is used herein. The data storage 520 may store computer-executable code, instructions, or the like that may be loadable into the memory 504 and executable by the processor(s) 502 to cause the processor(s) 502 to perform or initiate various operations. The data storage 520 may additionally store data that may be copied to memory 504 for use by the processor(s) 502 during the execution of the computer-executable instructions. Moreover, output data generated as a result of execution of the computer-executable instructions by the processor(s) 502 may be stored initially in memory 504 , and may ultimately be copied to data storage 520 for nonvolatile storage. More specifically, the data storage 520 may store one or more operating systems (O/S) 522 ; one or more database management systems (DBMS) 524 ; and one or more program module(s), applications, engines, computer-executable code, scripts, or the like such as, for example, one or more machine learning module(s) 526 . Some or all of these module(s) may be sub-module(s). Any of the components depicted as being stored in data storage 520 may include any combination of software, firmware, and/or hardware. The software and/or firmware may include computer-executable code, instructions, or the like that may be loaded into the memory 504 for execution by one or more of the processor(s) 502 . Any of the components depicted as being stored in data storage 520 may support functionality described in reference to correspondingly named components earlier in this disclosure. The data storage 520 may further store various types of data utilized by components of the remote server 500 . Any data stored in the data storage 520 may be loaded into the memory 504 for use by the processor(s) 502 in executing computer-executable code. In addition, any data depicted as being stored in the data storage 520 may potentially be stored in one or more datastore(s) and may be accessed via the DBMS 524 and loaded in the memory 504 for use by the processor(s) 502 in executing computer-executable code. The datastore(s) may include, but are not limited to, databases (e.g., relational, object-oriented, etc.), file systems, flat files, distributed datastores in which data is stored on more than one node of a computer network, peer-to-peer network datastores, or the like. In FIG. 5 , the datastore(s) may include, for example, purchase history information, user action information, user profile information, a database linking search queries and user actions, and other information. The processor(s) 502 may be configured to access the memory 504 and execute computer-executable instructions loaded therein. For example, the processor(s) 502 may be configured to execute computer-executable instructions of the various program module(s), applications, engines, or the like of the remote server 500 to cause or facilitate various operations to be performed in accordance with one or more embodiments of the disclosure. The processor(s) 502 may include any suitable processing unit capable of accepting data as input, processing the input data in accordance with stored computer-executable instructions, and generating output data. The processor(s) 502 may include any type of suitable processing unit including, but not limited to, a central processing unit, a microprocessor, a Reduced Instruction Set Computer (RISC) microprocessor, a Complex Instruction Set Computer (CISC) microprocessor, a microcontroller, an Application Specific Integrated Circuit (ASIC), a Field-Programmable Gate Array (FPGA), a System-on-a-Chip (SoC), a digital signal processor (DSP), and so forth. Further, the processor(s) 502 may have any suitable microarchitecture design that includes any number of constituent components such as, for example, registers, multiplexers, arithmetic logic units, cache controllers for controlling read/write operations to cache memory, branch predictors, or the like. The microarchitecture design of the processor(s) 502 may be capable of supporting any of a variety of instruction sets. Referring now to functionality supported by the various program module(s) depicted in FIG. 5 , the machine learning module(s) 526 may include computer-executable instructions, code, or the like that responsive to execution by one or more of the processor(s) 502 may perform functions including, but not limited to, performing any functionality associated with the AVT as described herein, and the like. Referring now to other illustrative components depicted as being stored in the data storage 520 , the O/S 522 may be loaded from the data storage 520 into the memory 504 and may provide an interface between other application software executing on the remote server 500 and hardware resources of the remote server 500 . More specifically, the O/S 522 may include a set of computer-executable instructions for managing hardware resources of the remote server 500 and for providing common services to other application programs (e.g., managing memory allocation among various application programs). In certain example embodiments, the O/S 522 may control execution of the other program module(s) to dynamically enhance characters for content rendering. The O/S 522 may include any operating system now known or which may be developed in the future including, but not limited to, any server operating system, any mainframe operating system, or any other proprietary or non-proprietary operating system. The DBMS 524 may be loaded into the memory 504 and may support functionality for accessing, retrieving, storing, and/or manipulating data stored in the memory 504 and/or data stored in the data storage 520 . The DBMS 524 may use any of a variety of database models (e.g., relational model, object model, etc.) and may support any of a variety of query languages. The DBMS 524 may access data represented in one or more data schemas and stored in any suitable data repository including, but not limited to, databases (e.g., relational, object-oriented, etc.), file systems, flat files, distributed datastores in which data is stored on more than one node of a computer network, peer-to-peer network datastores, or the like. In those example embodiments in which the remote server 500 is a mobile device, the DBMS 524 may be any suitable light-weight DBMS optimized for performance on a mobile device. Referring now to other illustrative components of the remote server 500 , the input/output (I/O) interface(s) 506 may facilitate the receipt of input information by the remote server 500 from one or more I/O devices as well as the output of information from the remote server 500 to the one or more I/O devices. The I/O devices may include any of a variety of components such as a display or display screen having a touch surface or touchscreen; an audio output device for producing sound, such as a speaker; an audio capture device, such as a microphone; an image and/or video capture device, such as a camera; a haptic unit; and so forth. Any of these components may be integrated into the remote server 500 or may be separate. The I/O devices may further include, for example, any number of peripheral devices such as data storage devices, printing devices, and so forth. The I/O interface(s) 506 may also include an interface for an external peripheral device connection such as universal serial bus (USB), FireWire, Thunderbolt, Ethernet port or other connection protocol that may connect to one or more networks. The I/O interface(s) 506 may also include a connection to one or more of the antenna (e) 534 to connect to one or more networks via a wireless local area network (WLAN) (such as Wi-Fi) radio, Bluetooth, ZigBee, and/or a wireless network radio, such as a radio capable of communication with a wireless communication network such as a Long Term Evolution (LTE) network, WiMAX network, 3G network, ZigBee network, etc. The remote server 500 may further include one or more network interface(s) 508 via which the remote server 500 may communicate with any of a variety of other systems, platforms, networks, devices, and so forth. The network interface(s) 508 may enable communication, for example, with one or more wireless routers, one or more host servers, one or more web servers, and the like via one or more of networks. The antenna (e) 534 may include any suitable type of antenna depending, for example, on the communications protocols used to transmit or receive signals via the antenna (e) 534 . Non-limiting examples of suitable antennas may include directional antennas, nondirectional antennas, dipole antennas, folded dipole antennas, patch antennas, multiple-input multiple-output (MIMO) antennas, or the like. The antenna (e) 534 may be communicatively coupled to one or more transceivers 512 or radio components to which or from which signals may be transmitted or received. As previously described, the antenna (e) 534 may include a cellular antenna configured to transmit or receive signals in accordance with established standards and protocols, such as Global System for Mobile Communications (GSM), 3G standards (e.g., Universal Mobile Telecommunications System (UMTS), Wideband Code Division Multiple Access (W-CDMA), CDMA2000, etc.), 4G standards (e.g., Long-Term Evolution (LTE), WiMax, etc.), direct satellite communications, or the like. The antenna (e) 534 may additionally, or alternatively, include a Wi-Fi antenna configured to transmit or receive signals in accordance with established standards and protocols, such as the IEEE 802.11 family of standards, including via 2.4 GHz channels (e.g., 802.11b, 802.11 g, 802.11n), 5 GHz channels (e.g., 802.11n, 802.11ac), or 60 GHz channels (e.g., 802.11ad). In alternative example embodiments, the antenna (e) 534 may be configured to transmit or receive radio frequency signals within any suitable frequency range forming part of the unlicensed portion of the radio spectrum. The antenna (e) 534 may additionally, or alternatively, include a GNSS antenna configured to receive GNSS signals from three or more GNSS satellites carrying time-position information to triangulate a position therefrom. Such a GNSS antenna may be configured to receive GNSS signals from any current or planned GNSS such as, for example, the Global Positioning System (GPS), the GLONASS System, the Compass Navigation System, the Galileo System, or the Indian Regional Navigational System. The transceiver(s) 512 may include any suitable radio component(s) for—in cooperation with the antenna (e) 534 —transmitting or receiving radio frequency (RF) signals in the bandwidth and/or channels corresponding to the communications protocols utilized by the remote server 500 to communicate with other devices. The transceiver(s) 512 may include hardware, software, and/or firmware for modulating, transmitting, or receiving—potentially in cooperation with any of antenna (e) 534 —communications signals according to any of the communications protocols discussed above including, but not limited to, one or more Wi-Fi and/or Wi-Fi direct protocols, as standardized by the IEEE 802.11 standards, one or more non-Wi-Fi protocols, or one or more cellular communications protocols or standards. The transceiver(s) 512 may further include hardware, firmware, or software for receiving GNSS signals. The transceiver(s) 512 may include any known receiver and baseband suitable for communicating via the communications protocols utilized by the remote server 500 . The transceiver(s) 512 may further include a low noise amplifier (LNA), additional signal amplifiers, an analog-to-digital (A/D) converter, one or more buffers, a digital baseband, or the like. The sensor(s)/sensor interface(s) 510 may include or may be capable of interfacing with any suitable type of sensing device such as, for example, inertial sensors, force sensors, thermal sensors, and so forth. Example types of inertial sensors may include accelerometers (e.g., MEMS-based accelerometers), gyroscopes, and so forth. The optional speaker(s) 514 may be any device configured to generate audible sound. The optional microphone(s) 516 may be any device configured to receive analog sound input or voice data. It should be appreciated that the program module(s), applications, computer-executable instructions, code, or the like depicted in FIG. 5 as being stored in the data storage 520 are merely illustrative and not exhaustive and that processing described as being supported by any particular module may alternatively be distributed across multiple module(s) or performed by a different module. In addition, various program module(s), script(s), plug-in(s), Application Programming Interface(s) (API(s)), or any other suitable computer-executable code hosted locally on the remote server 500 , and/or hosted on other computing device(s) accessible via one or more networks, may be provided to support functionality provided by the program module(s), applications, or computer-executable code depicted in FIG. 5 and/or additional or alternate functionality. Further, functionality may be modularized differently such that processing described as being supported collectively by the collection of program module(s) depicted in FIG. 5 may be performed by a fewer or greater number of module(s), or functionality described as being supported by any particular module may be supported, at least in part, by another module. In addition, program module(s) that support the functionality described herein may form part of one or more applications executable across any number of systems or devices in accordance with any suitable computing model such as, for example, a client-server model, a peer-to-peer model, and so forth. In addition, any of the functionalities described as being supported by any of the program module(s) depicted in FIG. 5 may be implemented, at least partially, in hardware and/or firmware across any number of devices. It should further be appreciated that the remote server 500 may include alternate and/or additional hardware, software, or firmware components beyond those described or depicted without departing from the scope of the disclosure. More particularly, it should be appreciated that software, firmware, or hardware components depicted as forming part of the remote server 500 are merely illustrative and that some components may not be present, or additional components may be provided in various embodiments. While various illustrative program module(s) have been depicted and described as software module(s) stored in data storage 520 , it should be appreciated that functionality described as being supported by the program module(s) may be enabled by any combination of hardware, software, and/or firmware. It should further be appreciated that each of the above-mentioned module(s) may, in various embodiments, represent a logical partitioning of supported functionality. This logical partitioning is depicted for ease of explanation of the functionality and may not be representative of the structure of software, hardware, and/or firmware for implementing the functionality. Accordingly, it should be appreciated that functionality described as being provided by a particular module may, in various embodiments, be provided at least in part by one or more other module(s). Further, one or more depicted module(s) may not be present in certain embodiments, while in other embodiments, additional module(s) not depicted may be present and may support at least a portion of the described functionality and/or additional functionality. Moreover, while certain module(s) may be depicted and described as sub-module(s) of another module, in certain embodiments, such module(s) may be provided as independent module(s) or as sub-module(s) of other module(s). Program module(s), applications, or the like disclosed herein may include one or more software components including, for example, software objects, methods, data structures, or the like. Each such software component may include computer-executable instructions that, responsive to execution, cause at least a portion of the functionality described herein (e.g., one or more operations of the illustrative methods described herein) to be performed. A software component may be coded in any of a variety of programming languages. An illustrative programming language may be a lower-level programming language such as an assembly language associated with a particular hardware architecture and/or operating system platform. A software component comprising assembly language instructions may require conversion into executable machine code by an assembler prior to execution by the hardware architecture and/or platform. Another example programming language may be a higher-level programming language that may be portable across multiple architectures. A software component comprising higher-level programming language instructions may require conversion to an intermediate representation by an interpreter or a compiler prior to execution. Other examples of programming languages include, but are not limited to, a macro language, a shell or command language, a job control language, a script language, a database query or search language, or a report writing language. In one or more example embodiments, a software component comprising instructions in one of the foregoing examples of programming languages may be executed directly by an operating system or other software component without having to be first transformed into another form. A software component may be stored as a file or other data storage construct. Software components of a similar type or functionally related may be stored together such as, for example, in a particular directory, folder, or library. Software components may be static (e.g., pre-established or fixed) or dynamic (e.g., created or modified at the time of execution). Software components may invoke or be invoked by other software components through any of a wide variety of mechanisms. Invoked or invoking software components may comprise other custom-developed application software, operating system functionality (e.g., device drivers, data storage (e.g., file management) routines, other common routines and services, etc.), or third-party software components (e.g., middleware, encryption, or other security software, database management software, file transfer or other network communication software, mathematical or statistical software, image processing software, and format translation software). Software components associated with a particular solution or system may reside and be executed on a single platform or may be distributed across multiple platforms. The multiple platforms may be associated with more than one hardware vendor, underlying chip technology, or operating system. Furthermore, software components associated with a particular solution or system may be initially written in one or more programming languages but may invoke software components written in another programming language. Computer-executable program instructions may be loaded onto a special-purpose computer or other particular machine, a processor, or other programmable data processing apparatus to produce a particular machine, such that execution of the instructions on the computer, processor, or other programmable data processing apparatus causes one or more functions or operations specified in the flow diagrams to be performed. These computer program instructions may also be stored in a computer-readable storage medium (CRSM) that upon execution may direct a computer or other programmable data processing apparatus to function in a particular manner, such that the instructions stored in the computer-readable storage medium produce an article of manufacture including instruction means that implement one or more functions or operations specified in the flow diagrams. The computer program instructions may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operational elements or steps to be performed on the computer or other programmable apparatus to produce a computer-implemented process. Additional types of CRSM that may be present in any of the devices described herein may include, but are not limited to, programmable random-access memory (PRAM), SRAM, DRAM, RAM, ROM, electrically erasable programmable read-only memory (EEPROM), flash memory or other memory technology, compact disc read-only memory (CD-ROM), digital versatile disc (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the information and which can be accessed. Combinations of any of the above are also included within the scope of CRSM. Alternatively, computer-readable communication media (CRCM) may include computer-readable instructions, program module(s), or other data transmitted within a data signal, such as a carrier wave, or other transmission. However, as used herein, CRSM does not include CRCM. Although embodiments have been described in language specific to structural features and/or methodological acts, it is to be understood that the disclosure is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as illustrative forms of implementing the embodiments. Conditional language, such as, among others, “can,” “could,” “might,” or “may,” unless specifically stated otherwise, or otherwise understood within the context as used, is generally intended to convey that certain embodiments could include, while other embodiments do not include, certain features, elements, and/or steps. Thus, such conditional language is not generally intended to imply that features, elements, and/or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding, with or without user input or prompting, whether these features, elements, and/or steps are included or are to be performed in any particular embodiment.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"184-148-279-692-909","jurisdiction":"US","doc_number":"12366533","kind":"B2","date_published":"2025-07-22","doc_key":"US_12366533_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12366533","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"18760099","date":"2024-07-01"},"priority_claims":{},"invention_title":[{"text":"Hybrid metrology method and system","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"2877","extracted_name":{"value":"Hina F Ayub"}}},"applicants":[{"residence":"IL","extracted_name":{"value":"NOVA LTD"},"extracted_address":"Rehovot"}],"inventors":[{"residence":"IL","sequence":1,"extracted_name":{"value":"Gilad Barak"},"extracted_address":"Rehovot"},{"residence":"IL","sequence":2,"extracted_name":{"value":"Yanir Hainick"},"extracted_address":"Tel-Aviv"},{"residence":"IL","sequence":3,"extracted_name":{"value":"Yonatan Oren"},"extracted_address":"Kiryat Ono"}],"agents":[{"extracted_name":{"value":"AlphaPatent Associates Ltd."}},{"extracted_name":{"value":"Daniel J. Swirsky"}}]},"classifications_ipcr":{"classifications":[{"symbol":"G01N21/65","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G01B11/06","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01L1/00","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01L1/24","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01N21/01","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01N21/95","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G03F7/00","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01L21/66","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"G01N21/65","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G01B11/0666","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01L1/00","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01L1/24","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01N21/01","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01N21/658","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01N21/9501","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G03F7/70625","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01L22/12","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G01B2210/56","classification_value":"A","classification_symbol_position":"L"}]},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12366533","kind":"B2","date":"2025-07-22"},"lens_id":"184-148-279-692-909"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12366533","kind":"B2","date":"2025-07-22"},"lens_id":"184-148-279-692-909"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"A method and system are presented for use in measuring characteristic(s) of patterned structures. The method utilizes processing of first and second measured data, wherein the first measured data is indicative of at least one Raman spectrum obtained from a patterned structure under measurements using at least one selected optical measurement scheme each with a predetermined configuration of illuminating and/or collected light conditions corresponding to the characteristic(s) to be measured, and the second measured data comprises at least one spectrum obtained from the patterned structure in Optical Critical Dimension (OCD) measurement session. The processing comprises applying model-based analysis to the at least one Raman spectrum and the at least one OCD spectrum, and determining the characteristic(s) of the patterned structure under measurements.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A system for use in measuring one or more characteristics of patterned structures on a semiconductor wafer during manufacturing, the system comprising: an optical measurement system configured and operable to perform optical measurements on a patterned structure using at least two optical measurement schemes including Raman Spectroscopy and Optical Critical Dimension metrology, wherein said Raman Spectroscopy metrology optical measurement scheme is configured for collection of optical signals using different excitation wavelengths, and generate measured data indicative of spectral responses of the patterned structure comprising at least one Raman spectrum and at least one Optical Critical Dimension spectrum; and a control system configured for data communication with the optical measurement system to receive and process the measured data to determine the one or more characteristics of the patterned structure by modeling electromagnetic interaction with the patterned structure, wherein the control system is configured to utilize at least a portion of a calculation engine to perform the modeling using the at least one Raman spectrum and utilize the same portion to perform the modeling using the at least one Optical Critical Dimension spectrum."]},{"claim_text":["2. The system of claim 1 wherein one or more of the characteristics of the patterned structure are determined based on at least one Raman spectrum, one or more of the characteristics of the patterned structure are determined based on at least one Optical Critical Dimension spectrum, and one or more of the characteristics of the patterned structure are determined based on both the at least one Raman spectrum and the at least one Optical Critical Dimension spectrum."]},{"claim_text":["3. The system of claim 1 and further including a light source system for illuminating the patterned structures on the semiconductor wafer when any of the optical measurements are performed."]},{"claim_text":["4. The system of claim 1 wherein the optical measurement system is configured and operable to perform the optical measurements in separate Raman Spectroscopy and Optical Critical Dimension modes."]},{"claim_text":["5. The system of claim 1 wherein the optical measurement schemes employ different measurement configurations using any of different polarization configurations for illumination and collection channels, different illumination and collection angles of incidence, different sample azimuths, and different wavelengths."]},{"claim_text":["6. The system of claim 1 wherein the wherein the optical measurement system is configured and operable to select a combination of Raman Spectroscopy and Optical Critical Dimension channels based on any of known sensitivities of each channel to one or more parameters of interest, known correlations between the known sensitivities to different ones of the parameters of interest, different configurations of the optical measurement system, and known productivity considerations including any of throughput and possible sample damage."]},{"claim_text":["7. The system of claim 1 wherein the wherein the one or more characteristics of the patterned structure include any of dimensions and materials properties."]},{"claim_text":["8. The system of claim 1 wherein the measured data are indicative of a number n, where n>1, of different Raman spectra obtained from the patterned structure using n different optical measurement schemes, respectively, with different configurations of at least one of illumination and collected light conditions corresponding to the one or more characteristics of the patterned structure being measured."]},{"claim_text":["9. The system of claim 8 wherein the different configurations of the at least one of illumination and collected light conditions are characterized by one or more of different excitation wavelength, different polarization, different angles of incidence, and different azimuth."]},{"claim_text":["10. The system of claim 1 wherein the one or more characteristics of the patterned structure being measured include one or more of material composition, stress, and crystallinity."]},{"claim_text":["11. The system of claim 1 wherein the optical measurement schemes measure different locations of the semiconductor wafer and wherein the locations share one or more attributes including any of dimensions and materials properties."]},{"claim_text":["12. The system of claim 1 wherein the optical measurement system comprises a separate optical measurement subsystem for each of the at least two optical measurement schemes."]},{"claim_text":["13. A method for use in measuring one or more characteristics of patterned structures on a semiconductor wafer during manufacturing, the method comprising: performing optical measurements on a patterned structure using at least two optical measurement schemes including Raman Spectroscopy and Optical Critical Dimension metrology, wherein at least said Raman Spectroscopy metrology optical measurement scheme is configured for collection of optical signals using different excitation wavelengths; generating measured data indicative of spectral responses of the patterned structure comprising at least one Raman spectrum and at least one Optical Critical Dimension spectrum; and processing the measured data to determine the one or more characteristics of the patterned structure by modeling electromagnetic interaction with the patterned structure, wherein at least a portion of a calculation engine is utilized to perform the modeling using the at least one Raman spectrum and the same portion is utilized to perform the modeling using the at least one Optical Critical Dimension spectrum."]},{"claim_text":["14. The method of claim 13 wherein one or more of the characteristics of the patterned structure are determined based on at least one Raman spectrum, one or more of the characteristics of the patterned structure are determined based on at least one Optical Critical Dimension spectrum, and one or more of the characteristics of the patterned structure are determined based on both the at least one Raman spectrum and the at least one Optical Critical Dimension spectrum."]},{"claim_text":["15. The method of claim 13 wherein the performing comprises performing the optical measurements in separate Raman Spectroscopy and Optical Critical Dimension modes."]},{"claim_text":["16. The method of claim 13 wherein the optical measurement schemes employ different measurement configurations using any of different polarization configurations for illumination and collection channels, different illumination and collection angles of incidence, different sample azimuths, and different wavelengths."]},{"claim_text":["17. The method of claim 13 and further comprising selecting a combination of Raman Spectroscopy and Optical Critical Dimension channels based on any of known sensitivities of each channel to one or more parameters of interest, known correlations between the known sensitivities to different ones of the parameters of interest, different configurations of the optical measurement system, and known productivity considerations including any of throughput and possible sample damage."]},{"claim_text":["18. The method of claim 13 wherein the wherein the one or more characteristics of the patterned structure include any of dimensions and materials properties."]},{"claim_text":["19. The method of claim 13 wherein the measured data are indicative of a number n, where n>1, of different Raman spectra obtained from the patterned structure using n different optical measurement schemes, respectively, with different configurations of at least one of illumination and collected light conditions corresponding to the one or more characteristics of the patterned structure being measured."]},{"claim_text":["20. The method of claim 19 wherein the different configurations of the at least one of illumination and collected light conditions are characterized by one or more of different excitation wavelength, different polarization, different angles of incidence, and different azimuth."]},{"claim_text":["21. The method of claim 13 wherein the one or more characteristics of the patterned structure being measured include one or more of material composition, stress, and crystallinity."]},{"claim_text":["22. The method of claim 13 wherein the optical measurement schemes measure different locations of the semiconductor wafer and wherein the locations share one or more attributes including any of any of dimensions and materials properties."]},{"claim_text":["23. The method of claim 13 and further comprising employing separate optical measurement subsystem for each of the at least two optical measurement schemes."]}],"lang":"en"}],"description":{"text":"TECHNOLOGICAL FIELD The present invention is in the field of metrology techniques, in particular useful for measuring on patterned structures, such as semiconductor wafers. The invention relates to an optical measurement system and method implementing a hybrid metrology technique. BACKGROUND The growing complexity of semiconductor device designs in advanced technology nodes, involves both a decrease in structural dimensions and higher complexity of the device design. The mainstream methods for dimensional characterization of such devices are based on optical metrology approaches, broadly termed Optical Critical Dimensions (OCD) metrology. The optical reflectivity of the sample depends on the dimensional characteristics of the measured structure, allowing inference of the measured structure dimensions from the measured signal through appropriate modeling and interpretation tools. Hybrid Metrology (HM) technique is aimed at improving the accuracy, precision or other metrology performance of measurements by combining information from different toolsets to provide increased metrology performance for complex multi-stack structures of various types, including FinFET devices (i.e. Field Effect transistor in which the conducting channel is wrapped by a thin silicon “fin”, which forms the body of the device). According to the known HM approach, the information measured by a secondary toolset (typically, critical dimensions Scanning Electron Microscopy (CD-SEM)) is used as input constraint on the modeling analysis of a primary toolset (typically, optical critical dimension (OCD)). For example, WO 2011/158239, assigned to the assignee of the present application, describes a system and method for use in metrology of patterned structures, including data input utility for receiving first type of data indicative of image data on at least a part of the patterned structure, and data processing and analyzing utility configured and operable for analyzing the image data, and determining a geometrical model for at least one feature of a pattern in the structure, and using this geometrical model for determining an optical model for second type of data indicative of optical measurements on a patterned structure. In this technique, optimization of the interpretation models of two tools (OCD and CD-SEM tools) is performed using measured data from both tools, by creating a combined model. The information measured by the secondary toolset (CD-SEM) is typically used as input constraint on the modeling analysis of the primary toolset (OCD). This is a so-called “sequential hybridization” of data from one toolset to another. While this sequential hybridization is generally successful, there are cases where it does not sufficiently or at all improve the measurement results. This is because a “threshold” parameter used to analyze CD-SEM images does not provide a reading of the CD value at a well-defined height of the structure being measured, but the CD value provided corresponds to ill-defined heights, correlated with other parameters of the structure such, as side wall angle (SWA). WO 15/125127, also assigned to the assignee of the present application, describes the technique enabling to remove the above-mentioned correlation for better matching of data (between at least two tools, and to a reference system) and thus provide better Hybrid Metrology results. This technique utilizes the concept of a so-called “co-optimization” based hybridization, where, for example, image analysis parameters of a secondary tool (e.g. CD-SEM, X-ray tool) are modulated by profile information from a primary tool, OCD (scatterometry), while the OCD extracted profile is concurrently optimized (to minimize errors) through addition of the results (CD) of e.g. CD-SEM. GENERAL DESCRIPTION There is need for a novel approach for combining the information from a dimensional metrology information channel, namely OCD, and a material and dimensional sensitive information channel, namely Raman spectroscopy. This is associated with another key trend in modern fabrication technology which involves the utilization of new materials, as well as more diverse phases and structural variations of these materials. Such variation of the materials properties often has an impact on other (e.g. optical/electrical) attributes, leading to an adverse effect on the optical dimensional metrology quality. For example, composition, stress \\strain, doping and crystal phase can all have direct impact on the optical properties (complex refractive index, ‘n&k’) of a material. Without knowledge of these properties, the optical metrology solutions would be degraded. In these situations, a metrology solution allowing material characterization at comparable throughput to that of the dimensional metrology tools is of high potential benefit. Moreover, the ability to separately distinguish between materials properties associated with different parts of the stack is of specific importance, in order to correctly ‘guide’ the optical metrology solution. Yet another trend common to modern dimensional metrology is the need for additional, independent information channels, sensitive to the target structure dimensional characteristics. Adding more such channels provides supporting perspective on the measured structure, and allows dealing with their ever increasing complexity. OCD is an extremely useful technique for dimensional characterization of nanostructures, heavily utilized during advanced semiconductor fabrication process. OCD is based on the acquisition of a set of reflected signal from the sample, at different wavelengths, polarizations, angles of incidence etc. These measurements are then compared to a corresponding set of modeled signals, representing the expected signal from some assumed structure. In this respect, OCD can only be used to characterize a known structure, for which the geometrical layout and material properties are roughly known. The assumed characteristics of the measured signal are then iteratively altered until fitting is obtained between the measurement and model. Raman spectroscopy is also a widely used technique in diverse field of science and metrology. The Raman spectrum carries information on various properties of the probed sample. Most notably, different peaks in the spectrum correspond to different materials. When the measured target is comprised of material compounds (e.g. SiGe), specific peaks in the Raman spectrum would correspond to different atom pairs (e.g. Si—Si, Si—Ge and Ge—Ge). In this connection, reference is made to FIG. 1 exemplifying the Raman spectrum from a thin SiGe layer deposited over Si (graph S 1 ), as well as pure (bulk) Si for reference (graph S 2 ). In the SiGe measurement, four peaks are clearly observed. The strong peak at 520 cm −1 corresponds to Si—Si vibrations in the substrate. The three additional peaks correspond to Si—Si, Si—Ge and Ge—Ge pairs in the SiGe film. In the pure-Si reference spectrum, only the substrate Si—Si peak is observed. Thus, the presence of a SiGe layer gives rise to three additional peaks, associated with the vibrations of different atom pairs in the layer. Methods for extracting information on concentration and stress from the positions of these peaks are well known in the literature. For example, a set of equations relating the positions of the three SiGe peaks with the Germanium composition and the layer stress is presented in the following publication: T. S. Perov et al., Composition and strain in thin Si 1 −xGex virtual substrates measured by micro - Raman spectroscopy and x - ray diffraction , J. App. Phys. 109, 033502 (2011). Doping is another characteristic which affects the Raman spectrum. Carrier concentration, arising from the dopant distribution, affects the Raman signal and causes an additional (arguably small) shift in the Raman peaks. The level of doping can hence be incorporated into the fitting procedure, and concurrent assessment of doping level along with stress and composition is possible through monitoring peak locations (as described for example in the following publication A. Perez-Rodriguez et al., Effect of stress and composition on the Raman spectra of etch - stop SiGeB layers , J. Appl. Phys. 80, 15 (1996)). The structure's properties such as composition, strain and doping, affect the optical properties of the structure. FIG. 2 shows an example for changes of optical properties with composition. Here, the real (solid lines) and imaginary (dashed lines) components of the refractive index of Si 1-x Ge x are presented for varying values of x (across the structure). Thus, the refractive index of Si 1-x Ge x (both real and imaginary components) varies as a function of the Ge concentration across the structure. During the interpretation of OCD measured data, such variations could greatly affect the interpretation sequence, and are often difficult to account for. The present invention provides a novel approach for combining the information from OCD measurements (constituting dimensional metrology information channel) and Raman spectroscopy (constituting a material and dimensional sensitive information channel). To this, end, the invention utilizes a modeling engine and algorithmic tool, to correctly interpret and hybridize the information from these two channels. The modeling engine allows calculation of both OCD spectrum as well as Raman spectrum from a given sample, and consequently can provide feedback on whether the measurements are consistent or inconsistent with some assumed set of properties (geometry, material properties) of the measured device. The associated algorithmic tool allows an efficient optimization method to identify the best set of geometrical and/or material properties, which would minimize the measurement-to-model error. According to one broad aspect of the invention, there is provided s method for use in measuring one or more characteristics of patterned structures. The method comprises: providing first and second measured data, wherein the first measured data is indicative of at least one Raman spectrum obtained from a patterned structure under measurements using at least one selected optical measurement scheme each with a predetermined configuration of at least one of illuminating and collected light conditions corresponding to said one or more characteristics to be measured; and the second measured data comprises at least one spectrum obtained from said patterned structure in Optical Critical Dimension (OCD) measurement session; processing the first measured and second measured data, and determining said one or more characteristics of the structure under measurements, wherein said processing comprises: applying model-based analysis to said at least one Raman spectrum and said at least one OCD spectrum, and determining said one or more characteristics of the patterned structure under measurements. In some embodiments, the model-based analysis includes concurrently analyzing the at least one Raman spectrum and the at least one OCD spectrum and determining the one or more characteristics of the patterned structure under measurements. Preferably, the first measured data is indicative of a number n (n>1) different Raman spectra obtained from the patterned structure under measurements using n different optical measurement schemes, respectively, with different configurations of the at least one of illuminating and collected light conditions corresponding to the one or more characteristics to be measured. In this case, the Raman and OCD spectra may also be analyzed concurrently; or alternatively, the n Raman spectra may be sequentially analyzed and a set of parameters of the patterned structure is deduced, enabling to use this set of the deduced parameters for interpreting the second measured indicative of the at least one OCD spectrum. The parameter(s) of the structure calculated from the model-based analysis of the Raman spectral data may be indicative of dimensional configuration of the structure. The characteristic(s) of the patterned structure that can be determined using this method includes: dimension and/or material composition and/or stress and/or crystallinity. The one or more predetermined configurations of the illuminating and/or collected light conditions is/are defined by selecting one or more of the following: excitation wavelength; polarization; angles of incidence; azimuth. When more than one Raman spectrum is used, the model-based analysis may include the following: for each i-th Raman spectrum, calculating distribution of Raman-contribution efficiency, RCE i (x,y,z), across at least part of the structure under measurements; analyzing one or more selected distributions of the Raman-contribution efficiency and determining a set of parameters of the patterned structure. The RCE i (x,y,z) is dependent on characteristics of the structure and the corresponding configuration of the illuminating and collected light conditions in the respective optical measurement scheme. The invention also provides a control system for use in measuring one or more characteristics of patterned structures. The control system is configured for carrying out the above method and comprises a processor unit configured to receive and process the above described first and second measured data by applying thereto model-based analysis and determining the one or more characteristics of the patterned structure under measurements. The invention further provides a measurement system for use in measuring one or more characteristics of patterned structures. The measurement system comprising: an optical measurement system configured and operable to perform optical measurements on a patterned structure using at least one selected optical measurement scheme each with a predetermined configuration of at least one of illuminating and collected light conditions corresponding to said one or more characteristics to be measured, and generating measured data indicative of spectral responses of the patterned structure comprising at least one Raman spectrum and at least one OCD spectrum; and the above-described control system configured for data communication with the optical measurement system to receive and process the measured data and determine the one or more characteristics of the patterned structure under measurements. BRIEF DESCRIPTION OF THE DRAWINGS In order to better understand the subject matter that is disclosed herein and to exemplify how it may be carried out in practice, embodiments will now be described, by way of non-limiting examples only, with reference to the accompanying drawings, in which: FIG. 1 exemplifies the Raman spectrum from two samples, one being a thin SiGe layer deposited over Si, and the other being a pure bulk Si; FIG. 2 exemplifies effect of changes in material composition across the structure on optical properties of the structure; FIG. 3 exemplifies effect of polarization on relative intensity of the single-phonon and two-phonon peaks in Si; FIG. 4 schematically illustrates the configuration and operation of an exemplary metrology scheme/system of the invention utilizing both Raman and OCD information channels; FIG. 5 is a block diagram of an exemplary system of the invention for implementing the hybrid metrology method of FIG. 4 while managing multiple optical measurement schemes; FIG. 6 is a flow diagram of an exemplary method of the invention for the hybrid metrology utilizing Raman spectroscopy and OCD; and FIG. 7 exemplifies a method suitable to be used in the invention utilizing acquisition of a multiplicity of different information Raman channels, for obtaining multiple Raman spectra from the same structure/same measurement site using different optical measurement schemes. DETAILED DESCRIPTION OF EMBODIMENTS The present invention provides a novel hybrid metrology technique which combines measurements obtained via a dimensional metrology information channel (OCD measurements) and a material and dimensional sensitive information channel (Raman spectroscopy). The present invention provides a novel metrology method and device, configured to allow optimized Raman-metrology for the sample characteristics of interest, as well as dimensional metrology using OCD, which can be implemented on a single platform, or on different platforms which would share information during the fabrication process. Also, the present invention provides a set of modeling solutions (methods and systems) to allow correct utilization of these methods and degrees of freedom in the device/system configuration, as well as accurate interpretation of the Raman measurements. The above two aspects of the invention can be used separately, with substantial potential benefit to either. Conversely, used together they can lead to significantly improved metrological performance, as will be discussed below. The following is the description of model-based hybrid metrology utilizing Raman and OCD channels, according to some embodiments of the invention. Raman spectroscopy represents a unique type of light-matter interaction. Different parts of the Raman spectrum have different responses to a change in the optical scheme, specifically: change(s) in illumination and collection polarizations\\retardations, change(s) in illumination and collection angle(s) of incidence and pupils shape, wavefronts and focus. As an example for the possible benefit from correct manipulation of one or more of these parameters, let us consider the issue of two-phonon background. As described previously, the Raman spectrum from pure bulk Si presents a sharp peak at about 520 cm −1 . An additional, very broad and significantly weaker, spectral peak is observed at 230 cm −1 -380 cm −1 . This weak Raman signal arises from a 2-phonon process. In most cases, the weak Raman signal associated with the 2-photon process is not of interest for the metrology. However, this signal acts as a background signature which can significantly affect (and confound) the interpretation of the Raman spectrum. The relative intensity between the 1-phonon peaks and the 2-phonon peak can be modified by several orders of magnitude through correct control over the illumination and collection polarizations. This dependence is illustrated in FIG. 3 , exemplifying effect of polarization on relative intensity of the single-phonon and two-phonon peaks in Si. Two graphs are shown P 1 and P 2 , where two polarization configurations are presented, i.e. illumination and collection polarizations P ill ∥P coll (graph P 1 ) and P ill ⊥P coll (graph P 2 ). As shown in the figure, when the illumination and collection polarizations P ill and P coll are tuned perpendicular to each other, and both are oriented at 45° to the crystal lattice of a sample, a 3 orders of magnitude suppression of the 2-phonon peak is observed. Thus, by aligning the illumination polarization P ill in direction 45° to the crystal structure, and aligning the collection polarization P coll perpendicular to illumination polarization, the 2-phonon signal is significantly reduced, compared to having the polarizations co-aligned. This is only one example for how correct polarization manipulation can greatly improve the signal quality and the ability to isolate important measurement components from those which are not of interest (of less interest). As will be described below, the same principle can be used to highlight sensitivity to specific parameters of interest. Such a simple approach is not practical (and even might be impossible) to be applied to a measured target which is not a planar film but rather is structured. The electromagnetic field distribution inside a structure can be very complicated, and depends on the structure dimensions as well as material characteristics. The present invention utilizes a model-based approach, such that the dependence of the Raman signal on dimensional properties can be deduced. In the invention, these two techniques allow of specific synergy, since they are both based on modeling the electromagnetic interaction with the sample and to a great extent can utilize the same calculation engines (or at least common modules of them). This realization, namely that the Raman signal by itself carries strong and unique dependence on dimensional parameters, allows for a novel type of dimensional characterization. In this approach, both Raman and OCD measurement are obtained from the same target. Then, through appropriate modeling and algorithmic tools, the inverse problem of characterizing the critical dimensions of the measured structure, as well as some of its material characteristics, is solved (by fitting procedure). In this respect, the additional Raman spectroscopy information is considered as another information channel added to the optical scatterometry channels. In this connection, reference is made to FIG. 4 , schematically illustrating the configuration and operation of an exemplary metrology scheme/system 10 of the invention utilizing both Raman and OCD information channels. As shown in the figure, first and second measured data MD 1 and MD 2 are provided comprising, respectively data indicative of one or more Raman spectra and data indicative of one or more OCD spectra. The measured data may be provided directly from respective measurement units (on line or real-time mode), and/or from external storage device(s) considering off-line mode or a combination of on-line and off-line modes. This, reference number 12 designates a measured data provider system, which may be constituted by respective measurement units and/or external storage device(s), configured for transferring measured data in any known suitable data communication technique to a control system 14 , where the measured data is processed. Generally, each of the measured data MD 1 and MD 2 may include data indicative of one corresponding spectrum. Preferably, however, at least the Raman spectral data MD 1 includes a set of at least two different spectra obtained with different optical scheme configurations, defined by different condition(s) of illuminating and/or collecting light. Such conditions include one or more of the following: different wavelengths, polarization configurations, angles of incidence, azimuths, etc. The control system 14 is generally a computer system configured for communication with measured data provider 12 ; and may also be configured for managing/controlling the measurements with different measurement schemes, as will be described more specifically further below. As shown in the present non-limiting example, the control system 14 includes a modelling utility 16 storing “theoretical” data about the structure under measurements, namely various parameters (dimensions, material compositions) of an ‘assumed’ structure configuration; and processor utility 20 . The latter includes modelling modules 18 configured and operable to calculate theoretical Raman spectral data TD 1 and theoretical OCD spectral data TD 2 for a given assumed structure configuration; a comparison module 20 ; and a parameter calculator module 22 . The comparison module 20 is configured and operable for combining information from OCD and Raman spectroscopy in the measured data MD 1 and MD 2 and comparing these data with the theoretical data TD 1 and TD 2 , and appropriately operating the modeling utility 16 and the modules 18 to vary the assumed structure parameters and recalculate the corresponding theoretical data to find the best fit condition; and a parameter calculator 22 that calculates the measured structure parameter(s) from the best fit modelled (theoretical) data. Thus, a corresponding set of calculated (theoretical) spectra is obtained, for some assumed structure. An algorithmic optimization tool is used to vary the properties of the modeled structure, until agreement is obtained between the calculated and measured spectra. FIG. 5 illustrates, by way of a block diagram of a system 100 of the invention for use in measuring on pattered structures using the hybrid metrology. System 100 includes a control system 146 which is configured to receive and process input measured data MD 1 indicative of multiple (generally at least two) Raman spectra measured on at least a part of a sample 105 using two or more measurement schemes implemented in an optical system; and receive and process input measured OCD data MD 2 indicative of OCD spectrum measured on at least a part of the sample 105 using a certain measurement scheme. In this example, the control system 114 is shown as being operable in on-line mode with respect to at least one of the Raman and OCD measurements, and is also configured for operating the optical measurement system(s) to controllably vary the measurements schemes to obtain said two or more Raman spectra corresponding to different condition(s) of illuminating and/or collected light. To this end, the control system 114 in addition to the above described control unit 14 includes an illumination controller 106 A and/or a collection controller 106 B. The optical system includes a light source system 102 defining an illumination channel IC, and a detection system 104 defining a collection channel CC, and also includes a light affecting unit located in/associated with at least one of the illumination and collection channels. In this non limiting example, the system includes both a light illumination affecting unit 106 and a light collection affecting unit 108 . The Illumination and collection affecting units are configured for affecting illumination and collection conditions. Such unit may include light propagation affecting optics for affecting the condition of light propagating along the respective channel. The illumination affecting unit 108 may include (e.g. in addition to the light propagation affecting optics) a controller for controlling operation of a light source system; alternatively or additionally such controller may be part of the control system 114 . It should be understood that partially the same optical system may be shifted between Raman and OCD operational modes, or may be concurrently operated in both modes, or separate optical systems may be used. The illumination controller 106 A is associated with the illumination affecting unit 108 and/or light source system 102 . The collection controller 106 B is associated with the collection affecting unit 110 . While it is often useful to have the same metrology target used for both measurement technologies (Raman and OCD), it could be beneficial to have separate test sites dedicated for each method. As these sites could share some important attributes (e.g. material composition, thicknesses) but have different other properties (e.g. line widths, pattern structure), the metrology could be greatly simplified on the one hand, but still allow fusion of the information from the different sites. Several variations and modifications are possible for the above-described approach of the invention. For example, the use of the strengths and weaknesses of the combined technologies may be optimized. To this end, the comparison engine 20 used to combine information from OCD and Raman spectroscopy does not necessarily have to treat their respective information equivalently. For example, it is possible to use the Raman spectrum data, preferably using multiple different measurement schemes (i.e. different from one another in the illumination and/or light collection conditions) to obtain accurate information on material compositions, from which optical parameters (n and k) can be deduced via known relations (as shown in FIG. 2 ). Then, these optical parameters can be used in the OCD data analysis, as inputs to the calculation core, leading to significant improvement in the OCD performance. Generally, it is often the case that some properties of the sample can be characterized well by one of the Raman and OCD technologies, other characteristics are better obtained through the other of these technologies, and some can benefit from both technologies. In this case, a multi-step analysis can be implemented, according to which each technology is first used in order to identify the parameter(s) which it can address by itself, and then the deduce characteristics as well as the combined information from both measured datasets is used to obtain the remaining parameters. The use of a multitude of information channels leads to a plethora of possible channel configurations and combinations. Both the OCD and Raman channels can provide different information about the measured sample by using different measurement configurations, e.g. different polarization configurations (for both illumination and collection channels), controlling illumination and collection angles of incidence, sample azimuth, wavelengths etc. A dedicated methodology, possibly supported by a suitable algorithmic solution, is needed to choose the best combination of Raman and OCD channels. In this methodology, the respective sensitivities of each channel to the parameters of interest, correlations between sensitivities to different parameters as well as optical system configuration and productivity considerations (e.g. throughput, possible sample damage, etc.) can be taken into account. The above is illustrated, in a self-explanatory manner in FIG. 6 showing a flow diagram of an exemplary method of the invention for the hybrid metrology utilizing Raman spectroscopy and OCD. In this example, one or more parameters P 1 of the structure being measured is/are calculated from model-and-fitting analysis of Raman measured data MD 1 , preferably including multiple Raman spectra obtained using different measurement schemes, and the parameter(s) P 1 is/are used for optimizing the OCD model (theoretical data TD 2 ); and the OCD measured data MD 1 from the same structure (e.g. in the same measurement site or not) undergoes model-and-fitting analysis (e.g. using OCD theoretical data TD 2 optimized with parameter P 1 ), and one or more other structure parameters P 1 is/are calculated, which may be used for further optimizing the Raman theoretical data TD 1 . Reference is made to FIG. 7 showing a flow diagram 200 of an exemplary method suitable to be used in the invention utilizing acquisition of a multiplicity of different information Raman channels, for obtaining multiple Raman spectra from the same structure/same measurement site using different optical measurement schemes. First, according to this method a ‘Raman-contribution efficiency’ (RCE) is defined as specifying the position-dependent contribution to the Raman signal. This property depends on the measured structure characteristics (dimensions, materials), the excitation wavelength and the characteristics of the illumination and collection channels (as will be described below). To clarify, the RCE represents the spatial distribution of the contribution to the Raman signal. It depends on the coupling of electromagnetic radiation into the structure, the excitation of the Raman signal inside the structure and coupling of the excited radiation to the detection system. Raman-contribution efficiency for a measured structure is calculated (step 212 ). This calculation may be assisted (step 214 ) by information about the structure obtained/measured from other metrology tools and/or test sites, e.g. OCD\\SEM\\TEM to provide dimensional characterization, ellipsometry for material characterization, etc. Data about a variety of n measurement conditions is provided (step 216 ), and the Raman-contribution efficiency distributions across the structure RCE 1 (x,y,z), RCE 2 (x,y,z), . . . . RCE n (x,y,z) are calculated for the n measurement conditions, respectively, typically illumination/collection conditions. These may include different angles of incidence (AOIs), wavelengths, polarizations, pupil shaping options, etc. Each different i-th configuration provides a different distribution of the RCE i (x,y,z) across the structure. Then, a subset of the calculated configurations, RCE n-j -RCE n-k , where j and k are integers, j≥k, is chosen (step 218 ), so as to gain information on the measured parameter distribution across the structure. Deriving the parameter distribution inside the structure from the set of measurement (step 220 ) can be accomplished using standard algorithms (e.g. deconvolution methods). As an example, a simple approach to implement such derivation can be based on a linear scheme: a set of measured Raman intensities I i is collected. Each is known to be related to the parameter distribution inside the structure through its RCE, namely: l i =∫RCE i ( x,y ) P ( x,y ) dxdy. By defining some spatial sampling of the measured structure, this relation can be written in matrix form: l i =M i,j P j or equivalently {right arrow over (I)}={acute over (M)}{right arrow over (P)}. Here, the index j relates to different spatial locations and the index i relates to a different measurement. As both I and M are known (through the measurement and the modeling engine correspondingly), the spatial distribution of the parameter can be directly obtained using RMS solution: {right arrow over (P)}={acute over (M)} −1 {right arrow over (I)}. Many other algorithmic methods are available, allowing more stable and well-controlled solutions. This methodology can be applied to any measurable property, such as stress, composition, crystallinity, which are just a few non-limiting examples. One capability of unique interest allowed by adding modeling capabilities to Raman spectroscopy is dimensional metrology. Indeed, such capabilities require a multifaceted modeling tool/methods, involving both comprehensive characterization of the electromagnetic field penetration into and out of the structure, as well as modeling of the Raman signal creation inside the structure. Such a path can provide highly sensitive information on the measured structure. Evidence that dimensional factors affect the measured Raman signal are known in the literature, for example from the following publications: A. K. Arora et al., Raman spectroscopy of optical phonon confinement in nanostructured materials , J. of Raman Spectroscopy 38, 604 (2007); B. Kaleli et al., Strain characterization of FinFETs using Raman spectroscopy , Thin Solid Films 31497 (2013); T. Nuytten et al., Edge - enhanced Raman scattering in narrow sGe fin field - effect transistor channels , App. Phys. Lett. 106, 033107 (2015). On specific cases (e.g. nanowires), the Raman signal has been found to provide dimensional information on a dimensional characteristic of the structure (e.g. nanowire diameter [J. Liu et al., Raman spectrum of array - ordered crystalline silicon nanowires , Physica E 23, 221 (2004); R. P. Wang et al., Raman spectral study of silicon nanowires: High - order scattering and phonon confinement effects , Phys. Rev. B 61, 16827 (2000)]). However, through general modeling capabilities, akin to that utilized in OCD metrology, a similar methodology to OCD can be used to solve the inverse-problem of deducing the dimensional properties from the measurements. In this method, the measured signal is compared to that calculated from the modeling tool, for some assumed properties (dimensions, materials) of the test structure. When good fit is obtained between the measured and calculated signal, it is deduced that the measured structure has similar characteristics to the corresponding calculated one. Similarly to common practice in OCD metrology, the theoretical Raman signals can be calculated in real-time (‘real-time regression’) or pre-calculated to form a parameter-dependent ‘library’ of theoretical spectra. Such analysis of the Raman spectrum can be used in conjunction with other metrology methods (e.g. OCD), to break correlation between parameters and improve sensitivity.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"121-055-026-410-936","jurisdiction":"US","doc_number":"12364450","kind":"B2","date_published":"2025-07-22","doc_key":"US_12364450_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12364450","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"17739229","date":"2022-05-09"},"priority_claims":{},"invention_title":[{"text":"Portable x-ray detector holder and positioner","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"2884","extracted_name":{"value":"David J Makiya"}},"assistant_examiner":{"extracted_name":{"value":"Soorena Kefayati"}}},"applicants":[{"residence":"US","extracted_name":{"value":"Ryan Sotkovsky"},"extracted_address":"Port St. Lucie, FL"}],"inventors":[{"residence":"US","sequence":1,"extracted_name":{"value":"Ryan Sotkovsky"},"extracted_address":"Port St. Lucie, FL"}],"agents":[{"extracted_name":{"value":"The Rapacke Law Group, P.A."}}]},"classifications_ipcr":{"classifications":[{"symbol":"A61B6/00","classification_value":"I","classification_symbol_position":"F"},{"symbol":"A61B6/42","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"A61B6/4429","classification_value":"I","classification_symbol_position":"F"},{"symbol":"A61B6/42","classification_value":"I","classification_symbol_position":"L"},{"symbol":"A61B6/4405","classification_value":"I","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"5533090","kind":"A","date":"1996-07-01"},"lens_id":"044-610-708-279-401"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"5799917","kind":"A","date":"1998-09-01"},"lens_id":"106-265-394-810-732"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"6554472","kind":"B1","date":"2003-04-01"},"lens_id":"009-790-274-919-935"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"9256911","kind":"B1","date":"2016-02-01"},"lens_id":"095-061-417-030-447"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"9706843","kind":"B2","date":"2017-07-01"},"lens_id":"076-041-352-863-239"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2004/0079849","kind":"A1","date":"2004-04-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2013/0193295","kind":"A1","date":"2013-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0030135","kind":"A1","date":"2015-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0085991","kind":"A1","date":"2015-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0055465","kind":"A1","date":"2018-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0200944","kind":"A1","date":"2019-07-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2020/0155089","kind":"A1","date":"2020-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2022/0054099","kind":"A1","date":"2022-02-01"}}}],"patent_count":13},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12364450","kind":"B2","date":"2025-07-22"},"lens_id":"121-055-026-410-936"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12364450","kind":"B2","date":"2025-07-22"},"lens_id":"121-055-026-410-936"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"Disclosed are devices and methods for facilitating the obtaining of radiologic images. Some embodiments of the disclosed devices are directed to a portable x-ray holder and positioner having a base, an arm coupled to the base, and an x-ray holding mechanism coupled to the arm. In certain embodiments, the arm is configured to be rotatable and extendable. In one embodiment, the device includes a hinge coupled to the base and/or to the arm. In some embodiments, the x-ray holding mechanism includes one or more brackets coupled to the arm. In certain embodiments, the arm has a first part configured to receive a second part within the first part, and the second part is configured to be telescoped out of the first part. In one embodiment, a fastening mechanism is provided that cooperates with the hinge and the arm to maintain a desired angular position of the arm.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A portable x-ray detector holder and positioner comprising: a base plate; a hinge coupled to the base plate; a base arm coupled to the hinge; a fastening mechanism for facilitating an angular adjustment of the base arm relative to the base, wherein the fastening mechanism for facilitating an angular adjustment of the base arm is coupled to the base arm and/or to the hinge; an extending arm configured to be received in the base arm and to be telescoped out of the base arm; a fastening mechanism for facilitating a length adjustment of the extending arm relative to the base arm, wherein the fastening mechanism for facilitating a length adjustment of the extending arm relative to the base arm is coupled to the base arm and/or to the extending arm; and an x-ray detector holding mechanism coupled to the base arm and/or to the extending arm for holding an x-ray detector."]},{"claim_text":["2. The modular portable x-ray detector holder and positioner of claim 1 , wherein the fastening mechanism for facilitating an angular adjustment comprises a screw."]},{"claim_text":["3. The portable x-ray detector holder and positioner of claim 1 , wherein the x-ray detector holding mechanism comprises one or more brackets coupled to the base arm and/or to the extending arm."]},{"claim_text":["4. The modular portable x-ray detector holder and positioner of claim 2 , wherein the screw is selectively tightened or loosened to adjust a position of the base arm."]},{"claim_text":["5. A method of obtaining radiologic images, the method comprising: providing an x-ray detector holder and positioner, the x-ray detector holder and positioner comprising: a base; a rotatable and extendable arm coupled to the base; and an x-ray detector holding mechanism coupled to said arm, wherein the x-ray detector holding mechanism comprises a fastening mechanism for facilitating a length adjustment of the extending arm relative to the base arm, wherein the fastening mechanism for facilitating a length adjustment of the extending arm relative to the base arm is coupled to the base arm and/or to the extending arm; adjusting an angle of said arm to a desired angle; adjusting a length of said arm to a desired length; attaching an x-ray detector to said x-ray detector holding mechanism; and positioning the x-ray detector holder and positioner relative to a patient to facilitate obtaining the radiologic images."]},{"claim_text":["6. The method of claim 5 , wherein the x-ray detector holder and positioner further comprises a hinge coupled to said arm."]},{"claim_text":["7. The method of claim 5 , wherein the x-ray detector holding mechanism comprises at least one bracket coupled to said arm."]},{"claim_text":["8. The method of claim 5 , wherein said arm comprises a first structure configured to receive a second structure, and wherein the second structure is configured to be telescoped out of the first structure."]}],"lang":"en"}],"description":{"text":"CROSS-REFERENCE TO RELATED APPLICATIONS The present application claims priority to U.S. Provisional Patent Application No. 63/185,408 filed May 7, 2021, entitled “PORTABLE X-RAY DETECTOR HOLER AND POSITIONER,” which is hereby incorporated by reference in its entirety. TECHNICAL FIELD Embodiments of the invention relate generally to devices and methods for facilitating the obtaining of radiologic images. In particular, embodiments of the invention are directed to devices and methods for holding and positioning an x-ray detector at a desired position to improve patient comfort and increase the efficiency of obtaining radiologic images. In some embodiments, the invention is most particularly directed to a portable x-ray detector holder and positioner having a rotatable and extendable arm. BACKGROUND Current x-ray detector holders tend to be bulky, heavy, and only hold the x-ray detector in only one position at a 90-degree angle. Technicians are allowed to use only these holders in the x-ray room, and it is not feasible to take such holders on portables due to their size, weight, and the inability to adjust the angle of the x-ray detector. Another method technicians currently use, especially during portable exams, is to wedge towels, sheets, blankets, and pillows underneath the x-ray detector to get the desired position angle to make the patient comfortable and allow the technician to perform the exam. Alternate known methods include a stationary x-ray detector holder. This apparatus is heavy, bulky, and only positions the x-ray detector at a 90-degree angle. This method and device are limited because the device is only used inside the x-ray room to perform cross-table lateral positions in lower extremity trauma patient situations. Another alternative is to prop folded up sheets, blankets, towels, pillows, or the like, behind or underneath the x-ray detector to obtain a position (including angle) that is comfortable for the patient. This method is limited because the x-ray detector is not supported in the same position and allows the x-ray detector to shift while taking the images, which cause repeats, more exposure to the patient, and a longer exam time. SUMMARY OF THE INVENTION In one embodiment, the invention concerns a portable x-ray detector holder and positioner. The x-ray detector holder and positioner can include a base plate; a hinge coupled to the base plate; a base arm coupled to the hinge; a fastening mechanism for facilitating an angular adjustment of the base arm relative to the base, wherein the fastening mechanism is coupled to the base arm and/or to the hinge; an extending arm configured to be received in the base arm and to be telescoped out of the base arm; a fastening mechanism for facilitating a length adjustment of the extending arm relative to the base arm, wherein the fastening mechanism is coupled to the base arm and/or to the extending arm; and an x-ray detector holding mechanism coupled to the base arm and/or to the extending arm for holding an x-ray detector. In some embodiments, the fastening mechanism for facilitating an angular adjustment comprises a screw, and the fastening mechanism for facilitating a length adjustment comprises a screw. In certain embodiments, the x-ray detector holding mechanism comprises one or more brackets coupled to the base arm and/or to the extending arm. In another aspect, the invention is directed to a method of obtaining radiologic images. In one embodiment the method involves providing an x-ray detector holder and positioner. The x-ray detector holder and positioner can include a base; a rotatable and extendable arm coupled to the base; and an x-ray detector holding mechanism coupled to the arm. The method can further involve adjusting an angle of the arm to a desired angle; adjusting a length of the arm to a desired length; attaching an x-ray detector to the x-ray detector holding mechanism; and positioning the x-ray detector holder and positioner relative to a patient to facilitate obtaining the radiologic image. In certain embodiment, the x-ray detector holder and positioner of the method further comprises a hinge and at least one bracket coupled to the arm. In some embodiments, the arm of the method comprises a first structure configured to receive a second structure, wherein the second structure is configured to be telescoped out of the first structure. Additional features and advantages of the embodiments disclosed herein will be set forth in the detailed description that follows, and in part will be clear to those skilled in the art from that description or recognized by practicing the embodiments described herein, including the detailed description which follows, the claims, as well as the appended drawings. Both the foregoing general description and the following detailed description present embodiments intended to provide an overview or framework for understanding the nature and character of the embodiments disclosed herein. The accompanying drawings are included to provide further understanding and are incorporated into and constitute a part of this specification. The drawings illustrate various embodiments of the disclosure, and together with the description explain the principles and operations thereof. BRIEF DESCRIPTION OF THE DRAWINGS A more complete understanding of the embodiments, and the attendant advantages and features thereof, will be more readily understood by references to the following detailed description when considered in conjunction with the accompanying drawings wherein: FIG. 1 illustrates a perspective view of an x-ray detector holder in accordance with one embodiment of the invention. FIG. 2 illustrates a perspective view of the holder of FIG. 1 , according to some embodiments; FIG. 3 illustrates a perspective view of the holder of FIG. 1 , according to some embodiments; FIG. 4 illustrates a perspective view of the holder of FIG. 1 , according to some embodiments; FIG. 5 illustrates a detail view of the pivot of the holder, according to some embodiments; FIG. 6 illustrates a detail view of the pivot of the holder, according to some embodiments; FIG. 7 illustrates a perspective view of the holder, according to some embodiments; FIG. 8 illustrates a perspective view of the holder, according to some embodiments; FIG. 9 illustrates a perspective view of the holder, according to some embodiments; and FIG. 10 illustrates a perspective view of the holder, according to some embodiments. DETAILED DESCRIPTION The specific details of the single embodiment or variety of embodiments described herein are set forth in this application. Any specific details of the embodiments are used for demonstration purposes only, and no unnecessary limitation or inferences are to be understood therefrom. Before describing in detail exemplary embodiments, it is noted that the embodiments reside primarily in combinations of components related to the system. Accordingly, the device components have been represented where appropriate by conventional symbols in the drawings, showing only those specific details that are pertinent to understanding the embodiments of the present disclosure so as not to obscure the disclosure with details that will be readily apparent to those of ordinary skill in the art having the benefit of the description herein. In some embodiments, the invention is directed to an x-ray detector holder and positioner that facilitates adjusting the angle and position of the x-ray detector. Known x-ray detector holders are typically stationary and hold the x-ray detector only at a 90-degree angle. Disclosed embodiments of the invention facilitate adjusting the angle of the x-ray detector at least from 0- to 90-degrees. In certain embodiments, the x-ray detector holder and positioner has an advantageous size and portability. Known x-ray detector holders are large, heavy, and awkward in shape, which limits where an x-ray detector holder can be used and/or stored. Inventive embodiments of the x-ray detector holder and positioner disclosed here are lightweight and ergonomically designed so that that the x-ray detector holder and positioner can be transported and used in a variety of locations or settings (for example, x-ray room, portable machine, trauma, and the like). Some embodiments of the x-ray detector holder and positioner disclosed herein are convenient to store when not in use, leaving room for other equipment. Embodiments of the invention provide various advantages over known methods. Some embodiments of the invention are lightweight and therefore easier to carry than current x-ray detector holders. Certain embodiments of the invention are ergonomic and enable the technician to easily store the x-ray holder and positioner, whether on a portable machine or in an x-ray room. Advantageously, certain embodiments of invention disclosed herein facilitate adjusting the angle of the x-ray detector, thereby facilitating improving the comfort of the patient and allowing the technician to perform the exam more efficiently. The more comfortable the patient is, the more likely that the technician will obtain clear and sharp images for a physician to read, thereby improving the patient's care and diagnosis. In one embodiment, the x-ray detector holder and positioner can be used in various imaging settings, such as a hospital, outpatient center, urgent care, orthopedic offices, and more. In some embodiments, the invention is directed to a durable, lightweight x-ray holder and positioner to assist radiologic technicians and patients during exams. In some embodiments, the x-ray holder and positioner is configured to hold an x-ray detector at a specific place and angle to improve the comfort of a patient and to enable the technician to more easily position the patient and to more efficiently perform an exam. In some embodiments, the x-ray holder and positioner is configured to be ergonomic and lightweight to use in the x-ray room, on portables, and in trauma exams. In certain embodiments, the x-ray holder and positioner is configured to provide a steady foundation, so the x-ray detector remains in position throughout the exam; and the x-ray detector holder and positioner enables the technician to adjust the angle of the x-ray detector's position to assist the patient in maintaining proper radiographic positioning and to facilitate a more efficient exam for the technician. Referencing FIG. 1 , in one embodiment x-ray holder and positioner 100 includes base 105 . In some embodiments, base 105 is rectangular and measures approximately 11-in by 16-in. In certain embodiments, x-ray holder and positioner 100 includes hinge 110 , coupled to base 105 , for supporting and positioning angularly moveable arm 115 A, 115 B. In one embodiment a fastening mechanism such as hinge screw 120 is coupled to hinge 110 and/or to arm 115 A, 115 B to facilitate setting and maintaining a desired angle of arm 115 A, 115 B. In certain embodiments, arm 115 A, 115 B, hinge 110 , and hinge screw 120 are configured to enable adjusting the angle of arm 115 A, 115 B through a range of at least 0-degrees (see FIG. 2 ) to 90-degrees (see FIG. 4 ) relative to base 105 . In one embodiment, arm 115 A, 115 B is an extendable structure having base arm 115 A and extending arm 115 B. In some embodiments, both base arm 115 A and extending arm 115 B can be about 10-in long; however, in certain embodiments base arm 115 A can have a length that is different from the length of extending arm 115 B. In certain embodiments, base arm 115 A is configured to receive within extending arm 115 B, such that extending arm 115 B substantially fits completely within base arm 115 A and can be telescoped out of base arm 115 A a length substantially as long as the length of extending arm 115 B. In some embodiments, there are multiples of extending arm 115 B that are coupled to one another to provide any suitable extension desired for the task of obtaining radiologic images. In certain embodiments, base arm 115 A and extending arm 115 B are structures that can be coupled to each other at varying lengths, without extending arm 115 B being necessarily received within base arm 115 A. In some embodiments, a fastening mechanism such as arm screw 125 can be provided to secure extending arm 115 B to base arm 115 A to hold extending arm 115 B at a desired length while in use. In one embodiment, one end of base arm 115 A is provided with bracket 130 A and one end of arm 115 B is provided with bracket 130 B for holding an x-ray detector (not shown) in place while in use. X-ray holder and positioner 100 enables improving the comfort of the patient and improving the performance efficiency of the technician. To use the x-ray holder and positioner 100 , the x-ray detector is placed within brackets 130 A, 130 B. Depending on the desired location of the x-ray detector, extending arm 115 B is adjusted to a desired length, then arm screw 125 is tightened to hold the x-ray detector in place. Next, the angle of arm 115 A, 115 B is adjusted until the x-ray detector is in a position where the patient is comfortable, and the technician can perform the exam efficiently. Hinge screw 120 is tightened to hold the angle of the x-ray detector in place. As illustrated in FIG. 1 , x-ray holder and positioner 100 can have an angular position of, for example, about 45-degrees and an extension of the full length of base arm 115 A and the full length of extending arm 115 B. After the exam has been completed, the angle and length of arm 115 A, 115 B are adjusted to the resting position (see FIG. 2 , 0-degrees and no extension of extending arm 115 B) of arm 115 A, 115 B and conveniently stored, for example, on the portable x-ray machine or in the x-ray room. Referencing FIG. 2 to FIG. 4 use of x-ray holder and positioner 100 is illustrated. As shown in FIG. 2 , x-ray holder and positioner 100 can have a first configuration, or resting position, wherein X-ray holder and positioner 100 is at an angle of substantially 0-degrees relative to base 105 and extending arm 115 B is substantially entirely enclosed along the length of extending arm 115 B by base arm 115 A. Usually in this configuration x-ray holder and positioner 100 is stored and/or transported. Referencing FIG. 3 , x-ray holder and positioner 100 is illustrated in another possible angular position of arm 115 A, 115 B. As shown, base arm 115 A is at an angle of about 30- to 40-degrees relative to base 105 . In the position illustrated, extending arm 115 B remains substantially completely within base arm 115 A; hence, arm 115 A, 115 B has no substantial extension beyond the length of base arm 115 A. Referencing FIG. 4 , x-ray holder and positioner 100 is illustrated in another possible angular position and extension of arm 115 A, 115 B. As shown, base arm 115 A is at an angle of substantially 90-degrees relative to base 105 . In the position illustrated, extending arm 115 B has been telescoped substantially completely out of base arm 115 A; hence, arm 115 A, 115 B has substantially its full extension. As illustrated in FIG. 1 through FIG. 4 , x-ray holder and positioner 100 is configured to facilitate the placement of an x-ray detector at a desired angle and at a variable distance relative to base 105 . Consequently, x-ray holder and positioner 100 improves both patient comfort and efficiency of obtaining radiologic images. As illustrated and described x-ray holder and positioner 100 can be positioned at any angle of, for example, between 0-degrees and 90-degrees, and the length of rotatable and extendable arm 115 A, 115 B can be extended to multiples of any suitable length for the task of obtaining radiologic images. FIGS. 5-10 illustrates a second embodiment of the x-ray holder and positioner 100 which includes a first extending arm 500 and a second extending arm 501 extending in parallel from one another and having a mountable surface 503 secured to each of the first extending arm 500 and the second extending arm 501 . The embodiment illustrated in FIGS. 5-10 provide similar benefits as the embodiment illustrated in FIGS. 1-4 while providing additional support for the x-ray holder and positioner 100 by adding a second extending arm 501 . FIG. 5 and FIG. 6 illustrate a detail view of the hinge 110 illustrated in a second embodiments. of the x-ray holder and positioner 100 . The hinge 110 is positioned between the base 105 and the first extending arm 500 and second extending arm 501 to allow them to hinge between 0° and 90° with reference to the base 105 . A rotatable mount 505 allows for the first extending arm 500 and second extending arm 501 , as well as the mounting surface 503 to rotate 360° such that the user can suitably position the x-ray detector as needed throughout use or for convenient storage. FIG. 7 and FIG. 8 illustrate a rear side 700 perspective view of the x-ray holder and positioner 100 . In specific reference to FIG. 7 , the mounting surface 503 interfaces with a retainer 701 to maintain the x-ray detector in a suitable position during use and/or during storage. The first extending arm 500 and the second extending arm 501 each include and extension assembly 703 A, 703 B which allow the arms to extend as needed. FIG. 9 and FIG. 10 illustrate a front side 900 perspective view of the x-ray holder and positioner 100 . The mountable surface 503 is a component of an x-ray detector holding mechanism 905 coupled to each of the first ending arm 500 and the second extending arm 501 . The mountable surface 503 retains the x-ray detector in a suitable positioned via a first pin 901 A and a second pin 901 B. A top retainer 903 may be extended or retracted to maintain the x-ray detector in a suitable position during use. Many different embodiments have been disclosed herein, in connection with the above description and the drawings. It will be understood that it would be unduly repetitious and obfuscating to literally describe and illustrate every combination and subcombination of these embodiments. Accordingly, all embodiments can be combined in any way and/or combination, and the present specification, including the drawings, shall be construed to constitute a complete written description of all combinations and subcombinations of the embodiments described herein, and of the manner and process of making and using them, and shall support claims to any such combination or subcombination. It will be appreciated by persons skilled in the art that the present embodiment is not limited to what has been particularly shown and described hereinabove. A variety of modifications and variations are possible in light of the above teachings without departing from the following claims.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"048-557-547-160-017","jurisdiction":"US","doc_number":"12366899","kind":"B2","date_published":"2025-07-22","doc_key":"US_12366899_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12366899","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"17484145","date":"2021-09-24"},"priority_claims":{},"invention_title":[{"text":"Transmission line embedded in a portion of a chassis of an electronic device","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"2841","extracted_name":{"value":"Anthony M Haughton"}},"assistant_examiner":{"extracted_name":{"value":"Theron S Milliser"}}},"applicants":[{"residence":"US","extracted_name":{"value":"Intel Corporation"},"extracted_address":"Santa Clara, CA"}],"inventors":[{"residence":"IN","sequence":1,"extracted_name":{"value":"Santhosh Ap"},"extracted_address":"Karnataka"},{"residence":"IN","sequence":2,"extracted_name":{"value":"Madhurkiran Sreenivasa Reddy"},"extracted_address":"Bangalore"},{"residence":"IN","sequence":3,"extracted_name":{"value":"Prakash Kurma Raju"},"extracted_address":"Bangalore"},{"residence":"IN","sequence":4,"extracted_name":{"value":"Prasanna Pichumani"},"extracted_address":"Bangalore"},{"residence":"IN","sequence":5,"extracted_name":{"value":"Vamshi Krishna Aagiru"},"extracted_address":"Bangalore"},{"residence":"IN","sequence":6,"extracted_name":{"value":"Nithesha Ananda"},"extracted_address":"Kamataka"}],"agents":[{"extracted_name":{"value":"Banner & Witcoff Ltd."}}]},"classifications_ipcr":{"classifications":[{"symbol":"G06F1/16","classification_value":"I","classification_symbol_position":"F"},{"symbol":"H05K1/02","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"G06F1/1683","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G06F1/1656","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H05K1/0243","classification_value":"I","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"8571598","kind":"B2","date":"2013-10-01"},"lens_id":"140-800-107-520-084"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"10854957","kind":"B2","date":"2020-12-01"},"lens_id":"127-421-417-621-365"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"11600904","kind":"B2","date":"2023-03-01"},"lens_id":"146-088-987-804-959"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"11983048","kind":"B2","date":"2024-05-01"},"lens_id":"002-331-767-036-703"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"12046801","kind":"B2","date":"2024-07-01"},"lens_id":"102-130-443-628-715"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"12149007","kind":"B2","date":"2024-11-01"},"lens_id":"144-993-543-824-059"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2008/0146265","kind":"A1","date":"2008-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2020/0266520","kind":"A1","date":"2020-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2021/0083366","kind":"A1","date":"2021-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2022/0026962","kind":"A1","date":"2022-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2023/0015184","kind":"A1","date":"2023-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2023/0018781","kind":"A1","date":"2023-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2023/0238685","kind":"A1","date":"2023-07-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2024/0079782","kind":"A1","date":"2024-03-01"}}}],"patent_count":14},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12366899","kind":"B2","date":"2025-07-22"},"lens_id":"048-557-547-160-017"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12366899","kind":"B2","date":"2025-07-22"},"lens_id":"048-557-547-160-017"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"Particular embodiments described herein provide for an electronic device that can be configured to include a substrate, a keyboard, and a chassis, where a portion of the chassis is between the substrate and the keyboard. A transmission line is embedded in the portion of the chassis between the substrate and the keyboard. In some examples, the portion of the chassis between the substrate and the keyboard that includes the transmission line is a support plate for the keyboard.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A mobile computing device configured for radio frequency communication, the mobile computing device comprising: a substrate; memory on the substrate; one or more processors on the substrate; a keyboard; a chassis, wherein a portion of the chassis is between the substrate and the keyboard; and a transmission line embedded in the portion of the chassis between the substrate and the keyboard."]},{"claim_text":["2. The mobile computing device of claim 1 , wherein the portion of the chassis between the substrate and the keyboard is a support plate for the keyboard."]},{"claim_text":["3. The mobile computing device of claim 1 , further comprising: a first air gap between the transmission line and the keyboard; and a second air gap between the transmission line and the substrate."]},{"claim_text":["4. The mobile computing device of claim 3 , wherein the first air gap and the second air gap are a dielectric for radio frequency waves emitted from the transmission line."]},{"claim_text":["5. The mobile computing device of claim 1 , further comprising: a heat spreader between the transmission line and the keyboard."]},{"claim_text":["6. The mobile computing device of claim 5 , wherein the heat spreader and substrate are grounded and create an electromagnetic interference shield."]},{"claim_text":["7. The mobile computing device of claim 1 , wherein the radio frequency communication is WiFi."]},{"claim_text":["8. The mobile computing device of claim 1 , wherein the transmission line is a strip line."]},{"claim_text":["9. An electronic device comprising: a substrate; memory on the substrate; one or more processors on the substrate; a keyboard; a chassis, wherein a portion of the chassis is between the substrate and the keyboard; a transmission line embedded in the portion of the chassis between the substrate and the keyboard; and one or more antennas."]},{"claim_text":["10. The electronic device of claim 9 , wherein the transmission line is a wireless communication transmission line."]},{"claim_text":["11. The electronic device of claim 9 , wherein the portion of the chassis between the substrate and the keyboard is a support plate for the keyboard."]},{"claim_text":["12. The electronic device of claim 9 , further comprising: a first dielectric; and a second dielectric, wherein the transmission line is between the first dielectric and the second dielectric."]},{"claim_text":["13. The electronic device of claim 9 , further comprising: a first air gap between the transmission line and the keyboard; and a second air gap between the transmission line and the substrate."]},{"claim_text":["14. The electronic device of claim 9 , further comprising: a plurality of transmission line supports coupled to the portion of the chassis between the substrate and the keyboard to support the transmission line."]},{"claim_text":["15. The electronic device of claim 14 , wherein the plurality of transmission line supports are comprised of non-conductive material."]},{"claim_text":["16. The electronic device of claim 9 , wherein the transmission line is a strip line."]},{"claim_text":["17. The electronic device of claim 9 , further comprising: transmission line coupling pads to couple the transmission line to the antenna and a wireless communication engine."]},{"claim_text":["18. A method, comprising: providing a substrate, memory on the substrate, and one or more processors on the substrate; removing at least a portion of an area of a chassis where a dielectric above and below the area can be created or already exists; adding a support structure for a transmission line to the portion of the area of the chassis that was removed; and securing the transmission line to the support structure."]},{"claim_text":["19. The method of claim 18 , further comprising: coupling the transmission line to a wireless communication engine; and coupling the transmission line to one or more antenna."]},{"claim_text":["20. The method of claim 18 , wherein the transmission line is a strip line."]}],"lang":"en"}],"description":{"text":"TECHNICAL FIELD This disclosure relates in general to the field of computing, and more particularly, to a transmission line embedded in a portion of a chassis of an electronic device. BACKGROUND Emerging trends in systems place increasing performance demands on the system. One way to attempt to improve performance and function is to increase the density of the devices and systems and pack more computing elements into the devices and systems. The increasing performance demands can create a relatively crowded system as more and more components are located in close proximity to each. One particular component is the communication cable for wireless systems. If the cable has a small diameter in an attempt to reduce the Z-height of the system, increased insertion loss can occur resulting is the need for a higher transmit power that can cause radiating noise level increases in the system. If the cable has a relatively large diameter, then the system Z-height can be negatively impacted. The term “Z-height,” “Z location,” etc. refers to the height along the “Z” axis of an (x, y, z) coordinate axis or cartesian coordinate system. BRIEF DESCRIPTION OF THE DRAWINGS To provide a more complete understanding of the present disclosure and features and advantages thereof, reference is made to the following description, taken in conjunction with the accompanying figures, wherein like reference numerals represent like parts, in which: FIG. 1 is a simplified block diagram of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 2 is a simplified block diagram of a portion of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 3 is a simplified block diagram of a portion of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 4 is a simplified block diagram of a portion of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 5 is a simplified perspective view of a portion of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 6 is a simplified perspective view of a portion of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 7 is a simplified block diagram of a portion of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 8 is a simplified perspective view of a portion of a system to enable a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure; FIG. 9 is a simplified flowchart illustrating potential operations that may be associated with the system in accordance with an embodiment of the present disclosure; and FIG. 10 is a block diagram illustrating an example device that include a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure. The FIGURES of the drawings are not necessarily drawn to scale, as their dimensions can be varied considerably without departing from the scope of the present disclosure. DETAILED DESCRIPTION Example Embodiments The following detailed description sets forth examples of apparatuses, methods, and systems relating to enabling a transmission line embedded in a portion of a chassis of an electronic device. Features such as structure(s), function(s), and/or characteristic(s), for example, are described with reference to one embodiment as a matter of convenience; various embodiments may be implemented with any suitable one or more of the described features. In the following description, various aspects of the illustrative implementations will be described using terms commonly employed by those skilled in the art to convey the substance of their work to others skilled in the art. However, it will be apparent to those skilled in the art that the embodiments disclosed herein may be practiced with only some of the described aspects. For purposes of explanation, specific numbers, materials, and configurations are set forth in order to provide a thorough understanding of the illustrative implementations. However, it will be apparent to one skilled in the art that the embodiments disclosed herein may be practiced without the specific details. In other instances, well-known features are omitted or simplified in order not to obscure the illustrative implementations. The terms “over,” “under,” “below,” “between,” and “on” as used herein refer to a relative position of one layer or component with respect to other layers or components. For example, one layer disposed over or under another layer may be directly in contact with the other layer or may have one or more intervening layers. Moreover, one layer disposed between two layers may be directly in contact with the two layers or may have one or more intervening layers. In contrast, a first layer or component “directly on” or “directly under” a second layer or component is in direct contact with that second layer or component. Similarly, unless explicitly stated otherwise, one feature disposed between two features may be in direct contact with the adjacent features or may have one or more intervening layers. In the following detailed description, reference is made to the accompanying drawings that form a part hereof wherein like numerals designate like parts throughout, and in which is shown, by way of illustration, embodiments that may be practiced. It is to be understood that other embodiments may be utilized and structural or logical changes may be made without departing from the scope of the present disclosure. Therefore, the following detailed description is not to be taken in a limiting sense. For the purposes of the present disclosure, the phrase “A and/or B” means (A), (B), or (A and B). For the purposes of the present disclosure, the phrase “A, B, and/or C” means (A), (B), (C), (A and B), (A and C), (B and C), or (A, B, and C). Reference to “one embodiment” or “an embodiment” in the present disclosure means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase “in one embodiment” or “in an embodiment” are not necessarily all referring to the same embodiment. The appearances of the phrase “for example,” “in an example,” or “in some examples” are not necessarily all referring to the same example. The term “about” indicates a tolerance of twenty percent (10%). For example, about one (1) mm would include one (1) mm and ±0.1 mm from one (1) mm. Similarly, terms indicating orientation of various elements, for example, “coplanar,” “perpendicular,” “orthogonal,” “parallel,” or any other angle between the elements generally refer to being within plus or minus five to twenty percent (+/−5-20%) of a target value based on the context of a particular value as described herein or as known in the art. FIG. 1 is a simplified block diagram of an electronic device configured with a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment of the present disclosure. In an example, an electronic device 102 can include a first housing 104 and a second housing 106 . The first housing 104 can be rotatively or pivotably coupled to the second housing 106 using a hinge 108 . The first housing 104 can include a display 110 . Electronic device 102 can be a laptop computer. The second housing 106 can include a keyboard 114 , memory 116 , one or more processors 118 , a wireless communication engine 120 , a transmission line 122 , one or more antenna 124 (e.g., FIG. 1 illustrates antenna 124 a and antenna 124 b ), and one or more electronic components 126 . Each of the electronic components 126 can be a device or group of devices available to assist in the operation or function of the electronic device 102 . The second housing 106 can also include a chassis 112 . The chassis 112 is the physical frame or structure that contains the power supply, motherboard, memory, disk drives and other components of electronic device 102 . For example, as illustrated in FIG. 1 , the chassis 112 is the physical frame or support structure for the keyboard 114 , the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the transmission line 122 , the one or more antenna 124 , and the one or more electronic components 126 (e.g., battery, disk drives, etc.). The transmission line 122 can be embedded in the chassis 112 of the electronic device 102 . In an example, the transmission line 122 is a conductive material and includes stainless steel, copper, an alloy such as nickel copper, or some material that is conductive, rigid, and can help guide RF energy from one point to another. In some examples, the transmission line 122 is a strip-line transmission line. The electronic device 102 can be in wireless communication with one or more other devices using the wireless communication engine 120 , the transmission line 122 , and the one or more antenna 124 . For example, as illustrated in FIG. 1 , using the wireless communication engine 120 , the transmission line 122 , and the antenna 124 a , the electronic device 102 can send and receive signal 128 a and communicate with cloud service(s) 130 , a server 132 , and/or a network element 134 using a network 136 . In addition, the electronic device 102 , using the wireless communication engine 120 , the transmission line 122 , and the antenna 124 b , can send and receive signal 128 b and communicate with a wireless device 138 . The wireless device 138 may be an Internet of Things (IoT) device, a Bluetooth® device, a WiFi enabled device, or some other device that can wirelessly communicate with electronic device 102 . In some examples, the wireless device 138 can be in communication with the cloud service(s) 130 , the server 132 , and/or the network element 134 using the network 136 . Generally, the transmission line 122 is a wireless communication transmission line. More specifically, the transmission line 122 is used to guide radio frequency (RF) energy from one point (e.g., the wireless communication engine 120 ) to another point (e.g., antenna 124 ). Each of the one or more antenna 124 are associated with the region of transition from a guided wave to a free space wave (e.g., signal 128 a or 128 b ), radiating RF energy. It is to be understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present disclosure. Substantial flexibility is provided in that any suitable arrangements and configuration may be provided without departing from the teachings of the present disclosure. For purposes of illustrating certain example techniques, the following foundational information may be viewed as a basis from which the present disclosure may be properly explained. End users have more media and communications choices than ever before. A number of prominent technological trends are currently afoot (e.g., more computing elements, more online video services, more Internet traffic, more complex processing, etc.), and these trends are changing the expected performance of devices as devices and systems are expected to increase function and performance. One current trend is thinner and lighter devices. To reduce the Z-height of some systems, the transmission lines for wireless signals are designed to have a relatively small diameter. (The term “Z-height,” “Z location,” etc. refers to the height along the “Z” axis of an (x, y, z) coordinate axis or cartesian coordinate system.) However, as the diameter of the transmission line is reduced, the insertion loss of the transmission line increases. This results in the need for a higher transmit power and that can impact the overall system power consumption. Also, the higher transmit power can increase the system noise. Another current trend to increase the performance and function is to increase the density of the devices and systems and pack more computing elements into the devices and systems. However, the increase in computing elements causes an increase in the electromagnetic interference (EMI) and radio frequency interference (RFI). EMI and RFI affect almost every electronic device, especially mobile compute devices. As stated above, as the diameter of the transmission line is reduced to reduce the Z-height of the system, a higher transmit power is needed to compensate for the increased insertion loss of the transmission line and the higher transmit power can increase the system noise. What is needed is a transmission line that does not greatly increase the Z-height of the system and does not greatly increase the system noise to compensate for the insertion loss due to a relatively small diameter transmission line. A transmission line, as outlined in FIG. 1 , can resolve these issues (and others). In an example, a transmission line embedded in a portion of a chassis of an electronic device can help to decrease the overall thickness of the electronic device without greatly increasing the insertion loss of the transmission line or the signal noise of the system. In some examples, the transmission line embedded in a portion of the chassis can also help to reduce the system level routing complexity by helping to eliminate or reduce some of the challenges associated with system cable routing. The transmission line can be supported by a plurality of transmission line supports at periodic locations based on the length of the transmission line. More specifically, in one example, the chassis of the electronic device can include a keyboard mounting plate and the transmission line can be imbedded in the keyboard mounting plate. A dielectric (e.g., air) can be located above and below the transmission line. In a specific example, the chassis of the electronic device can include a module mounting plate and the transmission line can be imbedded in the module mounting plate such that the module mounting plate can be used as the conductor for transmission line. The bottom side of a graphite layer under the keyboard and the bottom side of a substrate (e.g., a printed circuit board) for the electronic device can be used as the reference layers for the transmission line. The transmission line can be coupled to the module mounting plate using a plurality of transmission line supports that have a length, a width, and routing according to design specifications and functional requirements. In an example, the plurality of transmission line supports can be comprised of plastic, thermoplastic, thermoset, or some other non-conductive material that can support the transmission line. In a specific example, the plurality of transmission line supports can be comprised of nylon 30% glass filled or Teflon® and can be positioned at periodic locations based on the length of the transmission line. Each end of the transmission line can be coupled to a transmission line coupling pad. In some examples, each end of the transmission line can have a hook or “C” shaped profile that can act as a metal spring to help enable the connection between the ends of the transmission line and the transmission line coupling pads. The transmission line coupling pads can help connect the transmission line to the wireless communication engine and to the antenna to help enable wireless communications. Turning to the infrastructure of FIG. 1 , network 136 represents a series of points or nodes of interconnected communication paths for receiving and transmitting packets of information. Network 136 offers a communicative interface between nodes, and may be configured as any local area network (LAN), virtual local area network (VLAN), wide area network (WAN), wireless local area network (WLAN), metropolitan area network (MAN), Intranet, Extranet, virtual private network (VPN), and any other appropriate architecture or system that facilitates communications in a network environment, or any suitable combination thereof, including wired and/or wireless communication. In network 136 , network traffic, which is inclusive of packets, frames, signals, data, etc., can be sent and received according to any suitable communication messaging protocols. Suitable communication messaging protocols can include a multi-layered scheme such as Open Systems Interconnection (OSI) model, or any derivations or variants thereof (e.g., Transmission Control Protocol/Internet Protocol (TCP/IP), user datagram protocol/IP (UDP/IP)). Messages through the network could be made in accordance with various network protocols, (e.g., Ethernet, Infiniband, OmniPath, etc.). Additionally, radio signal communications over a cellular network may also be provided. Suitable interfaces and infrastructure may be provided to enable communication with the cellular network. The term “packet” as used herein, refers to a unit of data that can be routed between a source node and a destination node on a packet switched network. A packet includes a source network address and a destination network address. These network addresses can be Internet Protocol (IP) addresses in a TCP/IP messaging protocol. The term “data” as used herein, refers to any type of binary, numeric, voice, video, textual, or script data, or any type of source or object code, or any other suitable information in any appropriate format that may be communicated from one point to another in electronic devices and/or networks. In an example implementation, electronic device 102 , is meant to encompass an electronic device that includes a transmission line to help allow the electronic device 102 to wirelessly communicate with another device or network. Electronic device 102 may include any suitable hardware, software, components, modules, or objects that facilitate the operations thereof, as well as suitable interfaces for receiving, transmitting, and/or otherwise communicating data or information in a network environment. This may be inclusive of appropriate algorithms and communication protocols that allow for the effective exchange of data or information. Electronic device 102 may include virtual elements. In regards to the internal structure, electronic device 102 can include memory elements (e.g., memory 116 ) for storing information to be used in the operations outlined herein. Electronic device 102 may keep information in any suitable memory element (e.g., random access memory (RAM), read-only memory (ROM), erasable programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), application specific integrated circuit (ASIC), etc.), software, hardware, firmware, or in any other suitable component, device, element, or object where appropriate and based on particular needs. Any of the memory items discussed herein should be construed as being encompassed within the broad term ‘memory element.’ Moreover, the information being used, tracked, sent, or received could be provided in any database, register, queue, table, cache, control list, or other storage structure, all of which can be referenced at any suitable timeframe. Any such storage options may also be included within the broad term ‘memory element’ as used herein. In certain example implementations, functions outlined herein may be implemented by logic encoded in one or more tangible media (e.g., embedded logic provided in an ASIC, digital signal processor (DSP) instructions, software (potentially inclusive of object code and source code) to be executed by a processor, or other similar machine, etc.), which may be inclusive of non-transitory computer-readable media. In some of these instances, memory elements can store data used for the operations described herein. This includes the memory elements being able to store software, logic, code, or processor instructions that are executed to carry out the activities described herein. In an example implementation, electronic device 102 may include software modules (e.g., wireless communication engine 120 , etc.) to achieve, or to foster, operations as outlined herein. These modules may be suitably combined in any appropriate manner, which may be based on particular configuration and/or provisioning needs. In example embodiments, such operations may be carried out by hardware, implemented externally to these elements, or included in some other device to achieve the intended functionality. Furthermore, the modules can be implemented as software, hardware, firmware, or any suitable combination thereof. These elements may also include software (or reciprocating software) that can coordinate with other network elements in order to achieve the operations, as outlined herein. Additionally, electronic device 102 may include a processor (e.g., the one or more processors 118 ) that can execute software or an algorithm to perform activities as discussed herein. A processor can execute any type of instructions associated with the data to achieve the operations detailed herein. In one example, the processors could transform an element or an article (e.g., data) from one state or thing to another state or thing. In another example, the activities outlined herein may be implemented with fixed logic or programmable logic (e.g., software/computer instructions executed by a processor) and the elements identified herein could be some type of a programmable processor, programmable digital logic (e.g., a field programmable gate array (FPGA), an erasable programmable read-only memory (EPROM), an electrically erasable programmable read-only memory (EEPROM)) or an ASIC that includes digital logic, software, code, electronic instructions, or any suitable combination thereof. Any of the potential processing elements, modules, and machines described herein should be construed as being encompassed within the broad term ‘processor.’ Turning to FIG. 2 , FIG. 2 is a simplified block diagram of a side cut away view of a portion of an electronic device 102 a , in accordance with an embodiment of the present disclosure. In an example, the electronic device 102 a can include the chassis 112 , the keyboard 114 , the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a , the transmission line 122 , the one or more electronic components 126 , heat spreaders 140 a and 140 b , a support plate 142 , air gaps 146 a - 146 c , a substrate 148 , a thermal interface material (TIM) 150 , a cold plate 152 , and one or more heat pipes 154 . As illustrated in FIG. 2 , the heat spreader 140 a can be under the keyboard 114 . The term “under” is a relative term used to refer to a relative position of one layer or component with respect to other layers or components. The support plate 142 and the transmission line 122 can be under the heat spreader 140 a . The air gap 146 a can be between the transmission line 122 and the support plate 142 . The substrate 148 can be under the transmission line 122 and the support plate 142 . The air gap 146 b can be between the substrate 148 and the transmission line 122 and the support plate 142 . The memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a , and the electronic component 126 can be under the substrate 148 . The TIM 150 can be under the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a , and the electronic component 126 . The cold plate 152 can be under the TIM 150 . The one or more heat pipes 154 can be under the cold plate 152 . The heat spreader 140 b can be under the one or more heat pipes 154 with the air gap 146 c between the heat spreader 140 b and the one or more heat pipes 154 . The chassis 112 can be under the heat spreader 140 b. In an example, the keyboard 114 can be a mechanical keyboard or a digital keyboard. The heat spreader 140 a can be an electrically conductive heat spreader and is comprised of graphite or some other material that can help at least partially thermally insulate the keyboard 114 from heat below the heat spreader 140 a (e.g., the heat generated by the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a , and/or the electronic component 126 ). The support plate 142 can be part of the chassis 112 and can be comprised of aluminum, titanium, a magnesium alloy, copper, or some other type of metal or material that can function as a ground reference plane and help support the keyboard 114 . The transmission line 122 can be comprised of stainless steel, copper, an alloy such as nickel copper, or some material that is conductive, rigid, and can help guide RF energy from one point to another. The air gap 146 a can help provide a thermal insulating gap between the transmission line 122 and the heat spreader 140 a . In addition, the air gap 146 a can act as a dielectric for RF waves to help reduce insertion loss. The air gap 146 b can help provide a thermal insulating gap between the transmission line 122 and the substrate 148 . In addition, the air gap 146 b can act as a dielectric for RF waves to help reduce insertion loss. The substrate 148 can be a printed circuit board (PCB), system-on-a-chip (SoC) or some other substrate or support structure that can support the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a , and/or the electronic component 126 . The substrate 148 may be a non-semiconductor substrate or a semiconductor substrate. In one implementation, the non-semiconductor substrate may be silicon dioxide, an inter-layer dielectric composed of silicon dioxide, silicon nitride, titanium oxide and other transition metal oxides. Although a few examples of materials from which the non-semiconducting substrate may be formed are described here, any material that may serve as a foundation upon which a non-semiconductor device may be built falls within the spirit and scope of the embodiments disclosed herein. In another implementation, the semiconductor substrate may be a crystalline substrate formed using a bulk silicon or a silicon-on-insulator substructure. In other implementations, the semiconductor substrate may be formed using alternate materials, which may or may not be combined with silicon, that include but are not limited to germanium, indium antimonide, lead telluride, indium arsenide, indium phosphide, gallium arsenide, indium gallium arsenide, gallium antimonide, or other combinations of group III-V or group IV materials. In other examples, the substrate may be a flexible substrate including 2D materials such as graphene and molybdenum disulphide, organic materials such as pentacene, transparent oxides such as indium gallium zinc oxide poly/amorphous (low temperature of dep) III-V semiconductors and germanium/silicon, and other non-silicon flexible substrates. Although a few examples of materials from which the substrate 148 may be formed are described here, any material that may serve as a foundation upon which a semiconductor device may be built falls within the spirit and scope of the embodiments disclosed herein. The TIM 150 can be thermal grease, phase change material, gap filler, or any other material to transfer heat and bridge the interface between two or more solid surfaces (e.g., the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a , and/or the electronic component 126 and the cold plate 152 ). The cold plate 152 can be a heat spreader, heat transfer pedestal, or some other component that can help to transfer heat away from the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a and to the one or more heat pipes 154 . Each of the one or more heat pipes 154 can be a heat pipe, vapor chamber, or some other component that can help to transfer heat away from the cold plate 152 (e.g., to an active heat spreader such as a fan or to a passive heat spreader). The air gap 146 c can help provide an insulating gap between the one or more heat pipes 154 and the heat spreader 140 b . The heat spreader 140 b can be a conductive heat spreader and can be comprised of graphite or some other material that can help at least partially thermally insulate the chassis 112 from heat above the heat spreader 140 b (e.g., the heat collected by the one or more heat pipes 154 and/or the heat from the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the antenna 124 a , and/or the electronic component 126 ). The chassis 112 is part of the physical frame or structure of the electronic device 102 a . The support plate 142 is part of the chassis 112 . The heat spreader 140 and the substrate 148 are grounded and act as the reference planes for the transmission line 122 . In some examples, the transmission line 122 is an RF transmission line configured to help with RF communications. Also, the transmission line 122 may be a strip line and the heat spreader 140 is the top ground plane for the strip line and the substrate 148 is the bottom ground plate for the strip line. In addition, because the heat spreader 140 and the substrate 148 are grounded, they can be used as shielding to help counter EMI and/or RFI issues. More specifically, because the heat spreader 140 and the substrate 148 are grounded, they can be used as an EMI shield to help block the EMI radiation from the transmission line 122 . Turning to FIG. 3 , FIG. 3 is a simplified block diagram of a side cut away view of a portion of the electronic device 102 a , in accordance with an embodiment of the present disclosure. In an example, the electronic device 102 a can include the transmission line 122 , the heat spreader 140 a , the support plate 142 , the air gaps 146 a and 146 b , and the substrate 148 . As illustrated in FIG. 3 , the air gap 146 a between the transmission line 122 and the heat spreader 140 a can have a first air gap height 158 . For a transmission line 122 with a width of about 1 mm, the first air gap height 158 may be between about 0.6 millimeters and about 0.20 millimeters and ranges therein (e.g., between about 0.5 and about 0.3 millimeters, or between about 0.4 and about 0.25 millimeters), depending on design choice and design constraints. In other examples, other transmission lines 122 with other widths may have other ranges, depending on design choice and design constraints. In a specific example, the first air gap height 158 is greater than or equal to about 0.15 millimeters. In another specific example, the first air gap height 158 may be about 0.35 millimeters. The air gap 146 b between the transmission line 122 and the substrate 148 can have a second air gap height 162 . For a transmission line 122 with a width of about one (1) mm, the second air gap height 162 may be between about 0.6 millimeters and about 0.20 millimeters and ranges therein (e.g., between about 0.35 and about 0.2 millimeters, or between about 0.5 and about 0.4 millimeters), depending on design choice and design constraints. In a specific example, the second air gap height 162 is greater than or equal to about 0.15 millimeters. In another specific example, the second air gap height 162 may be about 0.3 millimeters. The transmission line 122 may have a transmission line height 160 . The transmission line height 160 may be between about 0.5 millimeters and about 0.2 millimeters and ranges therein (e.g., between about 0.4 and about 0.25 millimeters, or between about 0.45 and about 0.3 millimeters), depending on design choice and design constraints. In a specific example, the transmission line height 160 may be greater than or equal to about 0.1 millimeters. Based on the first air gap height 158 , (the air gap 146 a between the transmission line 122 and the heat spreader 140 a ), the second air gap height 162 , (the air gap 146 b between the transmission line 122 and the substrate 148 ), and a defined impedance for the transmission line 122 , the transmission line height 160 for the transmission line 122 can be determined. Turning to FIG. 4 , FIG. 4 is a simplified block diagram of a cut away top-down view of a portion of the electronic device 102 a , in accordance with an embodiment of the present disclosure. The electronic device 102 a can include the transmission line 122 , the support plate 142 , the air gap 146 b , a plurality of transmission line supports 164 , and transmission line coupling pads 166 . The plurality of transmission line supports 164 help to support the transmission line 122 and can be comprised of plastic or some other non-conductive material. In a specific example, the plurality of transmission line supports 164 can be comprised nylon or Teflon®. As illustrated in FIG. 4 , the plurality of transmission line supports 164 are relatively parallel to each other and are relatively perpendicular to the transmission line 122 . The transmission line coupling pads 166 help to allow the transmission line 122 to send and receive signals from the wireless communication engine 120 and the one or more antenna 124 . As illustrated in FIG. 4 , the transmission line 122 can have a transmission line width 172 . In addition, an air gap distance 174 represents the distance from an outside edge of the transmission line 122 to an inside edge of the support plate 142 . The transmission line width 172 depends on design choice and design constraints. In a specific example, the transmission line width 172 can be about one (1) mm. The air gap distance 174 also depends on design choice and design constraints. In a specific example, the air gap distance 174 can be greater than or equal to about 1.5 mm. The first air gap height 158 , the transmission line height 160 , and/or the second air gap height 162 illustrated in FIG. 3 and/or the transmission line width 172 and/or the air gap distance 174 can each be adjusted relative to each other, depending on design choice and design constraints, to achieve a desired impedance of the transmission line 122 for wireless communication. In addition, the material that comprises the transmission line 122 and/or the plurality of transmission line supports 164 can be selected to help achieve the desired impedance of the transmission line 122 for wireless communication. Turning to FIG. 5 , FIG. 5 is a simplified block diagram of a perspective view of a portion of the electronic device 102 a , in accordance with an embodiment of the present disclosure. As illustrated in FIG. 5 , the electronic device 102 a can include the transmission line 122 , the heat spreader 140 a , the support plate 142 , the air gaps 146 a and 146 b , and transmission line supports 164 . Note that only a portion of one of the plurality of transmission line supports 164 is illustrated in FIG. 5 . Also note that the portion of electronic device 102 a illustrated in FIG. 5 is inverted comparted to the portion of electronic device 102 a illustrated in FIGS. 2 and 3 . Turning to FIG. 6 , FIG. 6 is a simplified block diagram of a perspective view of a portion of the electronic device 102 a , in accordance with an embodiment of the present disclosure. As illustrated in FIG. 6 , the electronic device 102 a can include the transmission line 122 , the support plate 142 , the air gap 146 b , and the transmission line supports 164 . Note that only one of the plurality of transmission line supports 164 is illustrated in FIG. 6 . Also note that the coupling of the transmission line support 164 to the support plate 142 illustrated in FIG. 6 is for illustration purposes only and other means, mechanisms, configurations may be used to couple the plurality of transmission line supports 164 to the support plate 142 . Turning to FIG. 7 , FIG. 7 is a simplified block diagram of a perspective view of a portion of the electronic device 102 a , in accordance with an embodiment of the present disclosure. As illustrated in FIG. 7 , the electronic device 102 a can include the transmission line 122 , the support plate 142 , the substrate 148 , the transmission line supports 164 and the transmission line coupling pad 166 . Note that only a portion of one of the plurality of transmission line supports 164 is illustrated in FIG. 7 . In an example, a coupling end 168 of the transmission line 122 that couples with the transmission line coupling pad 166 can have a hook or general “C” shaped profile to help allow the transmission line 122 to couple with the transmission line coupling pad 166 . While the coupling end 168 of the transmission line 122 is illustrated as having a hook or general “C” shaped profile in FIG. 7 , other profiles, configurations, means, mechanisms may be used to help allow the transmission line 122 couple with the transmission line coupling pad 166 . Turning to FIG. 8 , FIG. 8 is a simplified block diagram of a perspective view of a portion of the electronic device 102 a , in accordance with an embodiment of the present disclosure. As illustrated in FIG. 8 , the electronic device 102 a can include the transmission line 122 , the support plate 142 , the substrate 148 , the transmission line supports 164 , and the transmission line coupling pad 166 . As illustrated in FIG. 8 , the support plate 142 is a support plate for a keyboard (e.g., keyboard 114 ). While the transmission line 122 has been illustrated as being located in the support plate 142 , the transmission line 122 can be located in other portions of the chassis 112 depending on design constraints (e.g., a dielectric above and below the transmission line 122 ) and the desired functionality of the transmission line 122 . Turning to FIG. 9 , FIG. 1s an example flowchart illustrating possible operations of a flow 900 that may be associated with a transmission line embedded in a portion of a chassis of an electronic device, in accordance with an embodiment. At 902 , an area of a chassis of an electronic device is located where a dielectric above and below the area can be created or already exists. For example, the support plate 142 is an area of the chassis 112 of the electronic device 102 a where a dielectric, (air gap 146 a and air gap 146 b ), above and below the area can be created or already exists. At 904 , at least a portion of the area of the chassis is removed. For example, the area of the chassis can be removed by stamping the area, milling the area, chemical etching, laser etching, or by some other means of removing an area of a chassis. At 906 , a support structure for a transmission line is added to the portion of the area of the chassis that was removed. For example, the transmission line supports 164 can be added to the portion of the area of the chassis that was removed. At 908 , the transmission line is secured to the support structure. For example, the transmission line can be secured to the transmission line supports as illustrated in FIG. 4 and/or FIG. 6 or by some other means to embed the transmission line in a portion of the chassis. At 910 , the transmission line is coupled to a wireless engine and antenna to help enable wireless communication. For example, the transmission line can be coupled to the transmission line coupling pad 166 to allow the transmission line 122 to send and receive signals from the wireless communication engine 120 and antenna 124 to help enable wireless communication. Turning to FIG. 10 , FIG. 10 is a simplified block diagram of an electronic device configured with a transmission line embedded in a portion of a chassis of an electronic device 102 b , in accordance with an embodiment of the present disclosure. In an example, the electronic device 102 b may be a tablet computer or some other wireless communication device with a single housing (e.g., smartphone, IoT device, etc.). As illustrated in FIG. 10 , the electronic device 102 b can include the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the transmission line 122 , the one or more antenna 124 (e.g., FIG. 10 illustrates antenna 124 a and antenna 124 b ), the one or more electronic components 126 , and a single housing device display 170 . Each of the electronic components 126 can be a device or group of devices available to assist in the operation or function of the electronic device 102 b . The electronic device 102 b can also include the chassis 112 . The chassis 112 is the physical frame or structure that contains the power supply, motherboard, memory, disk drives, display, and other components of electronic device 102 b . For example, as illustrated in FIG. 10 , the chassis 112 is the physical frame or structure for the memory 116 , the one or more processors 118 , the wireless communication engine 120 , the transmission line 122 , the one or more antenna 124 , the one or more electronic components 126 (e.g., battery, disk drives, etc.), and the single housing device display 170 . The transmission line 122 can be embedded in the chassis 112 of the electronic device 102 b in an area where a dielectric (e.g., an air gap) above and below the transmission line exists or can be created. The electronic device 102 b can be in wireless communication with one or more other devices using the wireless communication engine 120 , the transmission line 122 , and the one or more antenna 124 . For example, as illustrated in FIG. 10 , using the wireless communication engine 120 , the transmission line 122 , and the antenna 124 a , the electronic device 102 b can send and receive signal 128 a and communicate with the cloud service(s) 130 , the server 132 , and/or the network element 134 using the network 136 . In addition, using the wireless communication engine 120 , the transmission line 122 , and the antenna 124 b , the electronic device 102 b can send and receive signal 128 b and communicate with the wireless device 138 . Elements of FIG. 10 may be coupled to one another through one or more interfaces employing any suitable connections (wired or wireless), which provide viable pathways for network (e.g., network 136 , etc.) communications. Additionally, any one or more of these elements of FIG. 10 may be combined or removed from the architecture based on particular configuration needs. Network 136 may include a configuration capable of transmission control protocol/Internet protocol (TCP/IP) communications for the transmission or reception of packets in a network. Electronic device 102 b may also operate in conjunction with a user datagram protocol/IP (UDP/IP) or any other suitable protocol where appropriate and based on particular needs. Each of electronic devices 102 , 102 a , and 102 b may include any suitable hardware, software, components, modules, or objects that facilitate the operations thereof, as well as suitable interfaces for receiving, transmitting, and/or otherwise communicating data or information in a network environment. This may be inclusive of appropriate algorithms and communication protocols that allow for the effective exchange of data or information. Each of electronic devices 102 , 102 a , and 102 b may include virtual elements. Note that with the examples provided herein, interaction may be described in terms of two, three, or more elements. However, this has been done for purposes of clarity and example only. In certain cases, it may be easier to describe one or more of the functionalities of a given set of flows by only referencing a limited number of elements. It should be appreciated that electronic devices 102 , 102 a , and 102 b and their teachings are readily scalable and can accommodate a large number of components, as well as more complicated/sophisticated arrangements and configurations. Accordingly, the examples provided should not limit the scope or inhibit the broad teachings of electronic devices 102 , 102 a , and 102 b and as potentially applied to a myriad of other architectures. Although the present disclosure has been described in detail with reference to particular arrangements and configurations, these example configurations and arrangements may be changed significantly without departing from the scope of the present disclosure. Moreover, certain components may be combined, separated, eliminated, or added based on particular needs and implementations. Additionally, although electronic devices 102 a - 102 d have been illustrated with reference to particular elements and operations, these elements and operations may be replaced by any suitable architecture, protocols, and/or processes that achieve the intended functionality of electronic devices 102 , 102 a , and 102 b. Numerous other changes, substitutions, variations, alterations, and modifications may be ascertained to one skilled in the art and it is intended that the present disclosure encompass all such changes, substitutions, variations, alterations, and modifications as falling within the scope of the appended claims. In order to assist the United States Patent and Trademark Office (USPTO) and, additionally, any readers of any patent issued on this application in interpreting the claims appended hereto, Applicant wishes to note that the Applicant: (a) does not intend any of the appended claims to invoke paragraph six (6) of 35 U.S.C. section 112 as it exists on the date of the filing hereof unless the words “means for” or “step for” are specifically used in the particular claims; and (b) does not intend, by any statement in the specification, to limit this disclosure in any way that is not otherwise reflected in the appended claims. OTHER NOTES AND EXAMPLES In Example A1, is a mobile computing device configured for radio frequency communication, the mobile computing device including a substrate, a keyboard, a chassis, where a portion of the chassis is between the substrate and the keyboard, and a transmission line embedded in the portion of the chassis between the substrate and the keyboard. In Example A2, the subject matter of Example A1 can optionally include where the portion of the chassis between the substrate and the keyboard is a support plate for the keyboard. In Example A3, the subject matter of any one of Examples A1-A2 can optionally include where a first air gap between the transmission line and the keyboard and a second air gap between the transmission line and the substrate. In Example A4, the subject matter of any one of Examples A1-A3 can optionally include where the first air gap and the second air gap are a dielectric for radio frequency waves emitted from the transmission line. In Example A5, the subject matter of any one of Examples A1-A4 can optionally include a heat spreader between the transmission line and the keyboard. In Example A6, the subject matter of any one of Examples A1-A5 can optionally include where the heat spreader and substrate are grounded and create an electromagnetic interference shield. In Example A7, the subject matter of any one of Examples A1-A6 can optionally include where the radio frequency communication is WiFi. In Example A8, the subject matter of any one of Examples A1-A7 can optionally include where the transmission line is a strip line. Example AA1 is an electronic device including a substrate, memory on the substrate, one or more processors on the substrate, a keyboard, a chassis, where a portion of the chassis is between the substrate and the keyboard, a transmission line embedded in the portion of the chassis between the substrate and the keyboard, and one or more antenna. In Example AA2, the subject matter of Example AA1 can optionally include where the transmission line is a wireless communication transmission line. In Example AA3, the subject matter of any one of Examples AA1-AA2 can optionally include where the portion of the chassis between the substrate and the keyboard is a support plate for the keyboard. In Example AA4, the subject matter of any one of Examples AA1-AA3 can optionally include a first dielectric and a second dielectric, where the transmission line is between the first dielectric and the second dielectric. In Example AA5, the subject matter of any one of Examples AA1-AA4 can optionally include a first air gap between the transmission line and the keyboard and a second air gap between the transmission line and the substrate. In Example AA6, the subject matter of any one of Examples AA1-AA5 can optionally include a plurality of transmission line supports coupled to the portion of the chassis between the substrate and the keyboard to support the transmission line. In Example AA7, the subject matter of any one of Examples AA1-AA7 can optionally include a plurality of transmission line supports comprised of non-conductive material. In Example AA8, the subject matter of any one of Examples AA1-AA7 can optionally include where the transmission line is a strip line. In Example AA9, the subject matter of any one of Examples AA1-AA8 can optionally include transmission line coupling pads to couple the transmission line to the antenna and a wireless communication engine. Example M1 is a method including identifying an area of a chassis of an electronic device where a dielectric above and below the area can be created or already exists, removing at least a portion of the area of the chassis where a dielectric above and below the area can be created or already exists, adding a support structure for a transmission line to the portion of the area of the chassis that was removed, and securing the transmission line to the support structure. In Example M2, the subject matter of Example M1 can optionally include coupling the transmission line to a wireless communication engine and coupling the transmission line to one or more antenna. In Example M3, the subject matter of any one of the Examples M1-M2 can optionally include where the transmission line is a strip line.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"029-920-503-126-209","jurisdiction":"US","doc_number":"12368079","kind":"B2","date_published":"2025-07-22","doc_key":"US_12368079_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12368079","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"17958424","date":"2022-10-02"},"priority_claims":{"claims":[{"jurisdiction":"CN","doc_number":"202211027731.6","date":"2022-08-25","sequence":1}],"earliest_claim":{"date":"2022-08-25"}},"invention_title":[{"text":"Method for manufacturing electronic device","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"2899","extracted_name":{"value":"Mohammad M Choudhry"}}},"applicants":[{"residence":"TW","extracted_name":{"value":"InnoLux Corporation"},"extracted_address":"Miao-Li County"}],"inventors":[{"residence":"TW","sequence":1,"extracted_name":{"value":"Cheng-Chi Wang"},"extracted_address":"Miao-Li County"},{"residence":"TW","sequence":2,"extracted_name":{"value":"Tzu-Yen Chiu"},"extracted_address":"Miao-Li County"}],"agents":[{"extracted_name":{"value":"Winston Hsu"}}]},"classifications_ipcr":{"classifications":[{"symbol":"H01L21/66","classification_value":"I","classification_symbol_position":"F"},{"symbol":"H01L21/56","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01L23/00","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"H01L22/20","classification_value":"I","classification_symbol_position":"F"},{"symbol":"H01L21/561","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01L21/568","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01L24/11","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01L24/19","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01L2224/117","classification_value":"A","classification_symbol_position":"L"},{"symbol":"H01L2224/11901","classification_value":"A","classification_symbol_position":"L"},{"symbol":"H01L2924/1011","classification_value":"A","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"9653445","kind":"B2","date":"2017-05-01"},"lens_id":"087-989-470-349-834"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2004/0051550","kind":"A1","date":"2004-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2005/0208735","kind":"A1","date":"2005-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2005/0225347","kind":"A1","date":"2005-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2008/0191728","kind":"A1","date":"2008-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2009/0011539","kind":"A1","date":"2009-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0161548","kind":"A1","date":"2016-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0151502","kind":"A1","date":"2018-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0080971","kind":"A1","date":"2019-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2020/0227395","kind":"A1","date":"2020-07-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2021/0257244","kind":"A1","date":"2021-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"108122861","kind":"A","date":"2018-06-01"},"lens_id":"086-938-359-980-250"}},{"patcit":{"document_id":{"jurisdiction":"TW","doc_number":"201531718","kind":"A","date":"2015-08-01"},"lens_id":"130-590-075-779-642"}},{"patcit":{"document_id":{"jurisdiction":"TW","doc_number":"202029526","kind":"A","date":"2020-08-01"},"lens_id":"130-509-544-854-73X"}}],"patent_count":14},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12368079","kind":"B2","date":"2025-07-22"},"lens_id":"029-920-503-126-209"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12368079","kind":"B2","date":"2025-07-22"},"lens_id":"029-920-503-126-209"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"A method for manufacturing an electronic device includes: providing a base layer, wherein the base layer includes a plurality of first dies and a plurality of second dies, and a number of the plurality of first dies is greater than a number of the plurality of second dies; forming a circuit layer on the base layer; and performing an electricity test to confirm whether the circuit layer is electrically connected to one of the plurality of second dies.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A method for manufacturing an electronic device, comprising following steps: providing a base layer, wherein the base layer comprises a plurality of first dies and a plurality of second dies, and a number of the plurality of first dies is greater than a number of the plurality of second dies; forming a circuit layer on the base layer; and performing an electricity test to confirm whether the circuit layer is electrically connected to one of the plurality of second dies, wherein each of the plurality of second dies comprises an alignment mark, and forming the base layer comprises following steps: disposing the plurality of second dies on a carrier; disposing the plurality of first dies on the carrier, wherein at least one of the plurality of second dies is surrounded by at least eight of the plurality of first dies; forming a protective layer to surround the plurality of first dies and the plurality of second dies; and removing the carrier."]},{"claim_text":["2. The method for manufacturing the electronic device according to claim 1 , wherein in a cross-sectional view of the electronic device, a width of each of the plurality of second dies along a direction is less than a width of each of the plurality of first dies along the direction."]},{"claim_text":["3. The method for manufacturing the electronic device according to claim 1 , further comprising following steps: cutting the circuit layer to form a plurality of circuit structures; and performing another electricity test to confirm whether one of the plurality of circuit structures is electrically connected to the one of the plurality of second dies."]},{"claim_text":["4. The method for manufacturing the electronic device according to claim 3 , wherein the step of performing another electricity test comprises providing a voltage to the one of the plurality of circuit structures to obtain a resistance value of the one of the plurality of second dies."]},{"claim_text":["5. The method for manufacturing the electronic device according to claim 4 , wherein when the resistance value is within a predetermined range, at least one of the plurality of first dies adjacent to the one of the plurality of second dies and the corresponding circuit structure are confirmed as a good product."]},{"claim_text":["6. The method for manufacturing the electronic device according to claim 3 , further comprising forming a conductive element on the one of the plurality of circuit structures after the step of performing another electricity test."]},{"claim_text":["7. The method for manufacturing the electronic device according to claim 3 , further comprising cutting the base layer after the step of performing another electricity test."]},{"claim_text":["8. The method for manufacturing the electronic device according to claim 3 , wherein each of the plurality of circuit structures is a redistribution structure."]},{"claim_text":["9. The method for manufacturing the electronic device according to claim 1 , wherein one of the plurality of first dies comprises a plurality of first conductive pads, the one of the plurality of second dies comprises a plurality of second conductive pads, and a number of the plurality of second conductive pads is different from a number of the plurality of first conductive pads."]},{"claim_text":["10. The method for manufacturing the electronic device according to claim 1 , wherein the plurality of first dies are disposed on the carrier according to the alignment marks of the plurality of second dies."]},{"claim_text":["11. The method for manufacturing the electronic device according to claim 10 , wherein each of the plurality of second dies comprises a plurality of conductive pads disposed on an active surface and a back surface opposite to the active surface, wherein the active surfaces of the plurality of second dies face the carrier, and each of the alignment marks is respectively formed on the back surface of each of the plurality of second dies."]},{"claim_text":["12. The method for manufacturing the electronic device according to claim 10 , wherein each of the plurality of second dies comprises a plurality of conductive pads disposed on an active surface and a back surface opposite to the active surface, wherein the back surfaces of the plurality of second dies face the carrier, and each of the alignment marks is respectively formed on the active surface of each of the plurality of second dies."]},{"claim_text":["13. The method for manufacturing the electronic device according to claim 1 , wherein the plurality of second dies are respectively disposed on at least two corners of the base layer and a central region of the base layer, wherein the at least two corners are respectively located at two ends of a diagonal line of the base layer."]},{"claim_text":["14. The method for manufacturing the electronic device according to claim 1 , wherein in a top view of the electronic device, a die area of each of the plurality of second dies is less than or equal to a die area of each of the plurality of first dies."]},{"claim_text":["15. The method for manufacturing the electronic device according to claim 1 , wherein in a normal direction of the electronic device, a thickness of each of the plurality of second dies is less than or equal to a thickness of each of the plurality of first dies."]},{"claim_text":["16. The method for manufacturing the electronic device according to claim 1 , wherein the one of the plurality of second dies is electrically isolated from the plurality of first dies when performing the electricity test."]},{"claim_text":["17. The method for manufacturing the electronic device according to claim 1 , wherein the one of the plurality of second dies is electrically connected to one of the plurality of first dies when performing the electricity test."]},{"claim_text":["18. The method for manufacturing the electronic device according to claim 13 , wherein an extending line penetrates the at least two of the plurality of second dies respectively disposed on the at least two corners of the base layer and the one of the plurality of second dies disposed at the central region of the base layer."]}],"lang":"en"}],"description":{"text":"BACKGROUND OF THE DISCLOSURE 1. Field of the Disclosure The present disclosure relates to a method for manufacturing an electronic device, and more particularly to a method for manufacturing an electronic device with performing an electricity test to a die. 2. Description of the Prior Art In the current technology, the manufacture and production of some electronic devices often include the process of packaging electronic elements. However, the circuit design of electronic elements is complex and changeable, so how to monitor the performance or condition of the process and confirm the quality of products during the manufacturing process is an urgent issue to be discussed. In addition, if relevant tests are directly performed to the electronic elements, the electronic elements may be damaged, thus affecting the quality of products. SUMMARY OF THE DISCLOSURE One of objectives of the present disclosure is to provide a method for manufacturing an electronic device, so as to solve the problems encountered by the conventional manufacturing methods of electronic devices, and monitor the performance or condition of the process during the manufacturing process, thereby improving the quality and/or reliability of products. An embodiment of the present disclosure provides a method for manufacturing an electronic device. The method includes: providing a base layer, wherein the base layer includes a plurality of first dies and a plurality of second dies, and a number of the plurality of first dies is greater than a number of the plurality of second dies; forming a circuit layer on the base layer; and performing an electricity test to confirm whether the circuit layer is electrically connected to one of the plurality of second dies. These and other objectives of the present disclosure will no doubt become obvious to those of ordinary skill in the art after reading the following detailed description of the embodiment that is illustrated in the various figures and drawings. BRIEF DESCRIPTION OF THE DRAWINGS FIG. 1 is a flowchart of a method for manufacturing an electronic device according to an embodiment of the present disclosure. FIG. 2 is a top-view schematic diagram of first dies and second dies on a carrier according to an embodiment of the present disclosure. FIG. 3 to FIG. 6 are schematic diagrams illustrating the process of a method for manufacturing an electronic device according to an embodiment of the present disclosure. FIG. 7 is a cross-sectional schematic diagram of an electronic device according to an embodiment of the present disclosure. FIG. 8 is a top-view schematic diagram of first dies and a second die according to an embodiment of the present disclosure. FIG. 9 is a top-view schematic diagram of first dies and a second die according to another embodiment of the present disclosure. FIG. 10 is a schematic diagram illustrating a part of the process of a method for manufacturing an electronic device according to an embodiment of the present disclosure. DETAILED DESCRIPTION The present disclosure may be understood by reference to the following detailed description, taken in conjunction with the drawings as described below. It is noted that, for purposes of illustrative clarity and being easily understood by the readers, various drawings of this disclosure show a portion of the device, and certain components in various drawings may not be drawn to scale. In addition, the number and dimension of each component shown in drawings are only illustrative and are not intended to limit the scope of the present disclosure. Certain terms are used throughout the description and following claims to refer to particular components. As one skilled in the art will understand, electronic equipment manufacturers may refer to a component by different names. This document does not intend to distinguish between components that differ in name but not function. In the following description and in the claims, the terms “include”, “comprise” and “have” are used in an open-ended fashion, and thus should be interpreted to mean “include, but not limited to . . . ”. When the terms “include”, “comprise” and/or “have” are used in the description of the present disclosure, the corresponding features, areas, steps, operations and/or components would be pointed to existence, but not limited to the existence or addition of one or a plurality of the corresponding or other features, areas, steps, operations, components and/or combinations thereof. When an element or layer is referred to as being “on” or “connected to” another element or layer, it may be directly on or directly connected to the other element or layer, or intervening elements or layers may be presented (indirect condition). In contrast, when an element is referred to as being “directly on” or “directly connected to” another element or layer, there are no intervening elements or layers presented. The directional terms mentioned in this document, such as “up”, “down”, “front”, “back”, “left”, “right”, etc., are only directions referring to the drawings. Therefore, the directional terms used are for illustration, not for limitation of the present disclosure. The terms “about”, “equal”, “identical” or “the same”, and “substantially” or “approximately” mentioned in this document generally mean being within 20% of a given value or range, or being within 10%, 5%, 3%, 2%, 1% or 0.5% of a given value or range. The ordinal numbers used in the description and claims, such as “first”, “second”, “third”, etc., are used to describe elements, but they do not mean and represent that the element(s) have any previous ordinal numbers, nor do they represent the order of one element and another element, or the order of manufacturing methods. The ordinal numbers are used only to clearly discriminate an element with a certain name from another element with the same name. The claims and the description may not use the same terms. Accordingly, in the following description, a first constituent element may be a second constituent element in a claim. The electronic device of the present disclosure may include a semiconductor package, a light-emitting device, a display device, a backlight device, an antenna device, a sensing device, a radar device or a tiled device, but not limited herein. The electronic device may include a bendable or flexible electronic device. The display device may include a non-self-emissive display device or a self-emissive display device. The antenna device may include a liquid-crystal type antenna device or an antenna device other than liquid-crystal type, and the sensing device may include a sensing device used for sensing capacitance, light, heat, X-rays, microwaves or ultrasonic waves, but not limited herein. The electronic device may include electronic elements such as passive elements and active elements, for example, capacitors, resistors, inductors, diodes, transistors, etc. The tiled device may be, for example, a display tiled device or an antenna tiled device, but not limited herein. It should be noted that the electronic device may be any arrangement and combination of the above, but not limited herein. It should be noted that the technical features in different embodiments described in the following can be replaced, recombined, or mixed with one another to constitute another embodiment without departing from the spirit of the present disclosure. Please refer to FIG. 1 , FIG. 2 and FIG. 3 to FIG. 6 . FIG. 1 is a flowchart of a method for manufacturing an electronic device according to an embodiment of the present disclosure. FIG. 2 is a top-view schematic diagram of first dies and second dies disposed on a carrier in a method for manufacturing an electronic device according to an embodiment of the present disclosure. FIG. 3 to FIG. 6 are schematic diagrams illustrating the process of a method for manufacturing an electronic device according to an embodiment of the present disclosure, wherein FIG. 3 to FIG. 6 are process schematic diagrams, for example, along the section line A-A′ of FIG. 2 . As shown in FIG. 1 , FIG. 2 and FIG. 3 to FIG. 6 , a method for manufacturing an electronic device according to an embodiment of the present disclosure may include Step S 100 to Step S 300 , and may further optionally include Step S 400 and Step S 500 , as detailed in the following. As shown in Step S 100 and FIG. 2 to FIG. 4 , a base layer 100 is provided at first, wherein the base layer 100 may include a plurality of first dies 110 and a plurality of second dies 120 , and a number of the plurality of first dies 110 is greater than a number of the plurality of second dies 120 . The process of the electronic device in the present disclosure may be applied to, for example, a panel-level package (FOPLP) process, and may be a chip-first process, but not limited herein. The first die 110 and/or the second die 120 may include, for example, a diode or a semiconductor die, but not limited herein. The diode may include, for example, a light-emitting diode or a photodiode. For example, the light-emitting diode may include, an organic light-emitting diode (OLED), a mini light-emitting diode (mini LED), a micro light-emitting diode (micro LED), a quantum dot light-emitting diode (quantum dot LED), but not limited herein. A die may include a known good die (KGD), which may include various electronic elements, such as (but not limited to) wires, transistors, etc. In the embodiments of the present disclosure, the first die 110 may be a main die or a product die, and the second die 120 may be a dummy die, but not limited herein. In some embodiments, the base layer 100 may further include a protective layer 130 (as shown in FIG. 4 ), and the protective layer 130 may surround the plurality of first dies 110 and the plurality of second dies 120 to isolate moisture and air and/or reduce damage to dies. The “surround” herein may mean that in a cross-sectional schematic diagram, the protective layer 130 contacts at least one surface of the first die 110 and the second die 120 , such as covering the side surface and/or the top surface of the die. The protective layer 130 may include, for example, epoxy, poly(methyl methacrylate) (PMMA), polydimethylsiloxane (PDMS), ceramic, other suitable materials or combinations of the above materials, but not limited herein. Specifically, the process of forming the base layer 100 may for example include the following steps. At first, as shown in FIG. 2 and FIG. 3 , the plurality of first dies 110 and the plurality of second dies 120 are disposed on a carrier 102 . For example, the plurality of first dies 110 and the plurality of second dies 120 may be attached to the carrier 102 through a release layer 104 disposed on the carrier 102 , and the number of the first dies 110 disposed on the carrier 102 is greater than the number of the second dies 120 disposed on the carrier 102 . The carrier 102 may include transparent material, opaque material or translucent material, such as including glass, ceramic, stainless steel, composite material or other suitable materials, but not limited herein. The release layer 104 may include adhesive material, such as including adhesive that may be separated by laser, light or thermal cracking, but not limited herein. Then, as shown in FIG. 4 , the protective layer 130 is formed to surround the plurality of first dies 110 and the plurality of second dies 120 , and the protective layer 130 may cover the surfaces of the first dies 110 and the second dies 120 . Then, after the protective layer 130 is formed, the release layer 104 and the carrier 102 may be removed, thereby forming the base layer 100 provided in Step S 100 . As shown in FIG. 2 to FIG. 4 , the plurality of second dies 120 may be respectively disposed at specific positions in the base layer 100 , such as the positions of the base layer 100 where warpage is more likely to occur during the process, and the plurality of first dies 110 may be arranged as an array, for example, arranged as a plurality of rows extending along a direction X, and these rows are side by side along a direction Y. The direction X and the direction Y may be perpendicular to each other and both perpendicular to the normal direction of the electronic device, that is, a direction Z. The direction X may be parallel to the horizontal direction, and the direction Y may be perpendicular to the direction X, but not limited herein. In some embodiments, the plurality of second dies 120 may be respectively disposed on at least two corners of the base layer 100 and a center of the base layer 100 , and the above at least two corners are respectively located at two ends of a diagonal line of the base layer 100 . Taking the top view shown in FIG. 2 as an example, four of the second dies 120 may be respectively disposed on four corners of the base layer 100 (e.g., the upper-left corner, the upper-right corner, the lower-left corner and the lower-right corner of the base layer 100 ), and one of the second dies 120 may be disposed on the center of the base layer 100 or the central region of the base layer 100 (i.e., a position close to the center of the base layer 100 ), but the number and arrangement of the second dies 120 may be adjusted according to practical requirements, not limited herein. In some embodiments, two of the second dies 120 may be respectively disposed on two corners of two ends of the diagonal line of the base layer 100 (e.g., the upper-left corner and the lower-right corner of the base layer 100 , or the upper-right corner and the lower-left corner of the base layer 100 ), and one of the second dies 120 may be disposed on the center or the central region of the base layer 100 . In some embodiments, two of the second dies 120 may be respectively disposed on two corners of two ends of the diagonal line of the base layer 100 , and two of the second dies 120 may be disposed on the central region of the base layer 100 . The arrangement of the second dies 120 may be combined with the array of the first dies 110 , that is, the arrangement position of each second die 120 may be located in the row of the array of the first dies 110 described above, but not limited herein. In some embodiments, the plurality of second dies 120 may be disposed in regions where the first dies 110 are not disposed to balance the stress, but not limited in. Please refer to FIG. 3 . The first die 110 may include a plurality of first conductive pads 112 , the surface of the first die 110 with the first conductive pads 112 disposed thereon may be referred as an active surface 110 a , and the first die 110 may further include a back surface 110 b opposite to the active surface 110 a . That is to say, the active surface 110 a and the back surface 110 b are located on opposite sides of the first die 110 , and the plurality of first conductive pads 112 are disposed on the active surface 110 a . The second die 120 may include a plurality of second conductive pads 122 , the surface of the second die 120 provided with the second conductive pads 122 may be referred to as an active surface 120 a , and the second die 120 may further include a back surface 120 b opposite to the active surface 120 a . That is to say, the active surface 120 a and the back surface 120 b are located on opposite sides of the second die 120 , and the plurality of second conductive pads 122 are disposed on the active surface 120 a . In some embodiments, the active surfaces 110 a of the first dies 110 and the active surfaces 120 a of the second dies 120 may be disposed in a face-down way, that is, the active surfaces 110 a of the first dies 110 and the active surfaces 120 a of the second dies 120 may face the carrier 102 , but not limited herein. In other embodiments, the active surfaces 110 a of the first dies 110 and the active surfaces 120 a of the second dies 120 may be disposed in a face-up way, that is, the back surfaces 110 b of the first dies 110 and the back surfaces 120 b of the second dies 120 may face the carrier 102 . Please refer to FIG. 4 . In some embodiments, as shown in FIG. 4 , the protective layer 130 may cover the back surfaces 110 b of the first dies 110 and the back surfaces 120 b of the second dies 120 . In other embodiments, the back surfaces 110 b of the first dies 110 and the back surfaces 120 b of the second dies 120 are not covered by the protective layer 130 . For example, the protective layer 130 may expose the back surfaces 110 b of the first dies 110 and the back surfaces 120 b of the second dies 120 by a grinding process, thereby further improving the heat dissipation of the dies, but not limited herein. In some embodiments, in a cross-sectional view of the electronic device shown as FIG. 3 , each of the plurality of first dies 100 may have a width W1 along the direction X, each of the plurality of second dies 120 may have a width W2 along the direction X, and the width W2 of each of the plurality of second dies 120 along the direction X may be less than the width W1 of each of the plurality of first dies 110 along the direction X (i.e., W2<W1) to reduce the space occupied by the second dies 120 in the base layer 100 , but not limited herein. In some embodiments, in a top view of the electronic device shown as FIG. 2 , each of the plurality of first dies 100 may have a die area A1, each of the plurality of second dies 120 may have a die area A2, and the die area A2 of each of the plurality of second dies 120 may be less than or equal to the die area A1 of each of the plurality of first dies 110 (i.e., A2≤A1) to reduce the space occupied by the second dies 120 in the base layer 100 . The “die area” herein may mean the area of an individual die or one single die in the top view shown as FIG. 2 . In some embodiments, the plurality of first dies 110 may have different die areas, and the largest die area is chosen as the die area A1, and the die area A2 of the second die 120 may be less than or equal to the die area A1, but not limited herein. In some embodiments, in the direction Z (i.e., the normal direction of the electronic device) shown as FIG. 3 , each of the plurality of first dies 100 may have a thickness T1, each of the plurality of second dies 120 may have a thickness T2, and the thickness T2 of each of the plurality of second dies 120 may be less than or equal to the thickness T1 of each of the plurality of first dies 110 (i.e., T2≤T1). From the above design, the thickness T2 of the second dies 120 will not be too large, such that there is no need to thicken the protective layer 130 subsequently formed, or the thinner second dies 120 will not be easily damaged when grinding the protective layer 130 . In some embodiments, the plurality of first dies 110 may have different thicknesses in the direction Z, and the largest thickness is chosen as the thickness T1, and the thickness T2 of the second die 120 may be less than or equal to the thickness T1, but not limited herein. Step S 200 may be performed after Step S 100 . As shown in Step S 200 , FIG. 5 and FIG. 6 , a circuit layer 200 is formed on the base layer 100 . FIG. 5 and FIG. 6 show the structure that the base layer 100 is further flipped upside-down after the release layer 104 and the carrier 102 are removed, so that the active surfaces 110 a of the first dies 110 and the active surfaces 120 a of the second dies 120 face upwards, which is beneficial to the following manufacturing of the circuit layer 200 on their surfaces. Specifically, the circuit layer 200 may be formed on the side where the active surfaces 110 a of the first dies 110 and the active surfaces 120 a of the second dies 120 are located. The circuit layer 200 may include at least one insulating layer and at least one conductive layer stacked in the direction Z to form a redistribution layer (RDL), so as to redistribute the circuit or further increase the fan-out area of the circuit. The entirety of the at least one insulating layer in the circuit layer 200 is represented by an insulating layer 210 , and the entirety of the at least one conductive layer is represented by a conductive layer 220 . For example, an insulating layer 210 ′ (as shown in FIG. 5 ) may be formed on the base layer 100 , and then the insulating layer 210 ′ may be patterned. For example, through holes (not shown) may be formed in the insulating layer 210 ′. Then, a conductive layer may be formed on the insulating layer 210 ′, and then the conductive layer may be patterned. The conductive layer may be filled in the through holes of the patterned insulating layer 210 ′. Then, the above steps of forming the patterned insulating layer and the patterned conductive layer may be repeated, so that at least one patterned insulating layer and at least one patterned conductive layer are alternately formed in sequence to manufacture the circuit layer 200 including the insulating layer 210 and the conductive layer 220 , but not limited herein. The insulating layer 210 may include organic materials, inorganic materials or dielectric materials, such as polyimide (PI), epoxy and/or silicon dioxide, or other suitable materials, but not limited herein. The conductive layer 220 may include, for example, copper or other suitable conductive materials. The conductive layer 220 may include a seed layer and a metal layer, and the seed layer and the metal layer may include single-layer material or multi-layer materials, such as titanium, copper, molybdenum, aluminum, nickel, silver, tin or combinations of the above, but not limited herein. The seed layer contributes to the formation of the metal layer or improves adhesion, but not limited herein. The circuit layer 200 may further include active elements or passive elements, such as thin film transistors (TFTs), electrostatic discharge protection devices (ESDs) and/or capacitors, but not limited herein. Step S 300 may be performed after Step S 200 . As shown in Step S 300 , an electricity test is performed to confirm whether the circuit layer 200 is electrically connected to one of the plurality of second dies 120 . For example, a probe PR shown in FIG. 6 may be used to perform the electricity test to the second die 120 for confirming whether the circuit layer 200 is electrically connected to the second die 120 , thereby monitoring whether the condition of the process is normal, and further observing whether a portion of the first dies 110 adjacent to the tested second die 120 or all of the first dies 110 meet the standard, for example, whether the electrical signals are abnormal such as occurring the situations of short circuit, open circuit or excessive signal loss rate, but not limited herein. In some embodiments, the electricity test described in the present disclosure may be achieved by other contact tests, non-contact tests or other suitable tests, so as to confirm whether the elements, structures, and/or electrical connections of the second die 120 and the corresponding circuit layer 200 are in normal condition, thereby monitoring the performance of the process, and accordingly confirming whether the elements, structures, and/or electrical connections of the first dies 110 and the circuit layer 200 meet the standard. Step S 400 may be performed after Step S 300 . As shown in Step S 400 and FIG. 6 , the circuit layer 200 is cut to form a plurality of circuit structures 300 . Specifically, the circuit layer 200 including the insulating layer 210 and the conductive layer 220 may be cut into the plurality of circuit structures 300 , so that each of the circuit structures 300 may respectively correspond to one of the first dies 110 and the second dies 120 , that is, each of the circuit structures 300 may correspond to the first die 110 or the second die 120 one by one, or each of the circuit structures 300 may be electrically connected to the first die 110 or the second die 120 one by one. Each of the circuit structures 300 may include a portion of the insulating layer 210 and a portion of the conductive layer 220 in the circuit layer 200 , and each of the plurality of circuit structures 300 may be a redistribution structure, but not limited herein. In some embodiments, the plurality of circuit structures 300 formed after cutting may be electrically isolated from each other, that is, the plurality of circuit structures 300 are separate structures and are not electrically connected to each other. In other embodiments, after cutting, a portion of the plurality of circuit structures 300 may be electrically connected to each other, such as (but not limited to) being electrically connected by a dummy line, and this portion of the plurality of circuit structures 300 may be electrically isolated from other portion of the plurality of circuit structures 300 . For example, the circuit structure 300 corresponding to one of the second dies 120 may be electrically connected to another circuit structure(s) 300 corresponding to at least one of the first dies 110 adjacent to the second die 120 , but these circuit structures 300 are electrically isolated from the other portion of circuit structures 300 . Taking a region R1 and a region R2 marked by the dotted-frames in FIG. 2 as examples, the circuit structures 300 corresponding to the first dies 110 and one second die 120 in the region R1 may be electrically connected to each other, and the circuit structures 300 corresponding to the first dies 110 and one second die 120 in the region R2 may be electrically connected to each other, but the circuit structures 300 corresponding to the first dies 110 and the second die 120 in the region R1 is electrically isolated from the circuit structures 300 corresponding to the first dies 110 and the second die 120 in the region R2. However, the electrical connection relationship among the plurality of circuit structures 300 is not limited herein, which may be adjusted according to practical requirements. Step S 500 may be performed after Step S 400 . As shown in Step S 500 and FIG. 6 , another electricity test is performed to confirm whether one of the plurality of circuit structures 300 is electrically connected to one of the plurality of second dies 120 . Specifically, the electricity test may be performed to the circuit structure 300 corresponding to one of the second die 120 , such as (but not limited to) using the probe PR shown in FIG. 6 to perform the electricity test to the circuit structure 300 corresponding to the second die 120 , so as to confirm whether the circuit structure 300 is electrically connected to the corresponding second die 120 , thereby monitoring whether the condition of the process is normal, and further knowing whether a portion of the first dies 110 adjacent to the tested second die 120 or all of the first dies 110 meet the standard, for example, whether the electrical signals are abnormal such as including as short circuit, open circuit or excessive signal loss rate, but not limited herein. In some embodiments, the electricity test described in the present disclosure may be achieved by other contact tests, non-contact tests or other suitable tests, so as to confirm whether the elements, structures, and/or electrical connections of the second die 120 and the corresponding circuit structure 300 are in normal status, thereby monitoring the condition of the process, and accordingly confirming whether the elements, structures, and/or electrical connections of the first die 110 and the corresponding circuit structure 300 meet the standard. In some embodiments, it may be compared that whether the elements, structure and/or electrical connections of the plurality of second dies 120 and their corresponding circuit structures 300 are in normal condition or have the same electrical properties. For example, if the difference between the resistance of one second die 120 and the resistance of another second die 120 is within 20%, it is considered that they are in normal condition. By monitoring the condition of the process through the electrical characteristics of the dummy dies (i.e., the second dies 120 ), and accordingly confirming whether the elements, structures, and/or electrical connections of the first dies 110 and the corresponding circuit structures 300 meet the standard, the process stability may be improved and real-time monitoring may be achieved. Taking the region R1 in FIG. 2 as an example, the electricity test may be performed to the circuit structure 300 corresponding to the second die 120 in the region R1 to confirm whether this circuit structure 300 is electrically connected to the corresponding second die 120 or has electricity performance complying with the requirement. When the tested circuit structure 300 is electrically connected to the corresponding second die 120 or the test result is good, it means that the condition of the process in the region R1 is normal, and it may be confirmed that the first dies 110 and the corresponding circuit structures 300 in the region R1 are good products. When the tested circuit structure 300 is not electrically connected to the corresponding second die 120 or has poor electricity performance, it means that the condition of the process in the region R1 is abnormal, so it is necessary to further test the first dies 110 and the corresponding circuit structures 300 in the region R1 or perform other corresponding procedures to solve the problem. Similarly, the corresponding electricity test may be performed on the region R2, the region R3 and the region R4 to monitor whether the condition of the process is normal, and to confirm whether the first dies 110 and the corresponding circuit structures 300 in each region are good products. The second dies 120 in the region R1, the region R2, the region R3 and the region R4 may be disposed at the corners or the positions where warpage is more likely to occur during the process, and the second die 120 corresponding to the central region may be used to monitor the uniformity of the process. By performing the electricity test to the second dies 120 (e.g., dummy dies) and their corresponding circuit structures 300 instead of directly testing the first dies 110 (e.g., product dies) and their corresponding circuit structures 300 , the condition of the process may be monitored during the manufacturing process, and the damage to the first dies 110 may be reduced, such as reducing the risk that the circuit structures 300 corresponding to the first dies 110 are scratched by the probe, thereby improving the quality and/or reliability of the products. In some embodiments, the step of performing the electricity test may include providing a voltage to one of the plurality of circuit structures 300 (i.e., the circuit structure 300 corresponding to one of the second dies 120 ) to obtain a resistance value of one of the plurality of second dies 120 . When the obtained resistance value is within a predetermined range, it means that this second die 120 and the corresponding circuit structure 300 are in normal condition, and at least one of the plurality of first dies 110 adjacent to this second die 120 and the corresponding circuit structure 300 may be confirmed as a good product. When the obtained resistance value is out of the predetermined range, it means that this second die 120 and the corresponding circuit structure 300 are abnormal, and it is necessary to further test the at least one first die 110 adjacent to this second die 120 and the corresponding circuit structure 300 or perform other corresponding procedures. In some embodiments, the tested one of the plurality of second dies 120 may be electrically isolated from the plurality of first dies 110 when performing the electricity test. Specifically, when performing the electricity test, the provided signal is transmitted to the second die 120 only through the corresponding circuit structure 300 , and this second die 120 is electrically isolated from the plurality of first dies 110 . For example, the circuit structure 300 corresponding to this second die 120 is electrically isolated from the circuit structures 300 corresponding to the plurality of first dies 110 , so that the signal may not be transmitted to the first dies 110 . That is to say, the electricity test may be performed only to the second die 120 and its corresponding circuit structure 300 . By confirming whether the second die 120 and its corresponding circuit structure 300 meet the predetermined standard, it may be used as a comparison sample to monitor and confirm whether a portion of the first dies 110 adjacent to the tested second die 120 or all of the first dies 110 and their corresponding circuit structures 300 meet the standard. In some embodiments, one of the plurality of second dies 120 to be tested may be electrically connected to one of the plurality of first dies 110 when performing the electricity test. For example, the tested second die 120 may be electrically connected to one or plural first dies 110 adjacent to the tested second die 120 . Specifically, when performing the electricity test, the provided signal is transmitted to the corresponding second die 120 through the circuit structure 300 , and this second die 120 may be electrically connected to one or plural first dies 110 . For example, the circuit structure 300 corresponding to this second die 120 is electrically connected to the circuit structure(s) 300 corresponding to adjacent one or plural first dies 110 , so that the signal may be transmitted to the electrically connected first die(s) 110 . That is to say, the signal may be transmitted to the first die(s) 110 through the circuit structures 300 that are electrically connected to each other when the electricity test is performed to the second die 120 and its corresponding circuit structure 300 , but not limited herein. According to the method for manufacturing the electronic device of the present disclosure, after Step S 500 is performed, if the results of the electricity test meet the predetermined standard to confirmed that the condition of the process is normal, that is, it is confirmed that the second die 120 and its corresponding circuit structure 300 meet the standard or are not abnormal, a protective layer (not shown) may be optionally formed on the plurality of circuit structures 300 to surround the plurality of circuit structures 300 , and the protective layer may expose the uppermost portion of the conductive layer 220 in each of the circuit structures 300 . Then, a plurality of conductive elements (e.g., the conductive elements 202 shown in FIG. 7 , FIG. 8 or FIG. 9 ) may be formed on the exposed conductive layer 220 in each of the circuit structures 300 . For example, a conductive element may be formed on one of the plurality of circuit structures 300 . Then, the base layer 100 may be cut along the cutting lines CL to obtain an electronic device DE including the first die 110 , as shown in FIG. 7 , which is a cross-sectional schematic diagram of an electronic device DE manufactured by a manufacturing method according to an embodiment of the present disclosure. For example, the electronic device DE may include a first die 110 , a protective layer 130 surrounding the first die 110 , a circuit structure 300 and optional conductive elements 202 . The conductive elements 202 are disposed on and electrically connected to the exposed conductive layer 220 in the circuit structure 300 to serve as bonding elements of the electronic device DE. The conductive element 202 may be, for example, a bump, a pad, a solder ball or other suitable bonding elements. The conductive element 202 may include, for example, copper, tin, nickel, gold, lead, other suitable conductive materials or combinations of the above materials, but not limited to the above. In addition, the conductive elements 202 of the electronic device DE may be further electrically connected to a circuit board (not shown), but not limited herein. Please refer to FIG. 8 and FIG. 9 . FIG. 8 is a top-view schematic diagram of first dies and a second die according to an embodiment of the present disclosure. FIG. 9 is a top-view schematic diagram of first dies and a second die according to another embodiment of the present disclosure, wherein FIG. 8 and FIG. 9 may be, for example, partially enlarged schematic diagrams of the elements shown in FIG. 6 . As shown in FIG. 8 and FIG. 9 , in some embodiments, one of the plurality of first dies 100 may include a plurality of first conductive pads 112 , and the first die 110 may be electrically connected to one of the plurality of circuit structures 300 through the plurality of first conductive pads 112 , that is, one first die 110 is electrically connected to its corresponding circuit structure 300 located on its upper side through the first conductive pads 112 . In the embodiment shown in FIG. 8 , the plurality of first conductive pads 112 may be disposed on opposite two sides of the active surface 110 a as two columns, for example. In the embodiment shown in FIG. 9 , the plurality of first conductive pads 112 may be disposed on the active surface 110 a in a ring shape, for example, or the first conductive pads 112 may be disposed on four sides (including the long sides and the short sides) of the active surface 110 a . However, the arrangement of the first conductive pads 112 is not limited to the above, that is, the first conductive pads 112 in the first die 110 may be disposed on the active surface 110 a in different ways according to the required practical designs. According to the present disclosure, in order to make the second conductive pads 122 of the second die 120 applicable and corresponding to various designs of the first conductive pads 112 of the first die 110 , one of the plurality of second dies 120 may include a plurality of second conductive pads 122 , and a number of the plurality of second conductive pads 122 may be different from a number of the plurality of first conductive pads 112 , or the number of the plurality of second conductive pads 122 may be greater than the number of the plurality of first conductive pads 112 . That is to say, by making the number of the second conductive pads 122 of one second die 120 greater than the number of the first conductive pads 112 of one first die 110 , suitable second conductive pads 122 may be selected to be electrically connected to the corresponding circuit structure 300 , thereby increasing the flexibility of applying the second die 120 to different product processes. For example, the second conductive pads 122 may be disposed on the active surface 120 a with the arrangement pattern as shown in FIG. 8 and FIG. 9 , so that the second die 120 may be suitable for monitoring the condition of the process of the first dies 110 as shown in FIG. 8 and the condition of the process of the first dies 110 as shown in FIG. 9 . In some embodiments, the second die 120 may be electrically connected to the corresponding circuit structure 300 through at least a portion of the second conductive pads 122 , that is, the portion of the second conductive pads 122 may correspond to the design of the first conductive pads 112 of the first die 110 to be monitored, and the other portion of the second conductive pads 122 are not used for electrical connection, but not limited herein. Through the electrical connection of the portion of the second conductive pads 122 and the corresponding circuit structure 300 described above, the second die 120 and the corresponding circuit structure 300 constitute a testing electronic device (or referred to as a dummy electronic device) TE for testing. Therefore, in the above Step S 500 , the electricity test may be performed on the testing electronic device TE including the second die 120 to monitor the electricity performance of other electronic devices DE including the first dies 110 . As shown in FIG. 8 and FIG. 9 , the electronic device DE and the testing electronic device TE may further include conductive elements 202 on the surfaces thereof. For example, the conductive elements 202 may be formed on the surface of the circuit layer 200 or the circuit structure 300 and electrically connected to the exposed conductive layer 220 in the circuit structure 300 . The conductive elements 202 may be used as the bonding elements of the electronic device DE, as shown in FIG. 7 , but not limited herein. Please refer to FIG. 10 . FIG. 10 is a schematic diagram illustrating a part of the process of a method for manufacturing an electronic device according to an embodiment of the present disclosure. As shown in FIG. 10 , in some embodiments, each of the plurality of second dies 120 may include an alignment mark 124 . The alignment may be performed according to the alignment mark 124 of the at least one second die 120 when disposing the first die 110 , so as to improve the accuracy of alignment in the process, thereby improving the utilization rate of the carrier 102 . Specifically, the process of forming the base layer 100 may include the following steps, for example. At first, the plurality of second dies 120 are disposed on a carrier 102 , such as (but not limited to) disposed at four corners of the carrier 102 . Then, the plurality of first dies 110 are disposed on the carrier 102 according to the alignment marks 124 of the plurality of second dies 120 . For example, in FIG. 10 , the first dies 110 disposed on the upper-left of the carrier 102 may be aligned according to the alignment mark 124 of the second die 120 on the upper-left, and the first dies 110 disposed on the upper-right of the carrier 102 may be aligned according to the alignment mark 124 of the second die 120 on the upper-right, so that the plurality of first dies 110 may be substantially disposed as an array along the direction X and the direction Y (the arrangement may be referred to FIG. 2 ). After the plurality of first dies 110 are disposed, a protective layer 130 (as shown in FIG. 4 ) may be formed to surround the plurality of first dies 110 and the plurality of second dies 120 . Then, the carrier 102 may be removed, thereby forming the base layer 100 . In some embodiments, when the active surfaces 120 a of the plurality of second dies 120 face the carrier 102 (as shown in FIG. 3 ), each of the alignment marks 124 may be respectively formed on the back surface 120 b of each of the plurality of second dies 120 . For example, the alignment mark 124 may be formed on the back surface 120 b of the second die 120 by an etching process or other suitable processes. Therefore, the alignment marks 124 may be used for the alignment when disposing the first dies 110 subsequently, but not limited herein. In some embodiments, when the back surfaces 120 b of the plurality of second dies 120 face the carrier 102 , each of the alignment marks 124 may be respectively formed on the active surface 120 a of each of the plurality of second dies 120 . For example, the alignment mark 124 may be formed on the active surface 120 a of the second die 120 by an etching process or other suitable processes. From the above description, according to the methods for manufacturing the electronic device of the embodiments of the present disclosure, by disposing the second dies, the condition of the process of the first dies may be monitored during the manufacturing process, thereby improving the quality and/or reliability of products. In the present disclosure, the first die is an element included in the electronic device to be manufactured, and the second die may be regarded as a dummy die used for the electricity test. Therefore, when performing the test, the testing electronic device including the second die may be tested without directly testing the circuit structure or the first die in the product electronic device, thereby reducing the probability of damaging the product electronic device due to the electricity test. In addition, by disposing the second dies including the alignment mark, the accuracy of alignment for the first dies in the process may be improved. Those skilled in the art will readily observe that numerous modifications and alterations of the device and method may be made while retaining the teachings of the disclosure. Accordingly, the above disclosure should be construed as limited only by the metes and bounds of the appended claims.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"019-938-126-062-539","jurisdiction":"US","doc_number":"12367614","kind":"B2","date_published":"2025-07-22","doc_key":"US_12367614_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12367614","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"18586746","date":"2024-02-26"},"priority_claims":{"claims":[{"jurisdiction":"GB","doc_number":"1912183","date":"2019-08-23","sequence":1},{"jurisdiction":"GB","doc_number":"1912184","date":"2019-08-23","sequence":2},{"jurisdiction":"GB","doc_number":"1912795","date":"2019-09-05","sequence":3},{"jurisdiction":"GB","doc_number":"1912800","date":"2019-09-05","sequence":4}],"earliest_claim":{"date":"2019-08-23"}},"invention_title":[{"text":"Random accessible image data compression","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"2662","extracted_name":{"value":"Duy M Dang"}}},"applicants":[{"residence":"GB","extracted_name":{"value":"Imagination Technologies Limited"},"extracted_address":"Kings Langley"}],"inventors":[{"residence":"GB","sequence":1,"extracted_name":{"value":"Xile Yang"},"extracted_address":"Rickmansworth"}],"agents":[{"extracted_name":{"value":"Potomac Law Group, PLLC"}},{"extracted_name":{"value":"Vincent M DeLuca"}}]},"classifications_ipcr":{"classifications":[{"symbol":"G06T9/00","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G06F7/50","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06F7/72","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06T3/40","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"G06T9/00","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G06F7/50","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06F7/727","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06T3/40","classification_value":"I","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"5647024","kind":"A","date":"1997-07-01"},"lens_id":"125-061-137-514-03X"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"10230982","kind":"B2","date":"2019-03-01"},"lens_id":"199-404-284-324-70X"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2007/0258518","kind":"A1","date":"2007-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2008/0018794","kind":"A1","date":"2008-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2008/0107174","kind":"A1","date":"2008-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2008/0123736","kind":"A1","date":"2008-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2009/0295816","kind":"A1","date":"2009-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2010/0027679","kind":"A1","date":"2010-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2013/0194384","kind":"A1","date":"2013-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0348437","kind":"A1","date":"2014-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0354666","kind":"A1","date":"2014-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0237348","kind":"A1","date":"2015-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0249064","kind":"A1","date":"2016-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0025098","kind":"A1","date":"2017-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0097981","kind":"A1","date":"2017-04-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0139909","kind":"A1","date":"2017-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0177227","kind":"A1","date":"2017-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0278215","kind":"A1","date":"2017-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0324983","kind":"A1","date":"2017-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0014021","kind":"A1","date":"2018-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0160129","kind":"A1","date":"2018-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0293778","kind":"A1","date":"2018-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0246117","kind":"A1","date":"2019-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0318524","kind":"A1","date":"2019-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2022/0405977","kind":"A1","date":"2022-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"103733623","date":"2014-04-01"}}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"104221383","kind":"A","date":"2014-12-01"},"lens_id":"110-641-087-721-503"}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"105052143","kind":"A","date":"2015-11-01"},"lens_id":"131-176-020-012-13X"}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"106104668","kind":"A","date":"2016-11-01"},"lens_id":"104-495-714-356-526"}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"107633538","kind":"A","date":"2018-01-01"},"lens_id":"099-046-778-354-623"}},{"patcit":{"document_id":{"jurisdiction":"EP","doc_number":"3059964","kind":"A1","date":"2016-08-01"},"lens_id":"044-084-983-189-294"}},{"patcit":{"document_id":{"jurisdiction":"EP","doc_number":"3035288","kind":"B1","date":"2018-07-01"},"lens_id":"124-108-889-414-161"}},{"patcit":{"document_id":{"jurisdiction":"GB","doc_number":"2451911","kind":"B","date":"2010-03-01"},"lens_id":"029-283-901-052-816"}},{"patcit":{"document_id":{"jurisdiction":"GB","doc_number":"2507838","kind":"B","date":"2014-09-01"},"lens_id":"078-035-943-499-135"}},{"patcit":{"document_id":{"jurisdiction":"GB","doc_number":"2530312","kind":"B","date":"2016-09-01"},"lens_id":"075-429-333-439-672"}},{"patcit":{"document_id":{"jurisdiction":"GB","doc_number":"2530311","kind":"B","date":"2017-01-01"},"lens_id":"187-935-194-312-032"}},{"patcit":{"document_id":{"jurisdiction":"GB","doc_number":"2567248","kind":"B","date":"2019-04-01"},"lens_id":"109-897-108-097-732"}},{"patcit":{"document_id":{"jurisdiction":"JP","doc_number":"2010278484","kind":"A","date":"2010-12-01"},"lens_id":"128-494-130-384-546"}},{"patcit":{"document_id":{"jurisdiction":"KR","doc_number":"20090108662","kind":"A","date":"2009-10-01"},"lens_id":"049-404-192-450-187"}},{"patcit":{"document_id":{"jurisdiction":"TW","doc_number":"380337","kind":"B","date":"2000-01-01"},"lens_id":"155-402-321-195-64X"}},{"patcit":{"document_id":{"jurisdiction":"WO","doc_number":"2016009159","kind":"A1","date":"2016-01-01"},"lens_id":"112-071-310-665-331"}}],"patent_count":41},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367614","kind":"B2","date":"2025-07-22"},"lens_id":"019-938-126-062-539"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367614","kind":"B2","date":"2025-07-22"},"lens_id":"019-938-126-062-539"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"Methods and compression units for compressing a block of image data, the block of image data comprising a plurality of image element values, the image element values being divisible into at least a first value and a second value such that the block of image data comprises a two-dimensional block of first values, the method comprising: compressing a first data set comprising all or a portion of the two-dimensional block of first values in accordance with a first fixed-length compression algorithm to generate a first compressed block by: identifying common base information for the first data set; and identifying a fixed-length parameter for each first value in the first data set, the fixed-length parameter being zero, one or more than one bits in length; and forming a compressed block for the block of image data based on the first compressed block.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A lossless method of compressing a block of image data, the block of image data comprising a plurality of image element values that are divided into a plurality of sub-blocks of image element values, each image element value being divisible into at least a first value and a second value, the method comprising: generating a compressed block for the block of image data that comprises a data unit for each image element value, each data unit comprising (i) first data representing the first value of the corresponding image element value, and (ii) second data, different to the first data, representing the second value of the corresponding image element value; wherein the first data for each image element value in a same sub-block is a same size and is generated by a same fixed-length compression algorithm of one or more fixed-length compression algorithms and the second data for each image element value in a same sub-block is a same size and is generated by a same fixed-length compression algorithm of the one or more fixed-length compression algorithms; and wherein the first value of each image element value in a same sub-block is obtainable from the first data representing that first value and common base information in the compressed block that is common to first values in the sub-block and the second value of each image element value in a same sub-block is obtainable from the second data representing that second value and common base information in the compressed block that is common to second values in the sub-block."]},{"claim_text":["2. The method of claim 1 , wherein the first data for each image element value in a first set of one or more sub-blocks is generated by a same fixed-length compression algorithm of the one or more fixed-length compression algorithms and the compressed block comprises common base information that is common to the first values in the first set of one or more sub-blocks."]},{"claim_text":["3. The method of claim 2 , wherein the second data for each image element value in a second set of one or more sub-blocks is generated by a same fixed-length compression algorithm of the one or more fixed-length compression algorithms and the compressed block comprises common base information that is common to the second values in the second set of one or more sub-blocks."]},{"claim_text":["4. The method of claim 3 , wherein the first set of one or more sub-blocks comprises a different number of sub-blocks than the second set of one or more sub-blocks."]},{"claim_text":["5. The method of claim 3 , further comprising: dynamically selecting the second set of one or more sub-blocks; determining whether the second values in the plurality of sub-blocks can be suitably compressed as a unit using a fixed-length compression algorithm of the one or more fixed-length compression algorithms; in response to determining that the second values in the plurality of sub-blocks can be suitably compressed as a unit using a fixed-length compression algorithm of the one or more fixed-length compression algorithms, selecting the plurality of sub-blocks as the second set of one or more sub-blocks; and in response to determining that the second values in the plurality of sub-blocks cannot be suitably compressed as a unit using a fixed-length compression algorithm of the one or more fixed-length compression algorithms, selecting a subset of the plurality of sub-blocks as the second set of one or more sub-blocks."]},{"claim_text":["6. The method of claim 3 , wherein the first set of one or more sub-blocks comprises a different number of sub-blocks from the second set of one or more sub-blocks."]},{"claim_text":["7. The method of claim 1 , further comprising, dynamically selecting the first set of one or more sub-blocks by: determining whether the first values in the plurality sub-blocks can be suitably compressed as a unit using a fixed-length compression algorithm of the one or more fixed-length compression algorithms; in response to determining that the first values in the plurality of sub-blocks can be suitably compressed as a unit using a fixed-length compression algorithm of the one or more fixed-length compression algorithms, selecting the plurality of sub-blocks as the first set of one or more sub-blocks; and in response to determining that the first values in the plurality of sub-blocks cannot be suitably compressed as a unit using a fixed-length compression algorithm of the one or more fixed-length compression algorithms, selecting a subset of the plurality of sub-blocks as the first set of one or more sub-blocks."]},{"claim_text":["8. The method of claim 1 , wherein the fixed-length compression algorithm used to generate the first data for the first values in a sub-block is different to the fixed-length compression algorithm used to generate the second data for the second values in the sub-block."]},{"claim_text":["9. The method of claim 1 , wherein the one or more fixed-length compression algorithms comprises a plurality of fixed-length compression algorithms, the method further comprising: analysing the first values in a set of one or more sub-blocks to generate one or more diversity statistics, the one or more diversity statistics include one or more of: a range of first values in the set of one or more sub-blocks, a minimum first value in the set of one or more sub-blocks, a maximum first value in the set of one or more sub-blocks, and a number of unique first values in the set of one or more sub-blocks; and selecting one of the plurality of fixed-length compression algorithms to be used to generate the first data for the first values in the set of one or more sub-blocks based on the one or more diversity statistics."]},{"claim_text":["10. The method of claim 1 , wherein the one or more fixed-length compression algorithms comprises a fixed length compression algorithm in which if each first value in a set of one or more sub-blocks is the same and matches one of one or more predetermined values, the common base information for the first values of the set of one or more sub-blocks contains information identifying said one of the one or more predetermined values, and the first data for each first value in the set of one or more sub-blocks has zero bits."]},{"claim_text":["11. The method of claim 1 , wherein each sub-block has a same size."]},{"claim_text":["12. The method of claim 1 , wherein the one or more fixed-length compression algorithms comprises a fixed-length compression algorithm in which the common base information for the first values in a set of one or more sub-blocks comprises an origin based on the first values in the set of one or more sub-blocks and the first data for each first value in the set of one or more sub-blocks comprises a difference between the first value and the origin."]},{"claim_text":["13. The method of claim 1 , wherein the one or more fixed-length compression algorithms comprises a fixed-length compression algorithm in which the common base information for the first values in a set of one or more sub-blocks comprises a plurality of origins based on the first values in the set of one or more sub-blocks and the first data for each first value in the set of one or more sub-blocks comprises an index identifying one of the plurality of origins and a difference between the value and that origin."]},{"claim_text":["14. The method of claim 1 , wherein the one or more fixed-length compression algorithms comprises a fixed-length compression algorithm in which the common base information for the first values in a set of one or more sub-blocks comprises a look-up table of unique first values in the set of one or more sub-blocks and the first data for a first value in the set of one or more sub-blocks comprises an index to the look-up table."]},{"claim_text":["15. The method of claim 1 , wherein the one or more fixed-length compression algorithms comprises a fixed-length compression algorithm in which, if all the first values in a set of one or more sub-blocks are the same, the common base information comprises that common value and the first data for each first value in the set of one or more sub-blocks has zero bits."]},{"claim_text":["16. The method of claim 1 , wherein the compressed block further comprises information indicating the fixed-length compression algorithm of the one or more fixed-length compression algorithms used to generate the first data for each sub-block."]},{"claim_text":["17. The method of claim 1 , wherein the compressed block further comprises information indicating the size of the first data for each sub-block and the size of the second data for each sub-block."]},{"claim_text":["18. The method of claim 1 , wherein each image element value is a colour value, each first value is a colour value for a first colour channel and each second value is a colour value for a second colour channel."]},{"claim_text":["19. A non-transitory computer readable storage medium having stored thereon computer readable instructions that, when executed at a computer system, cause the computer system to perform the method as set forth in claim 1 ."]},{"claim_text":["20. A compression unit to compress a block of image data, the block of image data comprising a plurality of image element values that are divided into a plurality of sub-blocks of image element values, each image element value being divisible into at least a first value and a second value, the compression unit being configured to: generate a compressed block for the block of image data that comprises a data unit for each image element value, each data unit comprising (i) first data representing the first value of the corresponding image element value, and (ii) second data, different to the first data, representing the second value of the corresponding image element value; wherein the first data for each image element value in a same sub-block is a same size and is generated by a same fixed-length compression algorithm of one or more fixed-length compression algorithms and the second data for each image element value in a same sub-block is a same size and is generated by a same fixed-length compression algorithm of the one or more fixed-length compression algorithms; and wherein the first value of each image element value in a same sub-block is obtainable from the first data representing that first value and common base information in the compressed block that is common to first values in the sub-block and the second value of each image element value in a same sub-block is obtainable from the second data representing that second value and common base information in the compressed block that is common to second values in the sub-block."]}],"lang":"en"}],"description":{"text":"CROSS-REFERENCE TO RELATED APPLICATIONS AND CLAIM OF PRIORITY This application is a continuation, under 35 U.S.C. 120, application Ser. No. 17/890,463 filed Aug. 18, 2022, now U.S. Pat. No. 11,915,455, which is a continuation of prior application Ser. No. 17/001,160 filed Aug. 24, 2020, now U.S. Pat. No. 11,443,457, which claims foreign priority under 35 U.S.C. 119 from United Kingdom Application Nos. 1912800.8 and 1912795.0 filed on Sep. 5, 2019, and United Kingdom Application Nos. 1912184.7 and 1912183.9 filed on Aug. 23, 2019, the contents of which are incorporated by reference herein in their entirety. BACKGROUND Data compression, both lossless and lossy, is desirable in many applications in which data is to be stored in, and/or read from memory. By compressing data before storage of the data in memory, the amount of data transferred to the memory may be reduced. An example of data for which data compression is particularly useful is image data. The term ‘image data’ is used herein to refer to two-dimensional data that has a value corresponding to each pixel or each sample location of an image that is produced as part of a rasterization process on a Graphics Processing Unit (GPU). Image data includes, but is not limited to, depth data to be stored in a depth buffer, pixel data (e.g. colour data) to be stored in a frame buffer, texture data to be stored in a texture buffer and surface normal data to be stored in a surface normal buffer. These buffers may be any suitable type of memory, such as cache memory, separate memory subsystems, memory areas in a shared memory system or some combination thereof. A GPU may be used to process data in order to generate image data. For example, a GPU may determine pixel values (e.g. colour values) of an image to be stored in a frame buffer which may be output to a display. GPUs usually have highly parallelised structures for processing large blocks of data in parallel. There is significant commercial pressure to make GPUs (especially those intended to be implemented on mobile/embedded devices) operate at lower power levels. Competing against this is the desire to use higher quality rendering algorithms on fast GPUs, which thereby puts pressure on a relatively limited resource: memory bandwidth. However, increasing the bandwidth of the memory subsystem might not be an attractive solution because moving data to and from, and even within, the GPU consumes a significant portion of the power budget of the GPU. The same issues may be relevant for central processing units (CPUs) as well as GPUs. FIG. 1 shows an example graphics rendering system 100 which may be implemented in an electronic device, such as a mobile/embedded device. The graphics rendering system 100 comprises a host CPU 102 , a GPU 104 , a memory 106 (e.g. graphics memory) and a display 108 . The CPU 102 is configured to communicate with the GPU 104 . Data, which may be compressed data, can be transferred in either direction, between the GPU 104 and the memory 106 . Images (e.g. pixel data) which are rendered by the GPU 104 may be stored in memory 106 and displayed on the display 108 via a display interface 116 . The GPU 104 comprises a rendering unit 110 , a compression/decompression unit 112 , and a memory interface 114 . The graphics rendering system 100 is arranged such that data can pass, in either direction, between (i) the CPU 102 and the rendering unit 110 ; (ii) the CPU 102 and the memory interface 114 ; (iii) the memory interface 114 and the memory 106 ; (iv) the rendering unit 110 and the compression/decompression unit 112 ; (v) the compression/decompression unit 112 and the memory interface 114 ; and (vi) the memory 106 and the display interface 116 . In some examples, the graphics rendering system 100 may be further arranged such that data can pass to and from the compression/decompression unit 112 to the display interface 116 , and such that data can pass from the display interface 116 to the display 108 . In operation, the GPU 104 processes regions of image data individually. The regions may for example represent rectangular (including square) portions of the render space (i.e. the two-dimensional space representing, for example, an image area to be rendered). The rendering unit 110 may perform scan conversion and rasterization of graphics primitives, such as, but not limited to, triangles and lines, using known techniques such as Z-tests and texture mapping. The rendering unit 110 may contain cache units to reduce memory traffic. Some data is read or written by the rendering unit 110 , to the memory 106 via the memory interface 114 (which may include a cache) but for other data, such as data to be stored in a buffer, such as the frame buffer, the data preferably goes from the rendering unit 110 to the memory interface 114 via the compression/decompression unit 112 . The compression/decompression unit 112 reduces the amount of data that is to be transferred across the external memory bus to the memory 106 by compressing the data. The display interface 116 sends data defining a completed image to the display 108 . An uncompressed image may be accessed directly from the memory 106 . Compressed data may be decompressed via the compression/decompression unit 112 and sent as uncompressed data to the display 108 . In alternative examples the compressed data could be read directly by the display interface 116 and the display interface 116 could include logic for decompressing the compressed data in an equivalent manner to the decompression of the compression/decompression unit 112 . Although shown as a single entity, the compression/decompression unit 112 may contain multiple parallel compression and/or decompression units for enhanced performance. As is known to a person of skill in the art, the rendering unit 110 may generate a set of one or more colour values (e.g. RGB or RGBA) for each pixel in the render space and store the colour values in the frame buffer. The collection of colour values for a frame may be referred to herein as colour data, image data, frame buffer data or simply frame data. The rendering unit 110 may also generate other image data, such as depth data, surface normal data, lighting data, etc., and may store those image data values in one or more buffers in memory. These buffers may, in some cases, be referred to as frame buffers, while in other cases the term “frame buffer” may be reserved for buffers which store colour values or which store data to be sent to the display. In some graphics rendering systems the image data values stored in a buffer for a particular render may be used by the rendering unit 110 to render one or more subsequent frames. For example, colour values generated by one render may be used as texture values in the rendering of one or more subsequent frames, and surface normal values generated for a geometric model in one render may be used to apply lighting effects to the same model during the rendering of one or more subsequent frames. Since the image data (e.g. colour data) can be quite large the memory bandwidth associated with writing image data to a buffer in memory and reading the image data from the buffer in memory may be a significant portion of the total memory bandwidth of the graphics processing system and/or the GPU. As a result, the image data is often compressed, via the compression/decompression unit 112 , prior to being stored in a buffer and decompressed, via the compression/decompression unit 112 , after being read from the buffer. Since image data often comprises colour data, compression methods may be designed to suit the particular characteristics of colour image data. In other examples, compression methods may be designed for the different characteristics of depth data, or surface normal data. Known lossless methods for compressing colour data, such as those described in the Applicant's UK Patents 2451911, 2530312 and 2530311, are configured to divide the colour data into blocks and compress each block individually in a manner that requires the whole block to be decompressed together. For example, in these compression methods an 8×8 pixel block of colour values may be compressed together. Then to access any particular colour value in that block the whole 8×8 pixel block has to be decompressed. However, the rendering unit 110 doesn't typically need all the data (e.g. colour values) in a block for rendering a subsequent frame. For example, the rendering unit 110 may only need colour values related to a few pixels in a block. Accordingly, having to decompress a whole block to access only a small number of colour values in that block can make accessing the colour data in the frame buffer inefficient for the rendering unit 110 . Attempts have been made to address this problem by caching the decompressed blocks, but in many cases having a cache doesn't significantly improve the efficiency of accessing the data (e.g. colour values) in the frame buffer. Other attempts made to address this problem include reducing the block sizes (e.g. reducing the block size to a 4×4 block of colour values), but the inefficiency of having to decompress a whole block to access the colour values for a few pixels has shown to exist at any block level and the smaller the blocks the less efficient the compression is. The embodiments described below are provided by way of example only and are not limiting of implementations which solve any or all of the disadvantages of known image data compression and/or decompression methods. SUMMARY This summary is provided to introduce a selection of concepts that are further described below in the detailed description. This summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter. Described herein are methods and compression units for compressing a block of image data, the block of image data comprising a plurality of image element values, the image element values being divisible into at least a first value and a second value such that the block of image data comprises a two-dimensional block of first values, the method comprising: compressing a first data set comprising all or a portion of the two-dimensional block of first values in accordance with a first fixed-length compression algorithm to generate a first compressed block by: identifying common base information for the first data set; and identifying a fixed-length parameter for each first value in the first data set, the fixed-length parameter being zero, one or more than one bits in length; and forming a compressed block for the block of image data based on the first compressed block. A first aspect provides a method of compressing a block of image data, the block of image data comprising a plurality of image element values, the image element values being divisible into at least a first value and a second value such that the block of image data comprises a two-dimensional block of first values, the method comprising: compressing a first data set comprising all or a portion of the two-dimensional block of first values in accordance with a first fixed-length compression algorithm to generate a first compressed block by: identifying common base information for the first data set; and identifying a fixed-length parameter for each first value in the first data set, the fixed-length parameter being zero, one or more than one bits in length; and forming a compressed block for the block of image data based on the first compressed block. The first data set may comprise a first portion of the two-dimensional block of first values, and the method may further comprise compressing a second data set comprising a second portion of the two-dimensional block of first values in accordance with a second fixed-length compression algorithm to generate a second compressed block, and wherein the compressed block for the block of image data is further based on the second compressed block. The first and second fixed-length compression algorithms may be different. The first and second data sets may be different sizes. The method may further comprise sub-dividing the two-dimensional block of first values into a plurality of sub-blocks, and wherein the first data set is one of the plurality of sub-blocks. The method may further comprise, prior to compressing the first data set, selecting the first data set by: sub-dividing the two-dimensional block of first values into a plurality of sub-blocks; determining whether one of the sub-blocks can be suitably compressed using a fixed-length compression algorithm; in response to determining that the one of the sub-blocks can be suitably compressed using a fixed-length compression algorithm, selecting the one of the sub-blocks as the first data set; and in response to determining that the one of the sub-blocks cannot be suitably compressed using a fixed-length compression algorithm, sub-dividing the one of the sub-blocks into a plurality of mini-blocks and selecting one of the mini-blocks as the first data set. The method may further comprise, prior to compressing the first data set, selecting the first data set by: determining whether the two-dimensional block of first values can be suitably compressed using a fixed-length compression algorithm; in response to determining that the two-dimensional block of first values can be suitably compressed using a fixed-length compression algorithm, selecting the two-dimensional block of first values as the first data set; and in response to determining that the two-dimensional block of first values cannot be suitably compressed using a fixed-length compression algorithm, sub-dividing the two-dimensional block of first values into a plurality of sub-blocks and selecting one of the sub-blocks as the first data set. Determining whether a block or sub-block of values can be suitably compressed using a fixed-length compression algorithm may comprise determining whether a size of the compressed block or sub-block when the block or sub-block is compressed in accordance with the fixed-length compression algorithm is less than or equal to a predetermined threshold. The block of image data may further comprise a two-dimensional block of second values. Each value in the two-dimensional block of second values may be a colour value for a second colour channel. The method may further comprise: compressing a third data set comprising all or a portion of the two-dimensional block of second values using a third fixed-length compression algorithm to generate a third compressed block by: identifying common base information for the third data set; and identifying a fixed-length parameter for each second value in the third data set, the fixed-length parameter being zero, one or more than one bits in length; and wherein the compressed block for the block of image data is further based on the third compressed block. The first and third fixed-length compression algorithms may be different. Each first value and each second value may correspond to a pixel. The compressed block for the block of image data may comprises a pixel data unit for each pixel, the pixel data unit comprising: first data representing the first value in the two-dimensional block of first values corresponding to that pixel, the first data comprising the first value or a fixed-length parameter for that first value generated in accordance with a fixed-length compression algorithm; and second data representing the second value in the two-dimensional block of second values corresponding to that pixel, the second data comprising the second value or a fixed-length parameter for that second value generated in accordance with a fixed-length compression algorithm. The pixel data units may be grouped into blocks and the first data of each pixel data unit in a block may be the same size and the second data of each pixel data unit in a block may be the same size. Each block of pixel data units may comprise X pixel data units; the first data set may comprise Y values of the two-dimensional block of first values; and X is an integer greater than or equal to two and Y is an integer multiple of X. The method may further comprise: analysing the first values in the first data set to generate one or more diversity statistics; and selecting one of a plurality of fixed-length compression algorithms to be the first fixed-length compression algorithm based on the one or more diversity statistics. The one or more diversity statistics may include one or more of: a range of values in the first data set, a minimum value in the first data set, a maximum value in the first data set, and a number of unique values in the first data set. If each value of the first data set is the same and matches one of one or more predetermined values, the common base information may comprise information identifying the one of the one or more predetermined values and the fixed-length parameter for each value may have zero bits. The one or more predetermined values may comprise only a single value and the information identifying the one of the one or more predetermined values may comprise information identifying a particular fixed-length compression algorithm was used to compress the first data set. The one or more predetermined values may comprise a plurality of values. At least a portion of the plurality of values may be dynamically configurable. At least a portion of the plurality of values may be fixed. The block of image data may further comprise a two-dimensional block of second values; and if all of the values of the first data set are the same and match a first predetermined value, and all the values of a third data set are the same and match a second predetermined value, wherein the third data set comprises the second values of the two-dimensional block of second values corresponding to the values in the first data set, then the common base information may comprise information identifying the first and second predetermined values and the fixed-length parameters may have zero bits. The common base information may comprise an origin based on the values in the first data set and the fixed-length parameter for each value may comprise a difference between the value and the origin. The origin may be a minimum value in the first data set. A size of the fixed-length parameter may be based on a range of values in the first data set. The range may be selected as a smallest range according to modulo m arithmetic wherein m is 2 x and each value in the two-dimensional block of first values comprises x bits. The common base information may comprise a plurality of origins based on the values in the first data set and the fixed-length parameter for each value may comprise an index identifying one of the plurality of origins and a difference between the value and that origin. The common base information may comprise a look-up table of unique values in the first data set and the fixed-length parameter for a value may comprise an index to the look-up table. If all the values in the first data set are the same, the common base information may comprise that common value and the fixed-length parameter for each value may have zero bits. The method may further comprise forming a header for the compressed block of image data, wherein the header comprises the common base information and information that indicates a size of the fixed-length parameter. The header may further comprise information indicating the first fixed-length compression algorithm. Each image element value may be a colour value. Each value in the two-dimensional block of first values may be a colour value for a first colour channel. The block of image data may comprise image data generated by a rasterization process on a graphics processing unit. The first value may be a multi-bit value and the second value may be a multi-bit value. The first value may be an eight-bit value and the second value may be an eight-bit value. The method may further comprise storing the compressed block for the block of image data in memory. A second aspect provides a compression unit to compress a block of image data, the block of image data comprising a plurality of image element values, the image element values being divisible into at least a first value and a second value such that the block of image data comprises a two-dimensional block of first values, the compression unit comprising: a header generation unit configured to identify common base information for compressing a first data set according to a first fixed-length compression algorithm, the first data set comprising all or a portion of the two-dimensional block of first values; and a body generation unit configured to: identify a fixed-length parameter for each first value in the first data set according to the first fixed-length compression algorithm; and form a compressed block for the block of image data based on the common base information and the fixed-length parameters. A third aspect provides a compression unit configured to perform the method of the first aspect. The compression units, decompression units and compression/decompression units described herein may be embodied in hardware on an integrated circuit. There may be provided a method of manufacturing, at an integrated circuit manufacturing system, a compression unit, a decompression unit or a compression/decompression unit described herein. There may be provided an integrated circuit definition dataset that, when processed in an integrated circuit manufacturing system, configures the system to manufacture the compression unit, the decompression unit or the compression/decompression unit. There may be provided a non-transitory computer readable storage medium having stored thereon a computer readable description of a compression unit, a decompression unit or a compression/decompression unit that, when processed in an integrated circuit manufacturing system, causes the integrated circuit manufacturing system to manufacture an integrated circuit embodying a compression unit, a decompression unit or a compression/decompression unit. There may be provided an integrated circuit manufacturing system comprising: a non-transitory computer readable storage medium having stored thereon a computer readable description of a compression unit, a decompression unit or a compression/decompression unit described herein; a layout processing system configured to process the computer readable description so as to generate a circuit layout description of an integrated circuit embodying the compression unit, the decompression unit or the compression/decompression unit; and an integrated circuit generation system configured to manufacture the compression unit, decompression unit, or the compression/decompression unit according to the circuit layout description. There may be provided computer program code for performing a method as described herein. There may be provided non-transitory computer readable storage medium having stored thereon computer readable instructions that, when executed at a computer system, cause the computer system to perform the methods as described herein. The above features may be combined as appropriate, as would be apparent to a skilled person, and may be combined with any of the aspects of the examples described herein. BRIEF DESCRIPTION OF THE DRAWINGS Examples will now be described in detail with reference to the accompanying drawings in which: FIG. 1 is a block diagram of an example graphics rendering system; FIG. 2 is a flow diagram of an example method for compressing a block of image data; FIG. 3 is a schematic diagram illustrating an example block of image data comprising data for multiple colour channels; FIG. 4 is a schematic diagram illustrating a channel block divided into a plurality of sub-blocks; FIG. 5 is a graph illustrating the percentage of colour channels with a common colour value for an example benchmark; FIG. 6 is a schematic diagram illustrating a set of colour values falling into two clusters; FIG. 7 is a schematic diagram illustrating modulo arithmetic; FIG. 8 is a graph illustrating the number of delta bits used to compress 8×8 channel blocks/sub-blocks using the origin and delta compression algorithm for an example benchmark test; FIG. 9 is a graph illustrating the number of delta bits used to compress 16×16 channel blocks/sub-blocks using the origin and delta compression algorithm for an example benchmark test; FIG. 10 is a graph illustrating the number of delta bits used to compress 32×32 channel blocks/sub-blocks using the origin and delta compression algorithm for an example benchmark test; FIG. 11 is a schematic diagram illustrating a second set of colour values falling into two clusters; FIG. 12 is a schematic diagram illustrating compressing an example channel sub-block using the look-up table compression algorithm; FIG. 13 is a graph illustrating the distribution of channel colour values for unique channel blocks for a plurality of applications; FIG. 14 is a graph illustrating the distribution of compression algorithms for a plurality of applications when the compression algorithms comprise the origin and delta compression algorithm, the predetermined colour compression algorithm and the look-up table compression algorithm; FIG. 15 is a schematic diagram of a first example compressed block format when the channel blocks are not divided into sub-blocks prior to compression; FIG. 16 is a schematic diagram of a second example compressed block format when the channel blocks are not divided into sub-blocks prior to compression; FIG. 17 is a schematic diagram of an example compressed block format when the channel blocks are divided into sub-blocks prior to compression; FIG. 18 is a schematic diagram of a block of image data wherein each channel block is divided into a plurality of sub-blocks; FIG. 19 is a flow diagram of a first example method for selecting a fixed-length compression algorithm for compressing a channel block/sub-block; FIG. 20 is a flow diagram of a second example method for selecting a fixed-length compression algorithm for compressing a channel block/sub-block; FIG. 21 is a schematic diagram of a channel block that is divided into multiple levels of blocks; FIG. 22 is a flow diagram of an example method for selecting the blocks of a channel block to compress; FIG. 23 is a schematic diagram of an example header for a compressed block when a hierarchical compression scheme is used; FIG. 24 is a block diagram of an example compression unit for compressing a block of image data; FIG. 25 is a block diagram of an example decompression unit for decompressing a compressed block of image data that was compressed using the method of FIG. 2 ; FIG. 26 is a flow diagram of an example method of decompressing a block of image data that was compressed using the method of FIG. 2 ; FIG. 27 is a graph illustrating the size of the compressed blocks of image data compared to the size of the uncompressed blocks of image data for a variety of compression schemes for a benchmark test; FIG. 28 is a graph illustrating the percentage of channel blocks with a common colour value for a plurality of different benchmark tests; FIG. 29 is a graph illustrating the size of the compressed blocks of image data compared to the size of the uncompressed blocks of image data for a variety of compression schemes for a plurality of different benchmark tests; FIG. 30 is a block diagram of an example computer system in which the compression units, decompression units and/or compression/decompression units described herein may be implemented; and FIG. 31 is a block diagram of an example integrated circuit manufacturing system for generating an integrated circuit embodying a compression unit, a decompression unit or a compression/decompression unit described herein. The accompanying drawings illustrate various examples. The skilled person will appreciate that the illustrated element boundaries (e.g., boxes, groups of boxes, or other shapes) in the drawings represent one example of the boundaries. It may be that in some examples, one element may be designed as multiple elements or that multiple elements may be designed as one element. Common reference numerals are used throughout the figures, where appropriate, to indicate similar features. DETAILED DESCRIPTION The following description is presented by way of example to enable a person skilled in the art to make and use the invention. The present invention is not limited to the embodiments described herein and various modifications to the disclosed embodiments will be apparent to those skilled in the art. Embodiments are described by way of example only. As described above, compressing image data on a block basis in a manner that requires decompression of the whole block to access individual values makes it difficult for the logic, such as the rendering logic, that randomly accesses the image data to access the data efficiently. What is therefore needed is a lossless method of compressing image data which allows the compressed data to be randomly accessed (i.e. individual values in the compressed block can be accessed without having to decompress the whole block). Accordingly, described herein are methods and systems for compressing a block of image data so that the individual values of the block can be decompressed without having to decompress the whole block. Specifically, described herein are methods and systems for compressing a block of image data that comprises a plurality of image element values (e.g. colour values) that are divisible into at least a first value and a second value (e.g. a first channel colour value and a second channel colour value) such that the image data comprises at least a two-dimensional block of first values (e.g. a two-dimensional block of colour values for the first colour channel) and a two-dimensional block of second values (e.g. a two-dimensional block of colour values for the second colour channel). The term ‘image element value’ is used herein to refer to the unit of the particular image data. Accordingly the image element value is dependent on the type of image data. For example, for colour data the image element value is a pixel value or colour value (e.g. which may be defined by a set of channel colour values); for depth data the image element value is a depth value; for surface normal data the image element value is a surface normal direction (e.g. which may be defined by a set of values representing a unit vector or one or more angles); and for texture data the image element value is a texel value (e.g. which may be defined by a colour value or a set of colour values). In the methods and systems described herein each two-dimensional block of values is compressed separately using one or more fixed-length compression algorithms. In particular, in the methods and systems described herein one or more of the two-dimensional blocks of values is compressed by compressing all or a portion of the two-dimensional block of values using a fixed-length compression algorithm wherein values in the two-dimensional block (or a portion thereof) are represented by common base information and a fixed-length parameter for each value in the block (or a portion thereof) that is zero, one or more than one bits in length. A compressed block for the image data is then formed from the common base information and the fixed-length parameters. By compressing a two-dimensional block of values (or a portion thereof) using a fixed-length compression algorithm all of the values in that two-dimensional block (or the portion thereof) are represented using the same number of bits thus the portion of the compressed data that relates to a particular value can be easily identified. In some example methods and systems described herein the image data is divided into one or more blocks (e.g. 32×32 blocks of image elements, 16×16 blocks of image elements or 8×8 blocks of image elements) and the values in any two-dimensional block of values (e.g. each colour channel) in a block are represented by a fixed number of bits. For example, if the image data is colour data that comprises colour values for four channels numbered 0 to 3 and the image data is divided into 8×8 blocks of pixels then each channel 0 colour value in a particular 8×8 block of pixels will be represented by the same number of bits b 0 , each channel 1 colour value in that 8×8 block of pixels will be represented by the same number of bits b 1 , each channel 2 colour value in that 8×8 block of pixels will be represented by the same number of bits b 2 , and each channel 3 colour value in that 8×8 block of pixels will be represented by the same number of bits b 3 . Thus if all the bits that relate to the same pixel are packed together to form a pixel data unit then each pixel data unit will have b 0 +b 1 +b 2 +b 3 bits. If the pixel data units for a block are then packed together in pixel order to form a block data unit then the start of the pixel data unit for the i th pixel, wherein the first pixel is numbered 0, is at the i*(b 0 +b 1 +b 2 +b 3 ) bit from the start of the block data unit. The particular bits of the pixel data unit that correspond to a particular colour value can then be determined from b 0 , b 1 , b 2 , b 3 and the ordering of the channels in the pixel data unit. For example if the bits of each channel are packed together in the pixel data unit in channel order then the bits corresponding to the colour value for channel 0 are the first b 0 bits in the pixel data unit; the bits corresponding to the colour value for channel 1 are the b 1 bits starting from bit b 0 ; the bits corresponding to the colour value for channel 2 are the b 2 bits starting from bit b 0 +b 1 ; and the bits corresponding to the colour value for channel 3 are the last b 3 bits starting from b 0 +b 1 +b 2 . Accordingly the compressed blocks generated by the methods and systems described herein are randomly accessible. In the example compression and decompression methods and systems described below the blocks of image data are of blocks of colour values, e.g. pixel colour values, and each two-dimensional block of values relates to one of the colour channels of the pixel colour. For example, where the pixel colour values represent four channel RGBA data, there will be a two-dimensional block of values corresponding to each of the R (red), G (green), B (blue), and A (alpha) colour channels. However, the use of pixel colour values is for example only, and it should be understood that the compression and decompression methods and systems may operate on any type of image data, e.g. depth data, lighting data, or surface normal data. Furthermore, although in the examples below each image element value (e.g. pixel value) is comprised of a plurality of distinct values (e.g. each pixel value comprises a first channel colour value, a second channel colour value etc.) and the image data is divided into two-dimensional blocks of values on a per distinct value basis (e.g. one two-dimensional block of values comprises the first channel colour values, another two-dimensional block of values comprises the second channel colour values etc.) in other examples the image data may be divided into two-dimensional blocks of values in another manner. In some cases, each image element value may be a single distinct value (e.g. depth value) which may be divided into smaller chunks or portions which are used to form the two-dimensional blocks of values. For example, if the image element value is a multi-byte value the first two-dimensional block of values may comprise the first byte of each image element value (e.g. depth value), and a second two-dimensional block of values may comprise the second byte of each image element value (e.g. depth value). In other cases, each image element value may comprise a plurality of distinct values (e.g. a colour value for each of a plurality of colour channels), but the image data may not be divided into two-dimensional blocks of values on a per distinct value basis. For example, if each image element value comprises a first 10-bit colour channel value, a second 10-bit colour channel value, a third 10-bit colour channel value and a 2-bit colour channel value, instead of dividing the image data into two-dimensional blocks of values on a per channel basis the image data may be divided into two-dimensional blocks of values on a per-byte basis. In particular, a first two-dimensional block of values may comprise the first byte of each image element value and a second two-dimensional block of values may comprise the second byte of each image element value. In another example, the top eight-bits of each 10-bit colour channel value may form a block and a final block may be formed of the two lowest bits of each channel. For example, a first two-dimensional block of values may comprise the first 8-bits of the first colour channel value, a second two-dimensional block of values may comprise the first 8-bits of the second colour channel value, a third two-dimensional block of values may comprise the first 8-bits of the third colour channel value, and a fourth two-dimensional block of values may comprise the last two bits of each colour channel. It will be evident to a person of skill in the art that these are examples only and that the image element values may be divided into multiple values in another manner to form the two-dimensional blocks of values. In some cases, each image element value may be divided into a plurality of multi-bit values. In other words, each image element value may be divided into a plurality of sub-values wherein each sub-value comprises, or is formed by, at least two bits. For example, where each image element value is divided into a first value and a second value such that the block of image data comprises a two-dimensional block of first values and a two-dimensional block of second values, each first value may be a multi-bit value (i.e. a value comprising, or formed by, more than one bit) and each second value may be a multi-bit value (i.e. a value comprising, or formed by, more than one bit). In some cases, the image element values may be divided into eight-bit (i.e. byte) values. For example, as described above, each image element value may be divided into sub-values along byte lines (e.g. the first eight-bits of an image element value may form the first value, the second eight-bits of an element value may form the second value etc.) Dividing the image element values into multi-bit values, as opposed to single-bit values, may allow the compression methods and systems described herein to more efficiently compress a two-dimensional block of values (e.g. first values (e.g. first colour channel values) or second values (e.g. second colour channel values)), and thus more efficiently compress a block of image data comprising that two-dimensional block of values, as it reduces the number of two-dimensional blocks of values (which reduces the header overhead) and allows some of the more complicated fixed-length compression algorithms described below to be used to compress the two-dimensional block of values. Reference is now made to FIG. 2 which illustrates an example method 200 for compressing a block of image data. The method 200 begins at step 202 where a block of image data to be compressed is received. In this example the block of image data is a block of colour values or pixel values. As is known to those of skill in the art, data defining a digital image (e.g. a frame) comprises a set of one or more colour values for each pixel that may be used to determine the colour of that pixel. The set of colour values for a pixel may comprise a colour value for each colour channel. The number of channels is typically based on the format of the image. For example, if the image is in RGB format there are three colour channels—red, green and blue—and there is a red colour value, a green colour value and a blue colour value for each pixel. Similarly if the image is in RGBA format there are four channels—red, green, blue and opacity (or alpha)—and there is a red colour value, a green colour value, a blue colour value and an opacity (or alpha) value for each pixel. The colour values for each channel can be understood as forming a two-dimensional array or block. For example, FIG. 3 illustrates example image data 300 for a 32×32 pixel RGBA digital image. The image data 300 comprises a two-dimensional block of 8-bit colour values for each channel which may be referred to herein as a channel block. Specifically, the image data 300 comprises a 32×32 block 302 of 8-bit colour values for channel 0 (i.e. the red channel); a 32×32 block 304 of 8-bit colour values for channel 1 (i.e. the green channel); a 32×32 block 306 of 8-bit colour values for channel 2 (i.e. the blue channel); and a 32×32 block 308 of 8-bit colour values for channel 3 (i.e. the opacity channel). The colour at each pixel (which may be referred to herein as the pixel colour value) is determined from the different channel colour values associated with that pixel (i.e. the channel 0 colour value, the channel 1 colour value, the channel 2 colour value, and the channel 3 colour value associated with that pixel). A block of image data is the portion of the image data corresponding to a two-dimensional block of pixels in the image. Accordingly a block of image data comprises a two-dimensional block of colour values for each colour channel. The block of image data may be any suitable size. For example, the block of image data may comprise colour values for a 32×32 block of pixels, a 16×16 block of pixels or an 8×8 block of pixels. Where the compression is used to compress frame buffer data in a graphics processing system that implements tile-based rendering, the block of image data may correspond to a tile (e.g. a 32×32 block of pixels corresponding to a 32×32 pixel tile), to a set of tiles (e.g. a 32×32 block of pixels corresponding to four 16×16 pixel tiles), or to a portion of a tile (e.g. a 16×16 block of pixels corresponding to a quarter of a 32×32 pixel tile). Once a block of image data has been received the method 200 proceeds to step 204 . At step 204 , the block of image data is divided into channel blocks. For example, if the block of image data 300 shown in FIG. 3 is received in step 202 the block of image data 300 is divided into the four channel blocks 302 , 304 , 306 and 308 shown in FIG. 3 . Once the block of image data has been divided into channel blocks, the method 200 proceeds to step 206 where the channel blocks are compressed separately. With the exception of areas of constant colour, e.g. background or clear colour, for which specific compression techniques will be described below, rendered images typically do not contain many pixels which have the same pixel colour value (the colour determined from the colour values for each channel). It is possible, however, for many pixels (particularly those in close proximity to each other) to have one or more similar channel (e.g. red, green, blue or opacity) colour values. Accordingly, compressing a block of image data on a per channel basis may allow more efficient compression of image data as those parts of the image data that are more likely to be similar are compressed together. At step 206 , one or more of the channel blocks is compressed by compressing one or more data sets of the channel block using a fixed-length compression algorithm to generate one or more compressed channel blocks. In some cases, an entire channel block may be compressed so that the data set that is compressed is the entire channel block. In other cases, the channel block may be sub-divided into channel sub-blocks so that the data set(s) that are compressed comprise one or more channel sub-blocks. The term channel sub-block is used herein to mean a portion of a channel block that is smaller than the channel block in at least one dimension. For example, as shown in FIG. 4 , if the channel block 402 is a 32×32 block of colour values then the channel block 402 may be sub-divided into sixteen 8×8 sub-blocks 404 of colour values and one or more of the 8×8 sub-blocks 404 may be compressed using a fixed-length compression algorithm. As is known to those of skill in the art, a fixed-length compression algorithm is a compression algorithm in which each of the items (e.g. colour values) in the set of items (e.g. channel block/sub-block of colour values) being compressed is represented by the same number of bits in the compressed format. Accordingly, by using a fixed-length compression algorithm to compress a channel block/sub-block each colour value in that block/sub-block is represented in the compressed block by the same number of bits which allows the bits relating to any particular colour value in the channel block/sub-block to be easily identified. Thus, using a fixed-length compression algorithm allows the compressed block to be randomly accessible. The fixed-length compression algorithm is configured to compress a block or sub-block of values by (i) identifying common base information for the block; and (ii) identifying a fixed-length parameter for each value such that the original value can be obtained from the common base information and the fixed-length parameter. For example, one fixed-length compression algorithm may identify a common origin value for the block or sub-block and identify a fixed-length delta value for each value in the block or sub-block that represents the difference between the common origin value and the value. Example fixed-length compression algorithms which may be used to compress a channel block/sub-block are described below. When an entire channel block is compressed as a whole, only a single set of common base information is generated for the channel block and a fixed-length parameter is generated for each colour value in the channel block. For example, if the channel block is a 32×32 block of colour values then only a single set of common base information is generated for the channel block and a fixed-length parameter may be generated for each colour value in the channel block. In contrast, when the channel block is divided into a plurality of sub-blocks and one or more of the channel sub-blocks are compressed, a set of common base information is generated for each sub-block that is compressed. For example, a 32×32 channel block may be divided into four 16×16 channel sub-blocks and if two of these sub-blocks are compressed then common base information and fixed-length parameters are generated for each of the two compressed sub-blocks. Where a channel block is divided into channel sub-blocks and multiple channel sub-blocks are compressed, the same fixed-length compression algorithm does not have to be used to compress each sub-block. For example, a first channel sub-block may be compressed using a first fixed-length compression algorithm and a second channel sub-block for the same channel may be compressed using a second, different, fixed-length compression algorithm. As described in more detail below, this allows each channel sub-block to be compressed by the most suitable fixed-length compression algorithm for that channel sub-block. Similarly, where all or a portion of multiple channel blocks are compressed the same compression algorithm(s) do not have to be used for all the channel blocks. For example, a first sub-block of a first channel block may be compressed using a first fixed-length compression algorithm whereas a first sub-block of a second channel block may be compressed using a second, different fixed-length compression algorithm. As described in more detail below, since different channels have different characteristics this allows each channel to be compressed by the most suitable fixed-length compression algorithm(s) for that channel. Once one or more of the channel blocks have been compressed the method 200 proceeds to step 208 . At step 208 , a compressed block of image data is generated from the compressed channel blocks generated in step 206 . In some cases, a compressed block may comprise a header and a body. The header comprises information that identifies the size or length of the fixed-length parameter used for each compressed channel block/sub-block and the common base information for each compressed channel block/sub-block. For example, the header may comprise, for each compressed channel block/sub-block: (i) a length or size field (which may also be referred to herein as the format field) that indicates the length of the fixed-length parameter for that compressed channel block/sub-block; and (ii) a common base information field that comprises the common base information for that compressed channel block/sub-block. The body comprises the fixed-length parameters for each compressed channel block/sub-block and the original colour values for any uncompressed channel block/sub-block. Where a channel block/sub-block can be compressed using one of a plurality of fixed-length compression algorithms the header may also comprise, for each compressed channel block/sub-block, information indicating the fixed-length compression algorithm that was used to compress that channel block/sub-block. In some cases, there may be a separate compression algorithm field for each compressed channel block/sub-block which indicates the compression algorithm that was used to compress that channel block/sub-block. However, in other cases the information indicating the fixed-length compression algorithm that was used to compress a channel block/sub-block may be incorporated into another field. For example, in some cases the length or size field may be used to indicate which compression algorithm was used (e.g. the length or size field may be set to a certain value to indicate a first fixed-length compression algorithm was used and set to another value to indicated a second, different, fixed-length compression algorithm was used). The header may also comprise information indicating which, if any, channel blocks/sub-blocks were not compressed. In some cases, there may be a separate compressed/uncompressed field for each channel block/sub-block that indicates whether that channel block/sub-block was compressed or not. However, in other cases the information indicating that a channel block/sub-block was not compressed may be incorporated into another field. For example, in some cases the length or size field or the compression algorithm field may be used to indicate that a channel block/sub-block was not compressed. Example formats for a compressed block are described below with reference to FIGS. 15 to 17 . As described above, the body comprises the fixed-length parameters for each compressed channel block/sub-block and the original colour values for any uncompressed channel block/sub-block. The fixed-length parameters and/or original colour values may be stored in the body in any manner that allows the fixed-length parameters and/or original colour values to be randomly accessible. In some cases, as described in more detail below, the fixed-length parameters and/or original colour values for each pixel may be stored together in a pixel data unit. For example, where the image data comprises colour values for four channels numbered 0 to 3, each pixel data unit may comprise the fixed-length parameter/original colour value for channel 0, the fixed-length parameter/original colour value for channel 1, the fixed-length parameter/original colour value for channel 2, and the fixed-length parameter/original colour value for channel 3. In these cases, the pixel data units may be stored in in the body in any order which allows the pixel data units (and thus the fixed-length parameters/original colour values thereof) to be randomly accessible. In some cases, where the channel blocks are divided into sub-blocks prior to compression, the pixel data units for each sub-block may be stored together. For example, if the channel blocks are divided into 8×8 sub-blocks then the pixel data units for each 8×8 image data sub-block may be stored together. Example Fixed-Length Compression Algorithms Example fixed-length compression algorithms which may be used to compress a channel block/sub-block in step 206 of the method 200 of FIG. 2 will now be described. A first example fixed-length compression algorithm which may be used to compress a channel block/sub-block in step 206 of the method 200 of FIG. 2 is referred to herein as the common value compression algorithm. In this compression algorithm if all the colours values in the channel block/sub-block are the same then all the colour values of the block/sub-block can be efficiently represented by a single copy of that colour value. While rendered images typically do not contain many pixels which have the same pixel colour value (the colour determined from the colour values for each channel), it is possible for many pixels (particularly those in close proximity to each other) to share one or more common channel (e.g. red, green, blue or opacity) colour values. For example, where the image data is in RGBA format it is very common for many of the pixels to have the same opacity (or alpha) value. Accordingly, in the common value compression algorithm the common base information is the common colour value and the fixed-length parameters have zero bit length (i.e. no fixed-length parameters are stored). As is known to those of skill in the art, there are a set of standard benchmark tests which are used to measure the graphics performance of devices. The benchmark tests provide the device with game-like content and the performance of the device in response thereto is measured and used to benchmark the device's graphics performance. FIG. 5 illustrates the percentage of blocks in the Manhattan 3.0 benchmark test that have a common channel colour value for a variety of block sizes. Specifically, FIG. 5 illustrates the number of 8×8 blocks, 16×16 blocks and 32×32 blocks which have a common colour value for each of the R, G, B, and A channels. It can be seen from FIG. 5 that around 20% of the 8×8 blocks had a common colour value for channel 0 (red channel) and channel 1 (green channel); 30% of the 8×8 blocks had a common colour value for channel 2 (blue channel); and 80% of the 8×8 blocks had a common colour value for channel 3 (opacity channel). It can be seen from FIG. 5 that as the block size increases (e.g. to 16×16 and 32×32) the number of blocks which had a common channel colour value decreased. However, even at a block size of 32×32 60% of the blocks had a common colour value for channel 3 (opacity channel). Accordingly, significant bandwidth savings can be achieved by identifying those blocks that have a common channel colour value and representing all the colour values of that block with a single copy of that colour value. A second example fixed-length compression algorithm which may be used to compress a channel block/sub-block in step 206 of the method 200 of FIG. 2 is referred to herein as the origin and delta compression algorithm. In this compression algorithm each colour value is represented by a common origin value and an individual delta value with a fixed number of bits. Each delta value indicates the difference between the colour value and the origin value. The number of delta bits is based on the range of colour values in the block. Specifically the number of delta bits to represent a range k is ┌log 2 (k+1)┐. Table 1 illustrates the number of delta bits required to represent ranges up to 255. It can be seen that the smaller the range of colour values in a block/sub-block, the fewer bits can be used to represent those colour values. TABLE 1RangeDelta Bits[0, 1]1[0, 3]2[0, 7]3[0, 15]4[0, 31]5[0, 63]6[0, 127]7[0, 255]8 In some cases, the origin and delta compression algorithm may only be deemed a suitable compression algorithm if the number of bits used to represent the range is less than the number of bits to represent the original colour values. For example, if the original colour values are 8-bits then the origin and delta compression algorithm may only be deemed to be suitable if the range can be represented with 7 or fewer bits. A compressed colour value can be easily decompressed by adding the delta value for that colour value to the origin value. In some cases, the minimum colour value or the maximum colour value in the block/sub-block is used as the origin. This allows all of the delta values to be positive or all the delta values to be negative, which can simplify the decompression calculations. In other cases, an intermediate value in the range, such as the mean or the midpoint of the range of values may be used as the origin and one bit of the delta value may be used as a sign bit. In yet other cases, it may be more efficient to determine the delta value as the difference between the colour value and the origin value modulo 2 x wherein x is the number of bits used to represent the colour values. This may allow a block/sub-block of colour values that are clustered into ranges that are at the two ends of the colour value range to be represented more efficiently. For example, if each colour value is 8-bits which allows a minimum colour value of 0 and maximum colour value of 255; and, as shown in FIG. 6 , the colour values for a channel block/sub-block fall into two clusters 602 and 604 wherein the minimum value of the first cluster 602 is 0 and the maximum value of the first cluster 602 is 20, and the minimum value of the second cluster 604 is 235 and the maximum value of the second cluster 604 is 255 then the range 606 of values in the block/sub-block is 255 thus 8 delta bits are required to represent the range. If, however, the 8-bit range [0, 255] is considered a circle when using modulo arithmetic (i.e. modulo 2 x =28=256) as shown in FIG. 7 , then there are two paths that can be taken to get from one number in the range to another number in the range. Specifically, the clockwise path 702 may be taken where a value is added to the first number; or the counter-clockwise path 704 may be taken where a value is subtracted from the first number. For example, to get from 255 to 0, either 1 can be added to 255 (i.e. (255+1) mod 256=0) or 255 can be subtracted from 255 (i.e. (255−255) mod 256=0). The range for a set of values can then be represented as any path on the circle that encompasses all of the numbers in the set. For example, the range for the example set of values shown in FIG. 6 which fall into two clusters—a first cluster 602 with a min of 0 and a max of 20, and a second cluster 604 with a min of 235 and a max of 255—can be represented as a path from 0 to 255 which results in a range of 255 which would require 8 delta bits; or the range (shown at 608 in FIG. 6 ) can be represented as the path from 235 to 20 which results in a range of 41 which would require only 6 delta bits. Thus this example set of values can be represented much more efficiently if the origin is set to 235 and 6 delta bits are used to represent the difference between the colour value and the origin modulo 256. It will be evident to a person of skill in the art, that these are examples only and other suitable values may be used as the origin value. Accordingly, in the origin and delta compression algorithm the common base information is the origin value and the fixed-length parameter for each colour value is the delta value. Reference is now made to FIGS. 8 to 10 which show the percentage of channel blocks that were represented with each number of delta bits on a per channel basis when the origin and delta compression algorithm was used to compress RGBA formatted image data with 8-bit colour values in the Manhattan 3.0 benchmark test. Specifically, FIG. 8 illustrates the percentage of 8×8 channel blocks that were represented using 0-8 delta bits; FIG. 9 illustrates the percentage of 16×16 channel blocks that were represented using 0-8 delta bits; and FIG. 10 illustrates the percentage of 32×32 channel blocks that were represented using 0-8 delta bits. It can be seen from FIG. 8 that overall roughly 80% of the 8×8 channel blocks can be compressed using the origin and delta compression algorithm (and the common value algorithm when all the colour values in a channel block are the same). A third example fixed-length compression algorithm which may be used to compress a channel block/sub-block in step 206 of the method 200 of FIG. 2 is a variant of the origin and delta compression algorithm and is referred to herein as the multiple origin and delta compression algorithm. Instead of there being a single origin, there are multiple origins and each colour value is represented by the common origins, an individual index which identifies one of the common origins and a delta value that indicates the difference between the colour value and the identified origin. The multiple origin and delta compression algorithm may be suitable where the colour values in the channel block/sub-block are clustered into two or more groups such that the range of colour values within the channel block/sub-block is large, but the range within each cluster is small. Accordingly, in the multiple origin and delta compression algorithm the common base information is the plurality of origin values and the fixed-length parameter for each colour value is the index identifying one of the origins and the delta value. For example, FIG. 11 illustrates an example where colour values can be between 0 and 255 and the colour values in a channel block fall within two clusters 1102 , 1104 —a first cluster 1102 wherein the colour values are between 25 and 50 and a second cluster 1104 wherein the colour values are between 215 and 240. The range of all the colour values in the channel block is 240−25=115 which, according to Table 1, would require 7 delta bits. Alternatively, using modulo 256 arithmetic as described above, the range of all the colour values in the channel block is (50−215)mod 256=91, which, although smaller than 115, still requires 7 delta bits according to Table 1. However, the range for each cluster is only 25, which, according to Table 1, would require only 5 delta bits. Thus if there were two origin values, one for each cluster 1102 , 1104 , and the delta for each colour value is calculated from one of the origin values each colour value can be represented by a 5 bit delta value. For example, 25 and 215 may be stored as origin values 0 and 1 respectively, then for each colour value falling in the first cluster 1102 an index of 0 is stored along with a 5-bit delta value indicating the difference between the colour value and the first origin value (i.e. 25 in this example); and for each colour value falling in the second cluster 1104 an index of 1 is stored along with a 5-bit delta value indicating the difference between the colour value and the second origin value (i.e. 215 in this example). A fourth example fixed-length compression algorithm which may be used to compress a channel block/sub-block in step 206 of the method 200 of FIG. 2 is referred to herein as the look-up table compression algorithm. In this compression algorithm each unique colour value in the channel sub-block is stored in a look-up table and then a fixed-length index into the table is generated for each colour value in the block/sub-block. This method is suitable where there are only a small number of different colour values which may occur, for example, in black and white images. For example, as shown in FIG. 12 , if a channel sub-block 1202 comprises only three colour values—0, 128 and 255 then according to the look-up table compression algorithm these three values would be placed in a look-up table 1204 and each colour value in the block would be represented by an index into the look-up table as shown at 1206 . Specifically, if, as shown in FIG. 12 the colour value 0 is stored at index 0 of the look-up table 1204 , the colour value 128 is stored at index 1 of the look-up table 1204 , and the colour value 255 is stored at index 2 of the look-up table 1204 , then each zero is represented by an index of 0, each 128 is represented by an index of 1, and each 255 is represented by an index of 2. Accordingly, in the look-up table compression algorithm the common base information is the look-up table of unique colour values and the fixed-length parameter for each colour value is the index to the look-up table. A fifth example fixed-length compression algorithm which may be used to compress a channel block/sub-block in step 206 of the method 200 of FIG. 2 is referred to herein as the predetermined colour compression algorithm. In this compression algorithm there are a small number (e.g. one to four) of predetermined colour values and if all the colour values in the block are the same and match one of the predetermined colour values then instead of storing the colour value, information (e.g. an index or the like) identifying one of the predetermined colours is stored. In some cases, there may only be a single predetermined colour value. In these cases, identifying that the predetermined colour compression algorithm was used also identifies the predetermined colour. In other words, in these cases the predetermined colour value compression algorithm may be used to identify one particular colour value. In other cases, there may be a plurality of predetermined colour values (which may be stored in memory). In these cases, in addition to identifying that the predetermined colour compression algorithm was used to compress a channel block/sub-block, information is stored which identifies one of the plurality of predetermined colour values. This identification of the particular colour value of the plurality of predetermined colour values may take any suitable form. For example, in some cases an index may be stored which identifies the particular colour value. In some cases, the predetermined colour compression algorithm may be used to compress an entire block of image data (e.g. all channels of a block). For example, in some cases, applications may set each pixel to a clear colour value to clear the frame buffer before any draw calls. The specific clear colour value is generally a specific combination of the channel colour values. For example, the clear colour value may be 00FFFFFF (hexadecimal) for 8-bit per channel ARGB format where the first two hexadecimal values correspond to channel 0, the next two hexadecimal values correspond to channel 1, the next two hexadecimal values correspond to channel 2, and the final two hexadecimal values correspond to channel 3. The clear colour value is generally stored in memory and thus it is not necessary to store the clear colour value in the compressed block. Accordingly, in these cases the predetermined colour value compression algorithm can be used to indicate that every pixel in the block has the clear colour value. It will be evident to a person of skill in the art that this is an example only, and that the predetermined colour compression algorithm may be used to identify another pixel colour value. In another example, there may, also or alternatively, be a plurality of predetermined special pixel colour values which are frequently used. For example, in some cases, where an 8-bit per channel ARGB format is used, 00000000 (hexadecimal) and FF000000 (hexadecimal) may be defined as special pixel colour values as they are commonly used. In these cases, if it is determined that all of the pixels in a block have the same colour value and it is one of the predetermined colour values (or the clear colour value) then the predetermined colour compression algorithm may be used to compress this block by storing information (e.g. an index) that identifies one of the predetermined pixel colour values. This allows blocks wherein each pixel of the block has the same special pixel colour value to be compressed very efficiently. In some cases, in addition or alternatively to using the predetermined colour compression algorithm to compress a whole block of image data (e.g. all channels of a block) (which may be referred to herein as the predetermined pixel colour compression algorithm), the predetermined colour compression algorithm may be used to compress individual channel blocks/sub-blocks of a block of image data (which may be referred to herein as the predetermined channel colour compression algorithm). Specifically, instead of there being one or more predetermined pixel colour values (e.g. a 32-bit pixel colour value) there are one or more predetermined channel colour values (e.g. an 8-bit channel colour value) and if all the colour values in a channel block/sub-block are the same and match one of the predetermined channel colour values then the predetermined colour compression algorithm may be used to compress the channel block/sub-block. This may allow more blocks to be efficiently compressed compared to compressing at the pixel level. The predetermined channel colour compression algorithm works most effectively when the predetermined channel colour values are the most common channel colour values in the unique channel blocks (i.e. the channel blocks in which all the colour values are the same). In some cases, the predetermined channel colour values may be fixed for the graphics processing system (i.e. the same predetermined channel colour values are used for any and all applications running on the graphics processing system). In other cases, the predetermined colour channel colours may be application specific. For example, the graphics processing system may comprise memory (e.g. a register) which can be used to dynamically identify the predetermined channel colour values to be used for a particular application. In some cases, a portion (e.g. two) of the predetermined channel colour values may be fixed and another portion (e.g. two) of the predetermined channel colour values may be programmable or dynamically selectable. For example, FIG. 13 shows the distribution of colour values for the 8×8 channel blocks with a unique colour value (i.e. all the colour values in the 8×8 block are the same) for a plurality of different applications. It can be seen in FIG. 13 that a significant portion of the unique 8×8 channel blocks have colour values of 00 (hexadecimal) or FF (hexadecimal). Accordingly, the predetermined channel colour compression algorithm may be used to efficiently compress a significant number of unique colour channel blocks if the predetermined channel colour values are set to 00 (hexadecimal) and FF (hexadecimal). Also, since pixel colour values of 00000000 (hexadecimal), FFFFFFFF (hexadecimal), 00FFFFFF (hexadecimal) and FF000000 (hexadecimal) are very common this will also cover off the common pixel colour values. However, it can be seen that the next highest colour values for the unique channel blocks is application specific. For example, FD (hexadecimal), F1 (hexadecimal) and EE (hexadecimal) are commonly used channel colour values in the ‘Angry Birds’ application but not in other applications. Similarly, A6 (hexadecimal) and 96 (hexadecimal) are commonly used channel colour values in the ‘Leanback’ application, but not in other applications. Accordingly, the number of blocks that can be compressed using this method may be increased if a number (e.g. two) of the predetermined channel colour values were programmable. For example, in some cases there may be four predetermined channel colour values—two of the predetermined colour values may be fixed at 00 (hexadecimal) and FF (hexadecimal)—and two of the predetermined colour values may be programmable (e.g. via register settings). For example, the two programmable predetermined colour values may be set to FD (hexadecimal) and F1 (hexadecimal) when running ‘Angry Birds’ and A6 (hexadecimal) and 96 (hexadecimal) when running ‘Leanback’. In some cases, the two programmable predetermined colour values may have default values that are common for many applications, such as, but not limited to 0F (hexadecimal) and 01 (hexadecimal). Reference is now made to FIG. 14 which illustrates the distribution of fixed-length compression algorithms when 8×8 channel blocks are compressed using one of the following fixed-length compression algorithms: the origin and delta compression algorithm (referred to in FIG. 14 as ‘DeltaBitx’ wherein the number x indicates the number of delta bits that were used); the predetermined pixel colour compression algorithm wherein the predetermined colour value is the clear colour value (referred to in FIG. 14 as ‘ClearColour’); the predetermined channel colour compression algorithm wherein there are four predetermined channel colours of 00 (hexadecimal), FF (hexadecimal), 0F (hexadecimal) and 01 (hexadecimal) (referred to in FIG. 14 as ‘ConstBytex’ wherein the number x indicates which of the four predetermined channel colour values numbered from 0 to 3 was used); and the look-up table compression algorithm (referred to in FIG. 14 as ‘TableEntryBitx’ wherein the number x indicates the number of index bits). As ‘TableEntryBit0’ (i.e. the look-up table compression algorithm with zero index bits) is equivalent to the common value compression algorithm, the notation ‘TableEntryBit0’ is used in this example to indicate that the common value compression algorithm was used. Accordingly, in the predetermined colour value compression algorithm (either the pixel colour value version or the channel colour value version) the common base information is the information identifying one colour of the one or more predetermined colours and the fixed-length parameters have zero bit length (i.e. no fixed-length parameters are stored). It will be evident to a person of skill in the art that these are example fixed-length compression algorithms only and that any fixed-length compression algorithm in which the compressed data for any colour value can be randomly accessed may be used in the method 200 of FIG. 2 . Example Compressed Block Formats Example formats for the compressed blocks generated in accordance with the method 200 of FIG. 2 will now be described. Reference is now made to FIG. 15 which illustrates a first example format for a compressed block 1500 of image data where the channel blocks are not divided into sub-blocks prior to compression (i.e. each channel block is compressed in its entirety or left uncompressed). In this example there are four channels and thus four channel blocks, however it will be evident to a person of skill in the art that this is an example only and that the method and techniques described herein may be applied to image data with a different number of channels. The example compressed block 1500 comprises a header 1502 and a body 1504 . The header 1502 comprises information indicating which channel blocks were compressed, and for each compressed channel block comprises: information indicating the fixed-length compression algorithm used to compress that channel block, the size or length of the fixed-length parameter, and the common base information for that channel block. The body 1504 comprises the raw or uncompressed colour values for each uncompressed channel block and the fixed-length parameters for each compressed channel block. In FIG. 15 the header 1502 comprises a length or size field 1506 , 1508 , 1510 , 1512 for each channel block that indicates whether or not that channel block was compressed, and if compressed, indicates the compression algorithm used to compress the channel block and the length or size of the fixed-length parameter. In the example shown in FIG. 15 each length or size field 1506 , 1508 , 1510 , 1512 is 4-bits, a 0 (‘0000’ (binary)) indicates that the corresponding channel block was compressed using the common value compression algorithm; any number between 1 (‘0001’ (binary)) and 7 (‘0111’ (binary)) indicates that the corresponding channel block was compressed using the origin and delta compression algorithm and the parameter length (i.e. the number of delta bits) is equal to that number; and an 8 (‘1000’ binary) indicates that the corresponding channel block was not compressed and the raw or original colour values of that channel block are included in the compressed block. This is summarized in Table 2. TABLE 2Size FieldCompressionParameter(binary)RawAlgorithmLength0000NCommon0Value0001-0111NOrigin andValue inDeltaSize Field1000Y—— Accordingly, in the example shown in FIG. 15 the length field 1506 , 1512 for channels 0 and 3 is set to eight (‘1000’ (binary)) indicating channels 0 and 3 were not compressed; the length field 1508 for channel 1 is two (‘0010’ (binary)) indicating channel 1 was compressed using the origin and delta compression algorithm and the length of the fixed-length parameter is two bits; and the length field 1510 for channel 2 is set to zero (‘0000’ (binary)) indicating channel 2 was compressed using the common value compression algorithm and the fixed-length parameter is zero bits (i.e. no fixed-length parameter is stored for this channel block). The header 1502 also comprises a common base information field 1514 , 1516 for each compressed channel block that indicates the common base information which, combined with the fixed-length parameter for a colour value, can be used to obtain the raw or original colour value. In this example, only channels 1 and 2 have been compressed so the header 1502 comprises a common base information field 1514 , 1516 for channels 1 and 2 only. The common base information is generally based on the fixed-length compression algorithm used to compress the channel block. In this example, channel 1 was compressed according to the origin and delta compression algorithm so the common base information field 1514 comprises the origin value (e.g. minimum colour value); and channel 2 was compressed according to the common value compression algorithm so the common base information field 1516 comprises the common colour value. The body 1504 comprises the colour values for any uncompressed channel blocks and the fixed-length parameters for any compressed channel blocks. The colour values and/or fixed-length parameters may be stored in the body 1504 in any suitable manner that allows the fixed-length parameters and/or colour values associated with any pixel to be randomly accessible. In some cases, as shown in FIG. 15 , the fixed-length parameters and/or colour values that correspond to the same pixel are packed together to form a pixel data unit 1518 . In the example shown in FIG. 15 , channels 0 and 3 are uncompressed and channels 1 and 2 are compressed, therefore each pixel data unit 1518 comprises the uncompressed colour value for channel 0, the fixed-length parameter for channel 1, the fixed-length parameter for channel 2, and the uncompressed colour value for channel 3. However, in this particular example since channel 2 was compressed with the common value compression algorithm the fixed-length parameter has 0 bits, so no fixed-length parameter is actually stored for channel 2. The pixel data units 1518 may be stored in the body 1504 in any order. For example, the pixel data units 1518 may be stored in a Morton (or Z) order or scan line order within the block. Reference is now made to FIG. 16 which illustrates a second example format for a compressed block 1600 of image data generated in accordance with the method 200 of FIG. 2 where the channel blocks are not divided into sub-blocks prior to compression (i.e. each channel block is compressed in its entirety or left uncompressed). In this example, like the example of FIG. 15 , there are four channels and thus four channel blocks, however it will be evident to a person of skill in the art that this is an example only and that the methods and techniques may be applied to image data with a different number of channels. The example compressed block 1600 comprises a header 1602 and a body 1604 . Like the compressed block 1500 of FIG. 15 , the header 1602 comprises information indicating which channel blocks were compressed, and for each compressed channel block comprises information indicating the compression algorithm that was used to compress that channel block, the size or length of the fixed-length parameter, and the common base information for that channel block; and the body 1604 comprises the raw or uncompressed colour values for each uncompressed channel block and the fixed-length parameters for each compressed channel block. The header 1602 in this example comprises a compression algorithm field 1606 , 1608 , 1610 , 1612 for each channel block. Each compression algorithm field 1606 , 1608 , 1610 , 1612 indicates whether or not the corresponding channel block has been compressed or not, and if compressed it indicates the particular fixed-length compression algorithm that was used to compress the channel block. In this example the compression algorithm field is two bits and a 0 (‘00’ (binary)) in the compression field for a channel block indicates that the channel block was not compressed (and that raw original colour values are stored) and anything else indicates that the channel block was compressed, and the particular fixed-length compression algorithm used to compress the channel block. Specifically, in this example a 1 (‘01’ (binary)) indicates that the common value compression algorithm was used to compress the channel block; a 2 (‘10’ (binary)) indicates that the origin and delta compression algorithm was used to compress the channel block; a 3 (‘10’ (binary)) indicates that the look-up table compression algorithm was used to compress the channel block. This is summarized in Table 3. TABLE 3CompressionAlgorithmCompressionFieldRawAlgorithm00Y—01NCommonValue10NOrigin andDelta11NLook-upTable In the example shown in FIG. 16 , the compression algorithm fields 1606 , 1608 , 1610 and 1612 indicate that channels 0 and 3 were not compressed, and that channels 1 and 2 were compressed using the common value, and origin and delta compression algorithms respectively. If a channel block is not compressed then, as described in more detail below, the body comprises the original or uncompressed colour values for that block. In the example of FIG. 16 the header 1602 also comprises a length or size field 1614 , 1616 for each compressed channel block that indicates the length or size of the fixed-length parameter. In this example only channels 1 and 2 have been compressed so the header 1602 only comprises a length or size field 1614 , 1616 for channels 1 and 2. In this example, the length or size field 1614 , 1616 is three bits which can be used to indicate a size or length ranging from 0 bits to 7 bits. Specifically, channel 1 has a fixed-length parameter of 0 bits (i.e. it was compressed using the common value compression algorithm, so no fixed-length parameters are stored) and channel 2 has a fixed-length parameter of 3 (i.e. the fixed-length parameters are each 3 bits). However, it will be evident to a person of skill in the art that this is an example only and that the length or size field 1614 , 1616 may have any suitable number of bits and/or format. In some cases, there may not be a length or size field for blocks compressed using the common value compression algorithm as it is known from the compression field that the length of the fixed-length parameter is zero bits. The header 1602 also comprises a common base information field 1618 , 1620 for each compressed channel block that indicates the common base information which, combined with the fixed-length parameter for a colour value, can be used to obtain the raw or original colour value. In this example, only channels 1 and 2 have been compressed so the header 1602 only comprises common base information fields 1618 , 1620 for channels 1 and 2. The common base information is generally based on the fixed-length compression algorithm used to compress the channel block. In this example channel 1 was compressed using the common value compression algorithm so the common base information field 1618 for channel 1 comprises the common value; and channel 2 was compressed using the origin and delta compression algorithm so the common base information field 1620 for channel 2 comprises the origin value. The body 1604 , like the body 1504 of FIG. 15 , comprises the colour values for any uncompressed channel blocks and the fixed-length parameters for any compressed channel blocks. The colour values and/or fixed-length parameters may be stored in the body 1604 in any suitable manner that allows the fixed-length parameters and/or colour values to be randomly accessible. In some cases, as described above, the fixed-length parameters and/or colour values that correspond to the same pixel are packed together to form a pixel data unit 1622 . Since in the example shown in FIG. 16 , channels 0 and 3 are uncompressed and channels 1 and 2 are compressed each pixel data unit 1622 comprises the uncompressed colour value for channel 0, the fixed-length parameter for channel 1, the fixed-length parameter for channel 2, and the uncompressed colour value for channel 3. However, since channel 1 was compressed using the common value compression algorithm the fixed-length parameter has a length of 0 bits, so no fixed-length parameter is stored for channel 1. The pixel data units 1622 may be stored in the body 1604 in any order. For example, as described above, the pixel data units 1622 may be stored in Morton (or Z) order or scan line order within the block. Reference is now made to FIG. 17 which illustrates an example format for a compressed block 1700 of image data where each channel block is divided into four sub-blocks and each sub-block can be compressed or left uncompressed. In this example there are four channels and thus four channel blocks, however it will be evident to a person of skill in the art that this is an example only and that the methods and techniques may be applied to image data with a different number of channels. For example, as shown in FIG. 18 the block of image data 1800 may comprise RGBA image data for a 16×16 block of pixels. The image data 1800 can be divided into four 16×16 channel blocks 1802 , 1804 , 1806 , 1808 —i.e. a 16×16 block 1802 of colour values for channel 0 (red channel); a 16×16 block 1804 of colour values for channel 1 (green channel); a 16×16 block 1806 of colour values for channel 2 (blue channel); and a 16×16 block 1808 of colour values for channel 3 (opacity channel). In this example, prior to compression, each channel block 1802 , 1804 , 1806 , 1808 is divided into four 8×8 sub-blocks—sub-block zero 1810 , 1820 , 1830 , 1840 , sub-block one 1812 , 1822 , 1832 , 1842 , sub-block two 1814 , 1824 , 1834 , 1844 , and sub-block three 1816 , 1826 , 1836 , 1846 . Like the compressed blocks 1500 and 1600 of FIGS. 15 and 16 , the compressed block 1700 of FIG. 17 comprises a header 1702 and a body 1704 . The header 1702 comprises information indicating which sub-blocks were compressed, and for each compressed sub-block comprises information indicating the compression algorithm used to compress that sub-block, the size or length of the fixed-length parameter, and the common base information for that sub-block; and the body 1704 comprises the raw or uncompressed colour values for the uncompressed channel sub-blocks and the fixed-length parameters for the compressed channel sub-blocks. The header 1702 of FIG. 17 is similar to the header 1602 of FIG. 16 in that it comprises: compression algorithm fields 1706 , 1708 , 1710 , 1712 , 1714 , 1716 , 1718 , 1720 , 1722 , 1724 , 1726 , 1728 , 1730 , 1732 , 1734 , 1736 ; length or size fields 1738 , 1740 , 1742 , 1744 , 1746 , 1748 ; and common base information fields 1750 , 1752 , 1754 , 1756 , 1758 and 1760 . However, where the header 1602 of FIG. 16 only comprises a single set of compression algorithm fields, length or size fields, and common base information fields, the header 1702 of FIG. 17 comprises a set of compression algorithm fields, length or size fields, and common base information fields for each sub-block of the image data. Each set of compression algorithm fields, length or size fields, and common base information fields works the same way as the compression algorithm fields, length or size fields, and common base information fields of FIG. 16 except instead of describing the compression (or lack thereof) of a channel block they describe the compression of a channel sub-block. Specifically, for each sub-block of the image data there is: a compression algorithm field for each channel that indicates whether that channel sub-block has been compressed and if so, by which algorithm; a length or size field for each compressed channel sub-block that indicates the length of the fixed-length parameter for that compressed channel sub-block; and a common base information field for each compressed channel sub-block that comprises the common base information for that compressed channel sub-block. It will be evident to a person of skill in the art that this is only an example format for the header 1702 and the header 1702 may take any suitable format. For example, in other cases, instead of the header comprising a set of compression algorithm fields, length or size fields, and common base information fields for each sub-block as described with reference to FIG. 16 , the header may comprises a set of length or size fields and common base information fields for each sub-block as described with reference to FIG. 15 . The body 1704 of FIG. 17 includes the fixed-length parameters for each compressed channel sub-block and the original colour values for each uncompressed channel sub-block. The fixed-length parameters and/or original colour values may be stored in the body 1704 in any suitable manner in which they can be randomly accessed. In some cases, such as in the example shown in FIG. 17 , the fixed-length parameters and/or original colour values are grouped by sub-block to form a sub-block data unit 1762 , 1764 , 1766 , 1768 . Within each sub-block data unit 1762 , 1764 , 1766 , 1768 the fixed-length parameters and/or colour values related to the same pixel may be packed together to form a pixel data unit 1770 as described above with respect to FIGS. 15 and 16 . For example, if for a particular sub-block, channels 0 and 1 are not compressed and channels 2 and 3 are compressed then each pixel data unit for that sub-block may comprise the original uncompressed colour value for channel 0, the original uncompressed colour value for channel 1, the fixed-length parameter for channel 2, and the fixed-length parameter for channel 3. To improve the memory usage and bandwidth efficiency the sub-block data units 1762 , 1764 , 1766 , 1768 may be packed together. The sub-block data units 1762 , 1764 , 1766 , 1768 may be packed at any granularity such as, but not limited to, bytes or 4-byte words (i.e. the next sub-block may start at the next byte after the previous sub-block ends or the next sub-block may start at the next 4-byte word after the previous sub-block ends). Although the start of each sub-block data unit 1762 , 1764 , 1766 , 1768 can be determined from the length information and/or the compression algorithm information, in some cases the header 1702 may also include an offset field for each sub-block that indicates the location (e.g. address) within the body at which the sub-block data unit 1762 , 1764 , 1766 , 1768 for that sub-block starts. This may allow the compressed data for a particular sub-block to be located more quickly, however it increases the size and complexity of the header 1702 . In some cases, the offset field may indicate the address offset with respect to the start of the body 1704 at which the corresponding sub-block data unit begins. Using an offset, as opposed to the actual address, allows a smaller number of bits to be used to specify the address of the sub-block data unit. It will be evident to a person of skill in the art that these are example formats for compressed blocks generated in accordance with the method 200 of FIG. 2 and that the compressed blocks may take any suitable form. Dynamic Selection of Fixed-Length Compression Algorithm In some cases, the fixed-length compression algorithm that is used to compress a channel block/sub-block in step 206 of the method 200 of FIG. 2 may be dynamically selected based on the diversity of the colour values in the channel block/sub-block. For example, in some cases, prior to compressing a channel block/sub-block the colour values of the channel block/sub-block are analysed to generate one or more diversity statistics that indicate the diversity of the colour values in the channel block/sub-block. One of a plurality of fixed-length compression algorithms is then selected for the channel block/sub-block based on the diversity statistic(s). Diversity statistics may include, but are not limited to, the number of unique colour values in the channel block/sub-block, the range of the colour values in the channel block/sub-block (or statistics from which the range may be determined such as the minimum and maximum colour values) and/or any other suitable statistic. Reference is now made to FIG. 19 which illustrates a first example method 1900 for dynamically selecting a fixed-length compression algorithm for compressing a channel block/sub-block. In this example method 1900 either the common value compression algorithm or the origin and delta compression algorithm may be used to compress channel blocks/sub-blocks. The method 1900 begins at step 1902 where a channel block/sub-block is received (e.g. a 32×32 or 16×16 block of colour values for a channel). Once the channel block/sub-block has been received, the method 1900 proceeds to step 1904 where diversity statistics are generated for the received channel block/sub-block. In this example, the diversity statistics may include the range of the colour values in the channel block/sub-block (or statistics from which the range may be determined such as the minimum and maximum colour values in the block/sub-block). The range may be determined using any suitable method, such as, but not limited to, the modulo method described above. Once the diversity statistics are generated, the method 1900 proceeds to step 1906 where a determination is made as to whether the range is zero (i.e. all the colour values in the channel block/sub-block are the same). If the range is zero, then the common value compression algorithm is selected at step 1908 to compress the channel block/sub-block. If, however, the range is not zero (indicating there are at least two different colour values in the channel block/sub-block) then a determination is made at step 1910 as to whether the range can be represented with fewer delta bits than the raw or original colour values. For example, if the raw or original colour values are each 8-bits then a determination is made as to whether the range can be represented with fewer than 8-bits. If it is determined at step 1910 that the range can be represented with fewer delta bits than the raw or original colour values, then the origin and delta compression algorithm may be selected at step 1912 to compress the channel block/sub-block. If, however, it is determined at step 1910 that the range cannot be represented with fewer delta bits than the raw or original colour values then at step 1914 a determination is made not to compress the channel block/sub-block. Reference is now made to FIG. 20 which illustrates a second example method 2000 for dynamically selecting a fixed-length compression algorithm for a channel block/sub-block. In this example method 2000 any of: the common value compression algorithm, the origin and delta compression algorithm, and the look-up table compression algorithm may be used to compress a channel block/sub-block. The method 2000 begins at step 2002 where a channel block/sub-block is received (e.g. a 32×32 or 16×16 block of colour values for a channel). Once the channel block/sub-block has been received, the method 2000 proceeds to step 2004 where diversity statistics are generated for the received channel block/sub-block. In this example, the diversity statistics may include the range of colour values in the channel block/sub-block (or statistics from which the range may be determined such as the minimum and maximum colour values) and the number of unique colour values in the channel block/sub-block. The range may be determined using any suitable method, such as, but not limited to, the modulo method described above. Once the diversity statistics for the channel block/sub-block have been generated, the method 2000 proceeds to step 2006 where a determination is made whether the number of unique colour values in the block/sub-block is one (i.e. all the colour values in the channel block/sub-block are the same). As the range will also be zero when there is only one unique colour value in the channel block/sub-block the decision may alternatively be based on the range. If it is determined in step 2006 that there is only one unique colour value in the block/sub-block, then at step 2008 the common value compression algorithm is selected. If, however, it is determined at step 2006 that there is more than one unique colour value in the channel block/sub-block then the method 2000 proceeds to step 2010 . At step 2010 a determination is made as to whether the number of unique colour values exceeds a threshold (e.g. 2, 3 or 4). If it is determined at step 2010 that the number of unique colour values does not exceed the threshold then the look-up table compression algorithm is selected to compress the channel block/sub-block at step 2012 . If, however, it is determined that the number of unique colour values does exceed the threshold then the method 2000 proceeds to step 2014 where a determination is made as to whether the range can be represented with fewer bits than the raw or original colour values. For example, if the raw or original colour values are each 8-bits then a determination is made as to whether the range can be represented with fewer than 8-bits. If it is determined at step 2014 that the range can be represented with fewer bits than the raw or original colour values, then the origin and delta compression algorithm is selected to compress the channel block/sub-block at step 2016 . If, however, it is determined at step 2014 that the range cannot be represented with fewer bits than the raw or original colour values then at step 2018 a determination is made not to compress the channel block/sub-block. It will be evident to a person of skill in the art that these are examples only and that any suitable criteria and/or method may be used to select a fixed-length compression algorithm for compressing a channel block/sub-block. For example, in some cases the compression algorithm that would allow the channel block/sub-block to be represented by the smallest amount of data may be selected to compress the channel block/sub-block. For example, in some cases, if it is determined at step 2010 of method 2000 of FIG. 20 that the number of unique colour values does not exceed the threshold, instead of proceeding directly to step 2012 , the total amount of data to store the channel block/sub-block using the look-up table compression algorithm may be determined (including the data in the look-up table and the indices for each colour value in the channel block/sub-block) and compared to the total amount of data to store the channel block/sub-block using the origin and delta compression algorithm (including the common base information (e.g. the origin value) and the delta values for each colour value in the channel block/sub-block). If it is determined that the total amount of data to store the channel block/sub-block using the look-up table compression algorithm is less than the total amount of data to store the channel block/sub-block using the origin and delta compression algorithm, then the method may proceed to step 2012 . If, however, it is determined that the total amount of data to store the channel block/sub-block using the look-up table compression algorithm is greater than or equal to the total amount of data to store the channel sub-block using the origin and delta compression algorithm, then the method may proceed to step 2016 . Although the methods described above for selecting a fixed-length compression algorithm to compress a channel block/sub-bock (e.g. the methods 1900 and 2000 of FIGS. 19 and 20 ) are described as forming part of the method 200 of FIG. 2 , in other examples the described methods may be used independently of the method 200 of FIG. 2 to select a fixed-length compression algorithm for a channel block/sub-block or for another block of data. Hierarchical Compression In general, the larger the size of the block/sub-block that is compressed, the simpler the header of the compressed block can be and thus the less header overhead. However, the colour values will be more diverse in a larger channel block/sub-block, therefore the number of bits needed to represent the colour values in larger channel blocks/sub-blocks is generally higher. As shown in FIGS. 8-10 , the percentage of channel blocks/sub-blocks that required a higher number of delta bits increased for channel block/sub-block sizes of 16×16 pixels and 32×32 pixels compared with channel block/sub-block sizes of 8×8 pixels. Experiments have shown that in the Manhattan 3.0 benchmark test the total compressed data size when the origin and delta compression algorithm was used increased 8% each time the compression block size increased. Specifically, in the Manhattan 3.0 benchmark test compressing the channel blocks using the origin and delta compression algorithm in 8×8 blocks reduced the size of the image data 61% relative to the uncompressed image data; in 16×16 blocks reduced the size of the image data 54%; and in 32×32 blocks reduced the size of the image data 46%. Accordingly, in general, the smaller the size of the block/sub-block that is compressed the better the compression. However, there will be some channel blocks which can be compressed well using a larger block size. Therefore, to improve the efficiency of compression without losing the ability to represent large blocks of similar colour values efficiently, in some cases a hierarchical compression scheme, which may also be referred to herein as a multi-level compression scheme, may be implemented. In a hierarchical compression scheme the blocks of the channel block that are compressed together (i.e. as a unit) are dynamically selected from a plurality of block sizes. For example, instead of determining in advance that a 32×32 channel block is going to be divided into sixteen 8×8 blocks which are compressed individually, it may be dynamically determined whether the 32×32 channel block is to be compressed as a 32×32 block or as sixteen 8×8 blocks. In some examples, non-square block sizes may be used. For example, block sizes of 32×16, 16×32, 16×8, or 8×16 may also be considered. In some cases, there may be more than two sizes or levels of compression to choose from. For example, a 32×32 channel block may be compressed at a 32×32 block level, a 16×16 block level or an 8×8 block level. In these cases, a channel block may be compressed using any combination of the lower level blocks. For example, the 32×32 block may be compressed as a 32×32 block or any combination of 16×16 and 8×8 blocks. For example, one 16×16 block may be compressed as a unit whereas the other 16×16 blocks may be compressed as 8×8 blocks. In these cases, the method 200 of FIG. 2 further comprises selecting the blocks of each channel block to compress. In general, the more diverse the colour values in a channel block, the smaller the size of the blocks that are compressed, and, the less diverse the colour values in the channel block, the larger the size of the blocks that are compressed. Any suitable criteria may be used to select the block(s) of a particular channel block to compress. In some cases, the blocks of a particular channel block to be compressed may be selected by starting with the largest block size, determining whether the channel can be suitably compressed at that size and if not, dividing that block into a plurality of sub-blocks and, if the sub-block is not the minimum block size, repeating the method for each sub-block (i.e. determine whether that sub-block can be compressed at that block-size and if not, dividing that block into a plurality of sub-blocks) until a suitable compression algorithm is selected for each sub-block or the smallest block-size has been reached. For example, FIG. 21 shows a channel block 2100 that comprises a 32×32 block of colour values which can be divided into four 16×16 sub-blocks 2102 - 0 , 2102 - 1 , 2102 - 2 , 2102 - 3 , each of which can be divided into four 8×8 sub-blocks 2104 - 0 , 2104 - 1 , 2104 - 2 , 2104 - 3 , 2104 - 4 , 2104 - 5 , 2104 - 6 , 2104 - 7 , 2104 - 8 , 2104 - 9 , 2104 - 10 , 2104 - 11 , 2104 - 12 , 2104 - 13 , 2104 - 14 , 2104 - 15 . In this example, the channel block 2100 can be compressed using any combination of 32×32, 16×16 and 8×8 blocks. In this example, a determination is first made as to whether the 32×32 channel block can be suitably compressed as a 32×32 block. If it is determined that the channel block can be compressed as a 32×32 block, then the 32×32 block is compressed. If, however, it is determined that the channel block cannot be suitably compressed as a 32×32 block then the 32×32 block is divided into four 16×16 blocks and a determination is made for each 16×16 block whether that block can be suitably compressed. If any 16×16 block can be suitably compressed, then that 16×16 block is compressed. If, however, any 16×16 block cannot be suitably compressed as a 16×16 block then that 16×16 block is divided into 8×8 blocks and the 8×8 blocks are compressed (or not compressed). In some cases, the determination of whether the channel block/sub-block can be suitably compressed at that block size is based on the size of the fixed-length parameter for that channel block/sub-block. This may result in, for example, the entire 32×32 block being compressed together, each 16×16 block being compressed together, one to three 16×16 blocks being compressed together (e.g. blocks 2102 - 0 , 2102 - 1 , and 2102 - 2 ) and the remaining 16×16 block(s) (e.g. block 2102 - 3 ) being compressed as 8×8 blocks (e.g. blocks 2104 - 12 , 2104 - 13 , 2104 - 14 , 2104 - 15 ); or all the 8×8 blocks being individually compressed. Reference is now made to FIG. 22 which illustrates an example method 2200 for selecting the blocks of a channel block to be compressed which may be implemented by a compression unit, such as the compression unit 2400 described below. The method 2200 begins at step 2202 where a channel block (e.g. a 32×32 block of colour values for a particular channel) to be compressed is received. Once the channel block has been received the method 2200 proceeds to step 2204 where the received channel block is placed on a list of blocks to be compressed. The method 2200 then proceeds to step 2206 where it is determined whether the list of blocks to be compressed is empty. If it is determined that the list is empty, then the compression of the channel block is complete, and the method 2200 ends. If, however, there is at least one block in the list of blocks to be compressed then the method 2200 proceeds to step 2208 where one of the blocks in the list of blocks to be compressed is selected and removed from the list. In the first iteration of step 2208 the channel block will be selected. In any other iteration of block 2208 (if necessary) a channel sub-block will be selected. Once a block has been selected from the list of blocks to be compressed, the method 2200 proceeds to step 2210 . At step 2210 , a fixed-length compression algorithm for compressing the block is selected or identified. Any suitable method, such as, but not limited to, those described above with reference to FIGS. 19 and 20 , may be used to select or identify a fixed-length compression algorithm for compressing the block. Once a fixed-length compression algorithm for compressing the block has been selected or identified the method 2200 proceeds to step 2212 . At step 2212 , it is determined whether the selected block is the minimum block size. If the selected block is the minimum block size, then the selected block has to be compressed at this level or left uncompressed (i.e. it cannot be divided into sub-blocks for compression). If, however, the selected block is not the minimum sized block then the block may only be compressed at this level if it can be suitably compressed using the selected or identified fixed-length compression algorithm. If it cannot be suitably compressed using the selected or identified fixed-length compression algorithm it may be divided into sub-blocks which may be individually compressed. Accordingly, if it is determined at step 2212 that the selected block is of the minimum block size, then the method 2200 proceeds to step 2214 where the selected block is compressed using the selected or identified fixed-length compression algorithm (which may include storing the raw or original colour values). If, however, it is determined at step 2212 that the selected block is not the minimum block size (i.e. it is larger than a minimum sized block) then the method 2200 proceeds to step 2216 . At step 2216 , the size of the fixed-length parameter when the selected fixed-length compression algorithm is used to compress the selected block is determined. Once the size of the fixed-length parameter is determined, the method 2200 then proceeds to step 2218 . At step 2218 , a determination is made as to whether the size of the fixed-length parameter exceeds a threshold which indicates that the block can be suitably or efficiently compressed. In some cases, the threshold may be 0 meaning that a higher level block size is only used if all the colour values in the block are the same. In other cases, the threshold may be another small number such as, but not limited to, 1, 2 or 3. In some cases, the threshold may be based on the size of the selected block. Therefore there may be different thresholds for different sized blocks (e.g. the 32×32 block threshold may be different than the 16×16 block threshold). If it is determined at step 2218 that the size does not exceed the threshold, then the method 2200 proceeds to step 2214 where the selected block is compressed using the selected or identified fixed-length compression algorithm. If, however it is determined at step 2218 that the size of the fixed-length parameter exceeds the threshold (e.g. indicating that it is not suitable or efficient to compress this entire block together) then the method 2200 proceeds to steps 2220 and 2222 where the block is divided into a plurality (e.g. n) of sub-blocks and the sub-blocks are added to the list of blocks to be compressed. The number and size of the sub-blocks may be based on the size of the selected block and the block sizes supported by the compression unit. In some cases, the selected block is divided into sub-blocks of the next smallest supported block size. For example, if the channel block is a 32×32 pixel block and the compression unit can compress the 32×32 pixel block at the 32×32 pixel block level, the 16×16 pixel block level or an 8×8 pixel block level, then if the selected block is a 32×32 pixel block it may be divided into four 16×16 pixel blocks, and if the selected block is a 16×16 pixel block it may be divided into four 8×8 pixel blocks. Once the sub-blocks have been added to the list of blocks to be compressed, steps 2210 to 2222 are repeated for each sub-block. Specifically, for each sub-block, a fixed-length compression algorithm is selected or identified for that sub-block. If the sub-block is the smallest supported block size then the sub-block is compressed using the selected or identified fixed-length compression algorithm. If, however, the sub-block is not the minimum supported block size the size of the fixed-length parameter for the selected fixed-length compression algorithm is determined. If the size of the fixed-length parameter does not exceed the threshold then the sub-block is compressed according to the selected fixed-length compression algorithm. If, however, the size of the fixed-length parameter for the selected fixed-length compression algorithm exceeds the threshold then the sub-block is further sub-divided into sub-sub-blocks or mini-blocks and the sub-sub-blocks or mini blocks are added to the list of block to be compressed. The method is then repeated for the sub-sub-blocks or the mini blocks until the entire channel block has been compressed. It will be evident to a person of skill in the art that where there is only one fixed-length compression algorithm or the fixed-length compression algorithm for a selected block is predetermined then step 2210 may be omitted for that block. It will be evident to a person of skill in the art that this is an example method only and that other suitable methods may be used to select the blocks of a channel block to be compressed. For example, other methods may work in reverse—i.e. they may start with the lowest level blocks and only if it is possible to compress the lower level blocks with a certain number of bits is the higher level block considered for compression. When a hierarchical compression scheme is implemented the compressed block (e.g. the header of the compressed block) may also comprise information indicating which blocks of each channel have been compressed. For example, in some cases, the header of the compressed block may comprise for each compression level, information for each block at that level, that indicates whether that block has been compressed together for each channel. For example, RGBA image data for a 32×32 block of pixels comprises four 32×32 channel blocks of colour values. If each channel block can be compressed as a 32×32 block, as one or more 16×16 blocks and/or one or more 8×8 blocks then there are three compression levels—level 1: compression of a 32×32 block; level 2: compression of 16×16 blocks; and level 3: compression of 8×8 blocks. In this example there is one block at level 1 thus the header of the compressed block may comprise information for that block that indicates whether that block has been compressed for each channel. There are four blocks at level 2 thus the header may comprise information for each of these four blocks that indicate whether that block has been compressed for each channel. There are sixteen blocks at level 3 thus the header may comprise information for each of these sixteen blocks that indicate whether that block has been compressed for each channel. Reference is now made to FIG. 23 which illustrates an example header 2302 for a compressed block of image data that has been generated using a hierarchical compression scheme (i.e. the blocks and the sizes thereof that are compressed are dynamically selected). In this example, the header is generated for a 32×32 block of image data with four channels such that each of the four channel blocks comprises a 32×32 block of colour values like the channel block 2100 of FIG. 21 . In this example there are three possible levels of compression—level 1: 32×32 block, level 2: 16×16 blocks; and level 3: 8×8 blocks. However, it will be evident to a person of skill in the art that this is an example only and that the techniques and principles described herein may be applied to different sized image/channel blocks that can be compressed at different block sizes. The header 2302 of FIG. 23 is divided into a level 1 section 2304 , a level 2 section 2306 and a level 3 section 2308 . Each section 2304 , 2306 , 2308 comprises information for each block at that level that indicates whether that block is compressed for each channel. Each section 2304 , 2306 , 2308 also comprises information indicating the length or size of the fixed-length parameter and the common base information for any block at that level that is compressed. In some cases, the corresponding section will also include information that indicates the fixed-length compression algorithm which was used to compress the block. In the example shown in FIG. 23 , each section 2304 , 2306 , 2308 comprises a set of compression fields (one for each channel) for each block at that level that indicates whether or not that channel block is compressed at that level. For example, at level 1 there is only one block—the 32×32 block—so the level 1 section 2304 comprises a set of four compression fields 2310 , 2312 , 2314 , 2316 (one for each channel) which indicates whether the 32×32 block of that channel was compressed. For example, the first compression field 2310 indicates whether the 32×32 block was compressed for channel 0, the second compression field 2312 indicates whether the 32×32 block was compressed for channel 1, the third compression field 2314 indicates whether the 32×32 block was compressed for channel 2 and the fourth compression field 2316 indicates whether the 32×32 block was compressed for channel 3. In this example, a ‘1’ in a compression field indicates that the block was compressed for that channel and a ‘0’ indicates that the block of that channel was not compressed. When the compression field indicates that a block is compressed for a channel at a particular level, it indicates that the channel block is represented at that level in the encoding using one of the available compression methods, which, it should be noted, may also include a raw (or not compressed) mode. Accordingly, the level 1 section 2304 of FIG. 23 indicates that only channel 3 was compressed as a 32×32 block. Similarly, at level 2 there are four blocks (i.e. four 16×16 blocks) so the level 2 section 2306 comprises a set of four compression fields (i.e. one for each channel) for each of the four 16×16 blocks which indicates whether the 16×16 block of that channel was compressed. There are therefore sixteen compression fields at level 2, of which eight are illustrated as fields 2322 , 2324 , 2326 , 2328 , 2334 , 2336 , 2338 , and 2340 . Similarly, at level 3 there are sixteen blocks (i.e. sixteen 8×8 blocks) so the level 3 section 2308 comprises a set of four compression (i.e. one for each channel) for each of the sixteen 8×8 blocks which indicates whether the 8×8 block of that channel was compressed. There are therefore sixty four compression fields at level 3, of which eight are illustrated as fields 2342 , 2344 , 2346 , 2348 , 2358 , 2360 , 2362 , and 2364 . If the compression field for any block indicates that the block is compressed for a channel then the corresponding section 2304 , 2306 and 2308 of the header 2302 also comprises information indicating the size or length of the fixed-length parameter and the common base information for that block for that channel. Specifically, in the example shown in FIG. 23 for any block that was compressed for a channel the corresponding section 2304 , 2306 , 2308 of the header 2302 comprises a length field 2318 , 2330 , 2350 , 2352 , 2366 , 2368 , 2370 that indicates the length or size of the fixed-length parameter for that block; and a common base information field 2320 , 2332 , 2354 , 2356 , 2372 , 2374 , 2376 that indicates the common base information for that block. For example, the first 16×16 block (i.e. 16×16 block 0) is compressed for channel 2 only so the level 2 section 2306 comprises a length field 2330 and common base information field 2332 for channel 2 for that block. Similarly, the last 8×8 block (i.e. 8×8 block 15 ) is compressed for channels 0, 1 and 2 so the level 3 section 2308 comprises a length field 2366 , 2368 , 2370 and a common base information field 2372 , 2374 , 2376 for each of channels 0, 1 and 2. The length field and the common base information field may be configured as described above with respect to FIG. 15 . It will be evident to a person of skill in the art that this is an example header only and that the header may take any suitable form. For example, in other cases, instead of having a length field and common base information field for each compressed block there may be a compression algorithm field, a length field and a common base information field as described with respect to FIG. 16 . In yet other cases, instead of having a separate compression field and length field there may be a single length field which indicates whether or not the block is compressed, and if so, indicates the compression algorithm and the length or size of the fixed-length parameter. For example, as described above with respect to FIG. 15 there may be a 4-bit length field where a 0 (‘0000’ (binary)) indicates that the corresponding channel block was compressed using the common value compression algorithm; any number between 1 (‘0001’ (binary)) and 7 (‘0111’ (binary)) indicates that the corresponding channel block was compressed using the origin and delta compression algorithm and the parameter length (i.e. the number of delta bits) is equal to that number; an 8 (‘1000’ (binary)) indicates that the corresponding channel block was not compressed and the raw or original colour values of that channel block are included in the compressed block; and a 15 (‘1111’ (binary)) indicates that the corresponding channel block was not compressed (or, not encoded) at this level. This is summarised in Table 4. TABLE 4Is the channel blockSize Fieldcompressed/encodedCompressionParameter(binary)at this level?RawAlgorithmLength0000YNCommon0Value0001-0111YNOrigin andValue inDeltaSize Field1000YY——1111N——— Where the hierarchical compression scheme is used to compress a block of image data the fixed-length parameters and/or original colour values may be stored in the body at the smallest block level. For example, if each channel block can be compressed at a 32×32 block level or an 8×8 block level then the fixed-length parameters and/or original colour values corresponding to each 8×8 image block may be stored or grouped together. This ensures that any pixel within a particular 8×8 block will be represented by the same number of data bits allowing a particular pixel to be randomly accessible within that block. Specifically, either a channel will be compressed/not compressed at this level meaning that the number of bits per colour value for that channel are fixed by the compression algorithm/no compression at this level or a channel will be compressed at a higher level meaning that the number of bits per colour value for that channel are fixed by the compression algorithm at the higher level. Although the hierarchical compression method is described as forming part of the method 200 of FIG. 2 , in other examples the hierarchical compression method may be used independently of the method 200 of FIG. 2 to compress a channel block/sub-block or other image data (e.g. image data with only a single two-dimensional block of values). For example, in some cases the hierarchical compression method may be used to compress colour data at the pixel level. Compression Reference is now made to FIG. 24 which illustrates an example compression unit 2400 (which may form part of the compression/decompression unit 112 of FIG. 1 ) for compressing a block of image data using the method 200 of FIG. 2 . The compression unit 2400 comprises a header generation unit 2402 and a body generation unit 2404 . The header generation unit 2402 is configured to receive the block of image data to be compressed and generate the header for the compressed data block based on the received image data. The received image data comprises data for an n×m block of pixels which can be divided into an n×m block of colour values for each colour channel. As described above, the header of the compressed data block comprises information that identifies which blocks of each channel block are compressed and if a block of a channel block is compressed, the header also comprises information identifying the length or size of the fixed-length parameters for that block and the common base information for that block. Where the blocks of each colour channel that are to be compressed and the fixed-length compression algorithm to be used to compress those blocks are known then the header generation unit 2402 may be configured to determine, for each block of the channel blocks to be compressed, the length of the fixed-length parameters and the common base information based on the colour values in those blocks. For example, if each 8×8 block of each channel block is to be compressed using the origin and delta compression algorithm then the header generation unit may be configured to, for each 8×8 block: (i) analyse the colour values in the block to determine the range of values in each 8×8 block; (ii) determine the number of delta bits to represent the range; and (iii) identify the origin value (e.g. the minimum value). Where the fixed-length compression algorithm to be used to compress a particular block of a channel block is not known in advance (i.e. is not predetermined) then the header generation unit 2402 may also be configured to dynamically select the fixed-length compression algorithm to be used to compress that particular block. The header generation unit 2402 may be configured to select one of a plurality of fixed-length compression algorithms to be used to compress a particular block of a channel block in any suitable manner. For example, the header generation unit 2402 may be configured to select a fixed-length compression algorithm to be used to compress a block of a channel block in accordance with any of the methods described above (e.g. method 1900 or method 2000 of FIGS. 19 and 20 respectively). Where the particular blocks of a channel block that are to be compressed are not known in advance (i.e. they are not predetermined) then the header generation unit 2402 may also be configured to dynamically select the blocks of the channel block that are to be compressed. Any suitable method, such as a hierarchical method 2200 described above with respect to FIG. 22 may be used to dynamically select the blocks of a channel block that are to be compressed. The body generation unit 2404 is configured to receive the block of image data and the header generated by the header generation unit 2402 and compress one or more blocks of at least one channel block in accordance with the header. Specifically, the body generation unit 2404 compresses each of the one or more blocks of the at least one channel by generating a fixed-length parameter for each colour value of that block based on the information in the header. As described above, where the blocks to be compressed are known in advance (i.e. are predetermined) and the fixed-length compression algorithm(s) to be used to compress those blocks is/are known in advance (i.e. is/are predetermined) then the header may comprise information identifying the length or size of the fixed-length parameter for each block to be compressed and the common base information. In these cases the body generation unit is configured to generate a fixed-length parameter for each colour value in each relevant block based on the length of the fixed-length parameter for that block and the common base information for that block in accordance with the known fixed-length compression algorithm for that block. For example, if it is known in advance that each 8×8 block is to be compressed using the origin and delta compression algorithm then the body generation unit 2404 generates a delta value (of the specified length) for each colour value in each 8×8 block that represents the difference between the colour value and the origin value for that block. Where the fixed-length compression algorithm(s) and/or the blocks to be compressed are not known in advance then the header may also comprise information indicating which blocks of each channel block are to be compressed and/or the fixed-length compression algorithm to be used to compress the relevant blocks. In these cases, the body generation unit 2404 may be configured to identify which blocks of each channel block are to be compressed based on the information in the header and/or the fixed-length compression algorithm to be used to compress each of the relevant blocks. Once the body generation unit 2404 has generated the fixed-length parameters for each block to be compressed, the body generation unit 2404 may be configured to generate the body of the compressed block by combining or merging the fixed-length parameters of each compressed block and the raw colour values for each uncompressed block. As described above, in some cases, the body may be generated by packing the fixed-length parameter(s) and/or colour values for each pixel into a pixel data unit, and then packing the pixel data units of each block together. In some cases, the body and the header may be merged (by the body generation unit 2404 or another unit) to form a complete compressed block. However, in other cases the body and the header may be output separately. The body and header may be stored in memory (e.g. frame buffer) together or separately. Decompression Reference is now made to FIG. 25 which illustrates an example decompression unit 2500 (which may form part of the compression/decompression unit 112 of FIG. 1 ) for decompressing compressed image data generated in accordance with the method 200 of FIG. 2 to provide a channel colour value for a selected pixel. The decompression unit 2500 comprises a header analysis unit 2502 which is configured to analyse the header to identify the common base information for the channel colour value for the selected pixel and the location of the fixed-length parameter or colour value for the channel colour value for the selected pixel in the body; a body analysis unit 2504 configured to retrieve the fixed-length parameter or colour value from the identified location in the body; and a colour value generation unit 2506 configured to generate the colour value based on the common base information and the fixed-length parameter; or the colour value. The operation of the decompression unit 2500 will now be described in detail with respect to FIG. 26 . Reference is now made to FIG. 26 which illustrates an example method 2600 , which may be implemented by the decompression unit 2500 of FIG. 25 , for decompressing a compressed block of image data generated in accordance with the methods described herein to produce a channel colour value for a selected pixel (which may be referred to herein as a pixel channel colour value). The method 2600 begins at step 2602 where the compressed block of image data is received at the decompression unit 2500 . As described herein, the compressed block of image data comprises a header and a body. The header comprises information that indicates, for example, the blocks/sub-blocks that are compressed for each channel, and the length of the fixed-length parameter and the common base information of each compressed block/sub-block. The body comprises the fixed-length parameters for each compressed block and the raw colour values for each uncompressed block. As described above, in some cases, a whole channel block may be compressed such that the header comprises (i) a single set of common base information for that channel block, and (ii) information identifying the length of the fixed-length parameters; and the body comprises a fixed-length parameter for each colour value in the channel block. In other cases, one or more sub-blocks of a channel block may be compressed. In these cases, the header comprises (i) a set of common base information for each compressed channel sub-block, and (ii) information identifying the length of fixed-length parameters for each compressed block, and the body comprises, for each compressed sub-block, a fixed-length parameter for each colour value in that sub-block. For example, where two sub-blocks of a channel block are compressed the header may comprise (i) common base information that is common to the colour values in the first sub-block and common base information that is common to the colour values in the second sub-block, and (ii) information indicating the length of the fixed-length parameters for the first sub-block and information indicating the length of the fixed-length parameters for the second sub-block; and the body may comprise a first fixed-length parameter for each colour value in the first sub-block and a second fixed-length parameter for each colour value in the second sub-block. Where multiple channel sub-blocks are compressed the different sub-blocks may have a different size and/or they may be compressed by different fixed-length compression algorithms. For example, in a hierarchical compression scheme where a 32×32 channel block may be compressed at a 32×32 block level, a 16×16 block level or an 8×8 block level the 32×32 block may be compressed as a 32×32 block or any combination of 16×16 and 8×8 blocks. For example, one 16×16 block may be compressed as a unit whereas the other 16×16 blocks may be compressed as 8×8 blocks. Similarly, where multiple channel sub-blocks are compressed different fixed-length compression algorithms may be used to compress different sub-blocks. Also, as described above, the compressed block of image data may comprise information representing the colour values of a single channel block or multiple channel blocks. Where the compressed block of image data comprises information representing the colour values of multiple channel blocks (i.e. multiple colour channels) the header may comprise information indicating which block/sub-blocks of each channel have been compressed and for each block/sub-block of a channel that has been compressed the common base information and the length of the fixed-length parameter and, optionally the fixed-length compression algorithm that was used to compress that block/sub-block; and the body may comprise a fixed-length parameter for each colour value in a compressed channel block/sub-block and the colour value for each uncompressed channel block/sub-block. Different channels may be compressed in different sized blocks/sub-blocks and/or with different fixed-length compression algorithms. Once the compressed block of image data has been received the method 2600 proceeds to step 2604 . At step 2604 , the header analysis unit 2502 analyses the header of the compressed block to (i) determine the location in the body of the fixed-length parameter (if compressed) or the colour value (if not compressed) for the channel colour for the selected pixel; and (ii) determine the common base information related to the channel colour value for the selected pixel (if compressed). In some cases the location in the body of the fixed-length parameter (if compressed) or the colour value (if not compressed) may be based on the size of the fixed-length parameters for the compressed block/sub-block to which the desired colour value belongs. Specifically, when a block of image data is compressed in accordance with the methods described herein the colour values within the lowest block/sub-block level that relate to a particular channel will be represented by a fixed number of bits, thus if the bits that relate to each colour value are stored in a predetermined order the bits in the body of the compressed block that relate to a particular colour value can be determined from the number of bits used to represent the colour values of each channel. For example, for a four-channel image, if the lowest block-level for the compressed block is an 8×8 block then each channel 0 colour value in that 8×8 block will be represented by the same number of bits b 0 , each channel 1 colour value in that 8×8 block will be represented by the same number of bits b 1 , each channel 2 colour value in that 8×8 block will be represented by the same number of bits b 2 , and each channel 3 colour value in that 8×8 block will be represented by the same number of bits b 3 . Thus, if all the bits that relate to the same pixel are packed together to form a pixel data unit, then each pixel data unit will have b 0 +b 1 +b 2 +b 3 bits. If the pixel data units for a block are then packed together in pixel order to form a block data unit then the start of the pixel data unit for the i th pixel, wherein the first pixel is numbered 0, is at the i*(b 0 +b 1 +b 2 +b 3 ) bit from the start of the block data unit. As described above, in some cases, the start of the block data unit may be determined from the length of the fixed-length parameters; and, in other cases, the header may comprise an offset value for the block that indicates the offset from the start of the body of the compressed data block at which the block data unit begins. The particular bits of the pixel data unit that correspond to a particular colour value can then be determined from b 0 , b 1 , b 2 , b 3 and the ordering of the channels in the pixel data unit. For example, if the bits of each channel are packed together in the pixel data unit in channel order, then the bits corresponding to the colour value for channel 0 are the first b 0 bits in the pixel data unit; the bits corresponding to the colour value for channel 1 are the b 1 bits starting from bit b 0 ; the bits corresponding to the colour value for channel 2 are the b 2 bits starting from bit b 0 +b 1 ; and the bits corresponding to the colour value for channel 3 are the last b 3 bits starting from bit b 0 +b 1 +b 2 . If the fixed-length compression algorithm is not predetermined, the header analysis unit 2502 may also determine, from the header, the fixed-length compression algorithm used to compress the channel colour value for the selected pixel. Once the location of the fixed-length parameter or colour value in the body, and the common base information have been determined from the header of the compressed block the method 2600 proceeds to step 2606 . At step 2606 , the body analysis unit 2504 retrieves the fixed-length parameter (if compressed) or the colour value (if not compressed) for the channel colour value for the selected pixel from the location of the body determined by the header analysis unit. Once the fixed-length parameter or the raw colour value has been retrieved from the body of the compressed block, the method 2600 proceeds to step 2608 . At step 2608 , the colour value generation unit 2506 generates the raw colour value from the retrieved colour value (if not compressed) or from the common base information and the fixed-length parameter (if compressed). How the original colour value is generated from the common base information and the fixed-length parameter is based on the fixed-length compression algorithm used to compress the channel colour value. For example, if the common value compression algorithm was used to compress the colour value then the common base information comprises the common colour value, the fixed-length parameter has zero bits, and the common colour value is used as the channel colour value; if the origin and delta compression algorithm was used to compress the colour value then the common base information comprise the origin value, the fixed-length parameter comprises a delta value representing the difference between the origin value and the colour value, and the desired colour value is generated by adding the origin value and the delta value (as described above, in some cases the addition may be performed modulo m wherein m=2 x wherein each colour value comprises x bits); if the multiple origin and delta compression algorithm was used to compress the colour value then the common base information comprises multiple origin values and the fixed-length parameter comprises an index identifying one of the origin values and a delta value representing the difference between the identified origin value and the colour value, and the desired colour value is generated by adding the identified origin value and the delta value (as described above, in some cases the addition may be performed modulo m wherein m=2 x wherein each colour value comprises x bits); if the look-up table compression algorithm was used to compress the colour value then the common base information comprises a look-up table with a plurality of colour values and the fixed-length parameter comprises an index that identifies one of the colour values in the look-up table (i.e. an index to the look-up table), and the colour value that is identified by the index is used as the desired colour value; and if the predetermined colour compression algorithm was used to compress the colour value then the common base information comprises information identifying one of one or more predetermined colour values, the fixed-length parameter comprises zero bits, and the identified predetermined colour value is used as the desired colour value. As described above, when the predetermined colour compression algorithm is used there may be only a single predetermined colour value and the common base information may comprise information indicating that the predetermined colour compression algorithm was used to compress the colour value. In other cases, there may be a plurality of predetermined colour values where one or more of the predetermined colour values are fixed and/or one or more of the predetermined colour values may be configurable. In some cases, the common base information may identify a particular predetermined colour value for more than one channel. For example, the common base information may indicate that the colour values for the first channel are a particular predetermined colour value and the colour values for a second channel are a particular predetermined colour value. For example, the common base information may indicate that the pixel colour value (i.e. the combination of the channel colour values) for the pixels in the compressed block is a predetermined value. The fixed-length compression algorithm that was used to compress the colour value may be predetermined, or determined from the header by the header analysis unit 2502 and then provided to the colour value generation unit 2506 . Test Results Reference is now made to FIG. 27 which illustrates the results of using the described compression method for the Manhattan 3.0 benchmark test. Specifically, FIG. 27 shows the size of the compressed blocks of image data (including the header data and the body data) relative to the uncompressed blocks of image data when 32×32 image data blocks were compressed at a single level of compression—i.e. a 32×32 block, 16×16 blocks or 8×8 blocks—using the origin and delta compression method. It can be seen at 2702 that when the 32×32 blocks of image data were compressed in 8×8 blocks the size of the compressed data blocks were 40% of the size of the uncompressed blocks of image data which is a 60% reduction. As shown at 2704 , when the 32×32 blocks of image data were compressed in 16×6 blocks the size of the compressed data blocks were 46% of the size of the uncompressed blocks of image data, which is a 54% reduction. As shown at 2706 , when the 32×32 blocks of image data were compressed in 32×32 blocks the size of the compressed data blocks were 54% of the size of the uncompressed blocks of image data, which is a 46% reduction. Accordingly, the simpler single level compression has shown to work particularly well for an 8×8 block level. FIG. 27 also shows at 2708 that when a hierarchical compression method was implemented such that 32×32 blocks were compressed at a 16×16 block level if there was a common colour value in the 16×16 block, otherwise the 8×8 blocks were compressed using the origin and delta compression algorithm, the size of the compressed blocks of image data was 39% of the size of the uncompressed blocks of image data, which is a 61% reduction. FIG. 27 also shows at 2710 that when a hierarchical compression method was implemented such that 32×32 blocks were compressed at a 32×32 level if there was a common colour value in the 32×32 block, if not the 8×8 blocks were compressed using the origin and delta compression algorithm, the size of the compressed blocks of image data was 39% of the size of the uncompressed block of image data, which is also a 61% reduction. Thus an improvement in the level of compression can be achieved with a hierarchical compression scheme, but this increases the complexity of the compression and decompression. It was found on average that the size of the header was about 7% of the size of the compressed blocks of image data. Reference is now made to FIG. 28 which illustrates the percentage of 8×8 blocks that have a common colour value (which are also referred to herein as unique colour blocks) for each of a plurality of benchmark tests for each of a plurality of different block sizes. Reference is now made to FIG. 29 which illustrates the size of the compressed blocks of image data (including the header data and the body data) relative to the uncompressed blocks of image data when 32×32 image data blocks were compressed according to each of the following for each of a plurality of benchmark tests: a single level of compression—8×8 blocks—using the origin and delta compression algorithma single level of compression—16×16 blocks—using the origin and delta compression algorithma single level of compression—32×32 block—using the origin and delta compression algorithmMulti-level compression— 32×32 block if common value—using the common value compression algorithm16×16 block if common value—using the common value compression algorithm8×8 blocks using the origin and delta compression algorithm FIG. 30 shows a computer system in which the compression units, decompression units, and compression/decompression units described herein may be implemented. The computer system comprises a CPU 3002 , a GPU 3004 , a memory 3006 and other devices 3014 , such as a display 3016 , speakers 3018 and a camera 3020 . A processing block 3010 (which may be a compression unit, a decompression unit, or a compression/decompression unit described herein) is implemented on the GPU 3004 . In other examples, the processing block 3010 may be implemented on the CPU 3002 . The components of the computer system can communicate with each other via a communications bus 3022 . The compression and decompression units of FIGS. 24-25 are shown as comprising a number of functional blocks or units. This is schematic only and is not intended to define a strict division between different logic elements of such entities. Each functional block or unit may be provided in any suitable manner. It is to be understood that intermediate values described herein as being formed by a block or unit need not be physically generated by compression or decompression unit at any point and may merely represent logical values which conveniently describe the processing performed by the compression or decompression unit between its input and output. The compression units, decompression units, and/or compression/decompression units described herein may be embodied in hardware on an integrated circuit. The compression units, decompression units, and/or compression/decompression units described herein may be configured to perform any of the methods described herein. Generally, any of the functions, methods, techniques or components described above can be implemented in software, firmware, hardware (e.g., fixed logic circuitry), or any combination thereof. The terms “module,” “functionality,” “component”, “element”, “unit”, “block” and “logic” may be used herein to generally represent software, firmware, hardware, or any combination thereof. In the case of a software implementation, the module, functionality, component, element, unit, block or logic represents program code that performs the specified tasks when executed on a processor. The algorithms and methods described herein could be performed by one or more processors executing code that causes the processor(s) to perform the algorithms/methods. Examples of a computer-readable storage medium include a random-access memory (RAM), read-only memory (ROM), an optical disc, flash memory, hard disk memory, and other memory devices that may use magnetic, optical, and other techniques to store instructions or other data and that can be accessed by a machine. The terms computer program code and computer readable instructions as used herein refer to any kind of executable code for processors, including code expressed in a machine language, an interpreted language or a scripting language. Executable code includes binary code, machine code, bytecode, code defining an integrated circuit (such as a hardware description language or netlist), and code expressed in a programming language code such as C, Java or OpenCL. Executable code may be, for example, any kind of software, firmware, script, module or library which, when suitably executed, processed, interpreted, compiled, executed at a virtual machine or other software environment, cause a processor of the computer system at which the executable code is supported to perform the tasks specified by the code. A processor, computer, or computer system may be any kind of device, machine or dedicated circuit, or collection or portion thereof, with processing capability such that it can execute instructions. A processor may be any kind of general purpose or dedicated processor, such as a CPU, GPU, System-on-chip, state machine, media processor, an application-specific integrated circuit (ASIC), a programmable logic array, a field-programmable gate array (FPGA), or the like. A computer or computer system may comprise one or more processors. It is also intended to encompass software which defines a configuration of hardware as described herein, such as HDL (hardware description language) software, as is used for designing integrated circuits, or for configuring programmable chips, to carry out desired functions. That is, there may be provided a computer readable storage medium having encoded thereon computer readable program code in the form of an integrated circuit definition dataset that when processed (i.e. run) in an integrated circuit manufacturing system configures the system to manufacture a compression unit, decompression unit, or compression/decompression unit configured to perform any of the methods described herein, or to manufacture a processor comprising any apparatus described herein. An integrated circuit definition dataset may be, for example, an integrated circuit description. Therefore, there may be provided a method of manufacturing, at an integrated circuit manufacturing system, a compression unit, a decompression unit, and/or compression/decompression unit as described herein. Furthermore, there may be provided an integrated circuit definition dataset that, when processed in an integrated circuit manufacturing system, causes the method of manufacturing a compression unit, decompression unit, and/or compression/decompression unit to be performed. An integrated circuit definition dataset may be in the form of computer code, for example as a netlist, code for configuring a programmable chip, as a hardware description language defining hardware suitable for manufacture in an integrated circuit at any level, including as register transfer level (RTL) code, as high-level circuit representations such as Verilog or VHDL, and as low-level circuit representations such as OASIS® and GDSII. Higher level representations which logically define hardware suitable for manufacture in an integrated circuit (such as RTL) may be processed at a computer system configured for generating a manufacturing definition of an integrated circuit in the context of a software environment comprising definitions of circuit elements and rules for combining those elements in order to generate the manufacturing definition of an integrated circuit so defined by the representation. As is typically the case with software executing at a computer system so as to define a machine, one or more intermediate user steps (e.g. providing commands, variables etc.) may be required in order for a computer system configured for generating a manufacturing definition of an integrated circuit to execute code defining an integrated circuit so as to generate the manufacturing definition of that integrated circuit. An example of processing an integrated circuit definition dataset at an integrated circuit manufacturing system so as to configure the system to manufacture a compression unit, a decompression unit, and/or a compression/decompression unit will now be described with respect to FIG. 31 . FIG. 31 shows an example of an integrated circuit (IC) manufacturing system 3102 which is configured to manufacture a compression unit, a decompression unit, and/or a compression/decompression unit as described in any of the examples herein. In particular, the IC manufacturing system 3102 comprises a layout processing system 3104 and an integrated circuit generation system 3106 . The IC manufacturing system 3102 is configured to receive an IC definition dataset (e.g. defining a compression unit, a decompression unit, and/or a compression/decompression unit as described in any of the examples herein), process the IC definition dataset, and generate an IC according to the IC definition dataset (e.g. which embodies a compression units, decompression units, or compression/decompression unit as described in any of the examples herein). The processing of the IC definition dataset configures the IC manufacturing system 3102 to manufacture an integrated circuit embodying a compression unit, a decompression unit, or a compression/decompression unit as described in any of the examples herein. The layout processing system 3104 is configured to receive and process the IC definition dataset to determine a circuit layout. Methods of determining a circuit layout from an IC definition dataset are known in the art, and for example may involve synthesising RTL code to determine a gate level representation of a circuit to be generated, e.g. in terms of logical components (e.g. NAND, NOR, AND, OR, MUX and FLIP-FLOP components). A circuit layout can be determined from the gate level representation of the circuit by determining positional information for the logical components. This may be done automatically or with user involvement in order to optimise the circuit layout. When the layout processing system 3104 has determined the circuit layout it may output a circuit layout definition to the IC generation system 3106 . A circuit layout definition may be, for example, a circuit layout description. The IC generation system 3106 generates an IC according to the circuit layout definition, as is known in the art. For example, the IC generation system 3106 may implement a semiconductor device fabrication process to generate the IC, which may involve a multiple-step sequence of photo lithographic and chemical processing steps during which electronic circuits are gradually created on a wafer made of semiconducting material. The circuit layout definition may be in the form of a mask which can be used in a lithographic process for generating an IC according to the circuit definition. Alternatively, the circuit layout definition provided to the IC generation system 3106 may be in the form of computer-readable code which the IC generation system 3106 can use to form a suitable mask for use in generating an IC. The different processes performed by the IC manufacturing system 3102 may be implemented all in one location, e.g. by one party. Alternatively, the IC manufacturing system 3102 may be a distributed system such that some of the processes may be performed at different locations, and may be performed by different parties. For example, some of the stages of: (i) synthesising RTL code representing the IC definition dataset to form a gate level representation of a circuit to be generated, (ii) generating a circuit layout based on the gate level representation, (iii) forming a mask in accordance with the circuit layout, and (iv) fabricating an integrated circuit using the mask, may be performed in different locations and/or by different parties. In other examples, processing of the integrated circuit definition dataset at an integrated circuit manufacturing system may configure the system to manufacture a compression unit, a decompression unit, or a compression/decompression unit without the IC definition dataset being processed so as to determine a circuit layout. For instance, an integrated circuit definition dataset may define the configuration of a reconfigurable processor, such as an FPGA, and the processing of that dataset may configure an IC manufacturing system to generate a reconfigurable processor having that defined configuration (e.g. by loading configuration data to the FPGA). In some embodiments, an integrated circuit manufacturing definition dataset, when processed in an integrated circuit manufacturing system, may cause an integrated circuit manufacturing system to generate a device as described herein. For example, the configuration of an integrated circuit manufacturing system in the manner described above with respect to FIG. 31 by an integrated circuit manufacturing definition dataset may cause a device as described herein to be manufactured. In some examples, an integrated circuit definition dataset could include software which runs on hardware defined at the dataset or in combination with hardware defined at the dataset. In the example shown in FIG. 31 , the IC generation system may further be configured by an integrated circuit definition dataset to, on manufacturing an integrated circuit, load firmware onto that integrated circuit in accordance with program code defined at the integrated circuit definition dataset or otherwise provide program code with the integrated circuit for use with the integrated circuit. The implementation of concepts set forth in this application in devices, apparatus, modules, and/or systems (as well as in methods implemented herein) may give rise to performance improvements when compared with known implementations. The performance improvements may include one or more of increased computational performance, reduced latency, increased throughput, and/or reduced power consumption. During manufacture of such devices, apparatus, modules, and systems (e.g. in integrated circuits) performance improvements can be traded-off against the physical implementation, thereby improving the method of manufacture. For example, a performance improvement may be traded against layout area, thereby matching the performance of a known implementation but using less silicon. This may be done, for example, by reusing functional blocks in a serialised fashion or sharing functional blocks between elements of the devices, apparatus, modules and/or systems. Conversely, concepts set forth in this application that give rise to improvements in the physical implementation of the devices, apparatus, modules, and systems (such as reduced silicon area) may be traded for improved performance. This may be done, for example, by manufacturing multiple instances of a module within a predefined area budget. The applicant hereby discloses in isolation each individual feature described herein and any combination of two or more such features, to the extent that such features or combinations are capable of being carried out based on the present specification as a whole in the light of the common general knowledge of a person skilled in the art, irrespective of whether such features or combinations of features solve any problems disclosed herein. In view of the foregoing description it will be evident to a person skilled in the art that various modifications may be made within the scope of the invention.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"105-679-025-408-434","jurisdiction":"US","doc_number":"12368187","kind":"B2","date_published":"2025-07-22","doc_key":"US_12368187_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12368187","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"17106263","date":"2020-11-30"},"priority_claims":{"claims":[{"jurisdiction":"JP","doc_number":"2020-004448","date":"2020-01-15","sequence":1}],"earliest_claim":{"date":"2020-01-15"}},"invention_title":[{"text":"Secondary battery including a wound electrode body with specified foil bundling","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"1751","extracted_name":{"value":"Jonathan G Leong"}},"assistant_examiner":{"extracted_name":{"value":"Tony S Chuo"}}},"applicants":[{"residence":"JP","extracted_name":{"value":"TOYOTA JIDOSHA KABUSHIKI KAISHA"},"extracted_address":"Toyota"}],"inventors":[{"residence":"JP","sequence":1,"extracted_name":{"value":"Koshiro Yoneda"},"extracted_address":"Ichinomiya"},{"residence":"JP","sequence":2,"extracted_name":{"value":"Fumihiko Ishiguro"},"extracted_address":"Oobu"}],"agents":[{"extracted_name":{"value":"Oliff PLC"}}]},"classifications_ipcr":{"classifications":[{"symbol":"H01M10/05","classification_value":"I","classification_symbol_position":"F"},{"symbol":"H01M4/66","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H01M10/0587","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"H01M10/0587","classification_value":"I","classification_symbol_position":"F"},{"symbol":"H01M4/66","classification_value":"I","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2010/0203371","kind":"A1","date":"2010-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0044533","kind":"A1","date":"2015-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0164133","kind":"A1","date":"2016-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0076424","kind":"A1","date":"2018-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"105702999","kind":"A","date":"2016-06-01"},"lens_id":"003-166-119-526-86X"}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"107808975","kind":"A","date":"2018-03-01"},"lens_id":"062-344-884-532-414"}},{"patcit":{"document_id":{"jurisdiction":"JP","doc_number":"2002-008708","kind":"A","date":"2002-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"JP","doc_number":"2007-305322","kind":"A","date":"2007-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"JP","doc_number":"2009-026705","kind":"A","date":"2009-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"KR","doc_number":"10-2016-0070015","kind":"A","date":"2016-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"KR","doc_number":"10-2019-0058428","kind":"A","date":"2019-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"WO","doc_number":"2009/013592","kind":"A2","date":"2009-01-01"},"lens_id":"030-750-475-340-801"}}],"patent_count":12},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12368187","kind":"B2","date":"2025-07-22"},"lens_id":"105-679-025-408-434"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12368187","kind":"B2","date":"2025-07-22"},"lens_id":"105-679-025-408-434"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"A secondary battery has a flat-shaped wound electrode body and a rectangular battery case housing the wound electrode body. In the wound electrode body, in at least any one of a positive electrode current collection foil laminated part and a negative electrode current collection foil laminated part, a positive electrode current collection foil exposed portion or a negative electrode current collection foil exposed portion is foil-bundled at a foil-bundling position and joined to a positive electrode current collection terminal or a negative electrode current collection terminal. At the foil-bundling position, the thickness A of the wound electrode body in the lamination direction and the shortest distance B to the foil-bundling position from the vertex of the R portion closest to the foil-bundling position among R portions of the wound electrode body satisfy, B≤(1/2) A.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A secondary battery comprising: a wound electrode body formed in a flat shape, in which a positive electrode and a negative electrode are wound in a longitudinal direction after being overlapped a plurality of times while a separator is interposed therebetween, the positive electrode being a sheet -shaped member in which a positive electrode active material layer is formed on an elongated positive electrode current collection foil and the negative electrode being a sheet-shaped member in which a negative electrode current collection foil is formed on an elongated negative electrode active material layer; a positive electrode current collection terminal joined to the positive electrode of the wound electrode body; a negative electrode current collection terminal joined to the negative electrode of the wound electrode body; and a battery case housing the wound electrode body, the battery case having a rectangular prismatic shape and a rectangular wide-width surface, wherein the wound electrode body includes a positive electrode active material layer laminated portion in which the positive electrode active material layer is laminated, a negative electrode active material layer laminated portion in which the negative electrode active material layer is laminated, a positive electrode current collection foil laminated part arranged at one of both end portions of the positive electrode active material layer laminated portion and the negative electrode active material layer laminated portion in a winding axis direction, the positive electrode current collection foil laminated part being laminated in a state where a positive electrode current collection foil exposed portion of the positive electrode current collection foil is protruded from the negative electrode, and the positive electrode current collection foil exposed portion being a portion in which the positive electrode active material layer is not formed, and a negative electrode current collection foil laminated part arranged at the other of the both end portions of the positive electrode active material layer laminated portion and the negative electrode active material layer laminated portion in the winding axis direction, the negative electrode current collection foil laminated part being laminated in a state where a negative electrode current collection foil exposed portion of the negative electrode current collection foil is protruded from the positive electrode, and the negative electrode current collection foil exposed portion being a portion in which the negative electrode active material layer is not formed, a foil-bundling position is provided in the positive electrode current collection foil laminated part, the positive electrode current collection foil exposed portion is foil-bundled at the foil-bundling position, and the positive electrode current collection foil exposed portion which has been foil-bundled at the foil-bundling position is joined to the positive electrode current collection terminal; the separator is adjacent to part of the positive electrode current collection foil exposed portion; the positive electrode current collection foil exposed portion that is laminated is joined to the positive electrode current collection terminal in a continuous manner along the lamination direction, or the negative electrode current collection foil exposed portion that is laminated is joined to the negative electrode current collection terminal in a continuous manner along the lamination direction; and in a case where a thickness of the wound electrode body in a lamination direction is denoted by A, and a shortest distance to the foil-bundling position from a vertex of an R portion closest to the foil-bundling position among R portions of the wound electrode body is denoted by B, the foil-bundling position satisfies, B≤(1/2) A, wherein an angle between a first current collection foil which has been foil-bundled and a plane direction of the laminated positive electrode or the laminated negative electrode is 35° or more and 40° or less and a scratch depth generated in the separator is less than 6 μm, wherein the first current collection foil is a current collection foil present at a position farthest from the foil-bundling position of two current collection foils constituting an outer surface of both end portions of the positive electrode current collection foil laminated part or the negative electrode current collection foil laminated part in the lamination direction, and wherein in a case where a shortest distance between the foil-bundling position and a boundary line of the positive electrode active material layer laminated portion or the negative electrode active material layer laminated portion in the winding axis direction is denoted by C, C≥(1/3) A is satisfied."]},{"claim_text":["2. The secondary battery according to claim 1 , wherein the foil -bundling position is present in the positive electrode current collection foil laminated part."]},{"claim_text":["3. The secondary battery according to claim 1 , wherein the positive electrode current collection foil exposed portion and the positive electrode current collection terminal, or the negative electrode current collection foil exposed portion and the negative electrode current collection terminal, are joined by ultrasonic welding."]},{"claim_text":["4. The secondary battery according to claim 1 , wherein the thickness of the wound electrode body in a lamination direction A is 11.4 mm."]},{"claim_text":["5. The secondary battery according to claim 1 , wherein the angle between the first current collection foil which has been foil-bundled and the plane direction of the laminated positive electrode or the laminated negative electrode is about 40°."]},{"claim_text":["6. The secondary battery according to claim 1 , wherein the negative electrode active material layer includes graphite."]},{"claim_text":["7. The secondary battery according to claim 1 , wherein a heat resistant layer is provided on a surface of the separator."]},{"claim_text":["8. The secondary battery according to claim 1 , wherein the separator has an air permeability of 350 seconds/100 cc or less."]}],"lang":"en"}],"description":{"text":"CROSS-REFERENCE TO RELATED APPLICATION This application claims priority to Japanese Patent Application No. 2020-004448 filed on Jan. 15, 2020, incorporated herein by reference in its entirety. BACKGROUND 1. Technical Field The present disclosure relates to a secondary battery. More specifically, the present disclosure relates to a secondary battery having a flat-shaped wound electrode body and a rectangular battery case housing the electrode body. 2. Description of Related Art Since secondary batteries such as a lithium ion secondary battery (lithium secondary battery), a sodium ion secondary battery, and a nickel hydrogen battery are lighter in weight and have higher energy density than existing batteries, the secondary batteries are used as a so-called portable power source of personal computers and mobile terminals and as a battery for driving a vehicle. In particular, the lithium ion secondary battery, which is lightweight and has a high energy density, is preferably used as a high output power source for driving vehicles such as an electric vehicle (EV), a hybrid vehicle (HV), and a plug-in hybrid vehicle (PHV). As one configuration of this type of secondary battery, a configuration including an electrode body having a positive or negative electrode laminate structure in which a sheet-shaped positive electrode (hereinafter, may be referred to as “positive electrode sheet”) having a positive electrode active material layer that is formed on a positive electrode current collection foil and a sheet-shaped negative electrode (hereinafter, may be referred to as “negative electrode sheet”) having a negative electrode active material layer that is formed on a negative electrode current collection foil are alternatively overlapped multiply while a separator is interposed between the positive electrode and the negative electrode is mentioned. For example, a so-called wound electrode body in which an elongated positive electrode sheet and a similarly an elongated negative electrode sheet are overlapped while a separator is interposed therebetween, wound in the longitudinal direction, and formed into a flat shape is a typical example of an electrode body having the positive or negative electrode laminate structure (see Japanese Unexamined Patent Application Publication No. 2007-305322 (JP 2007-305322 A). In such a wound electrode body described above, in the winding axis direction of the wound electrode body, a positive electrode current collection foil laminated part that is configured such that an active material layer non-forming portion (hereinafter, also referred to as a “positive electrode current collection foil exposed portion”) of each of the laminated positive electrode sheets is multiply overlapped is present at one end portion of the main body portion of the wound electrode body (that is, a laminate structure portion of a positive or negative electrode, in other words, refers to a portion in which a positive or negative electrode active material layer forming portion is formed while facing each other) in the winding axis direction of the wound electrode body. Similarly, a negative electrode current collection foil laminated part that is configured such that an active material layer non-forming portion (hereinafter, also referred to as a “negative electrode current collection foil exposed portion”) of each of the laminated negative electrode sheets is multiply overlapped is present at the other end portion of the main body portion. Further, each current collection structure of the positive or negative electrode is formed by bundling the current collection foil laminated part (hereinafter, also referred to as “foil-bundling”), arranging a part of the current collection terminal of the corresponding electrode, and joining them by welding means such as ultrasonic welding. SUMMARY As a secondary battery has a high output and energy density, various contrivances (for example, thinning of the current collection foil and reduction of the length of the current collection foil exposed portion of the current collection foil in the winding axis direction) have been made to reduce the volume of the non-storage battery component such as a current collection foil in order to increase the volume of the main body portion of the electrode body housed inside the battery case having a predetermined volume. However, for example, in the wound electrode body that has been devised as described above, of the two current collection foils constituting an outer surface of both ends of the current collection foil laminated parts in the lamination direction, an angled portion (that is, a stress concentrated portion in which a high surface pressure is generated) may be generated between the space from the boundary line of an active material layer forming portion of one current collection foil present at the position relatively far from the foil-bundling position to an end portion of the other current collection foil facing the one current collection foil, due to the foil-bundling position of the current collection foil laminated part. As a result, the internal resistance in the battery may increase due to damage to the separator adjacent to the one current collection foil. As a secondary battery has a high output and energy density, an object of the present disclosure is to provide a secondary battery having a wound electrode body in which a current collection foil is thinned and the length of a current collection foil exposed portion in the winding axis direction is reduced. In an aspect of the present disclosure, a secondary battery includes a wound electrode body, a positive electrode current collection terminal, a negative electrode current collection terminal, and a case that houses the wound electrode body. The wound electrode body is formed in a flat shape, in which a positive electrode and a negative electrode are wound in the longitudinal direction after being overlapped a plurality of times while a separator is interposed therebetween. The positive electrode is a sheet-shaped member in which a positive electrode active material layer is formed on an elongated positive electrode current collection foil, and the negative electrode is a sheet-shaped member in which a negative electrode active material layer is formed on an elongated negative electrode current collection foil. The positive electrode current collection terminal is joined to the positive electrode of the wound electrode body, and the negative electrode current collection terminal is joined to the negative electrode of the wound electrode body. The case has a rectangular prismatic shape having a rectangular wide-width surface. The wound electrode body disclosed herein includes a positive electrode active material layer laminated portion in which a positive electrode active material layer is laminated and a negative electrode active material layer laminated portion in which a negative electrode active material layer is laminated. A positive electrode current collection foil laminated part is arranged at one of both end portions of the positive electrode active material layer laminated portion and the negative electrode active material layer laminated portion in a winding axis direction. The positive electrode current collection foil laminated part is laminated in a state where a positive electrode current collection foil exposed portion of the positive electrode current collection foil, in which the positive electrode active material layer is not formed, is protruded from the negative electrode. A negative electrode current collection foil laminated part is arranged at the other of the both end portions of the positive electrode active material layer laminated portion and the negative electrode active material layer laminated portion in the winding axis direction. The negative electrode current collection foil laminated part is laminated in a state where a negative electrode current collection foil exposed portion of the negative electrode current collection foil, in which the negative electrode active material layer is not formed, is protruded from the positive electrode. In at least any one of the positive electrode current collection foil laminated part and the negative electrode current collection foil laminated part, the positive electrode current collection foil exposed portion or the negative electrode current collection foil exposed portion is foil-bundled at a foil-bundling position. The positive electrode current collection foil exposed portion or the negative electrode current collection foil exposed portion, each of which has been foil-bundled at the foil-bundling position, is joined to the positive electrode current collection terminal or the negative electrode current collection terminal. Further, in a case where the thickness of the wound electrode body in the lamination direction is denoted by A, and the shortest distance to the foil-bundling position from the vertex of the R portion closest to the foil-bundling position among R portions of the wound electrode body is denoted by B, the foil-bundling position described above satisfies, B≤(1/2) A. According to the above aspect, of the two current collection foils constituting an outer surface in both ends of the current collection foil laminated parts of the positive electrode and negative electrode in the lamination direction, an angled portion (that is, a stress concentrated portion in which a high surface pressure is generated) is unlikely to be generated between the boundary line of an active material layer forming portion of one current collection foil present at the position relatively far from the foil-bundling position and an end of the other current collection foil facing the one current collection foil. Thus the possibility that the separator adjacent to the one current collection foil is damaged is reduced. As a result, the increase in internal resistance in the battery can be reduced. In the above aspect, the angle (hereinafter, also referred to as “foil-bundling angle”) between the first current collection foil which has been bundled and the plane direction (that is, the direction orthogonal to the lamination direction of the positive electrode and the negative electrode) of the laminated positive electrode or negative electrode may be less than 40°. The first current collection foil 60 is a current collection foil present at the position relatively farthest from the foil-bundling position of the two current collection foils constituting the outer surface of both the ends of the positive electrode current collection foil laminated part or the negative electrode current collection foil laminated part in the lamination direction. As described above, in a case where the foil-bundling angle is 40° or less as described above, the angled portion is further difficult to be generated, and the possibility that the separator adjacent to the current collection foil is damaged is suitably reduced. As a result, the increase in internal resistance in the battery can be suitably reduced. In the above aspect, in a case where the shortest distance between the foil-bundling position and the boundary line of the positive electrode active material layer laminated portion or negative electrode active material layer laminated portion in the winding axis direction is denoted by C, C≥(1/3) A may be satisfied. Since the foil-bundling angle is reduced by defining the distance C as described above, the angled portion is difficult to be generated, and the possibility that the separator adjacent to the current collection foil is damaged is further suitably reduced. As a result, the increase in internal resistance in the battery can be further suitably reduced. In addition, the distance C may satisfy C≥(1/2) A. In the above aspect, the foil-bundling position may be present in the positive electrode current collection foil laminated part. Generally, a positive electrode sheet (positive electrode) is made larger than a negative electrode sheet (negative electrode). For this reason, of the two current collection foils constituting the outer surface of both the ends of the positive electrode current collection foil laminated part in the lamination direction, in a case where the angled portion is generated when one current collection foil present at the position relatively farthest from the foil-bundling position is foil-bundled, a separator adjacent to the other current collection foil interferes with the end portion of the negative electrode in the vicinity of the current collection foil, and thus the separator may be greatly damaged. Accordingly, in a case where the foil-bundling position is provided in the positive electrode current collection foil laminated part, the effects of the present disclosure can be suitably exhibited. In the above aspect, the positive electrode current collection foil exposed portion and the positive electrode current collection terminal, or the negative electrode current collection foil exposed portion and the negative electrode current collection terminal may be joined by ultrasonic welding. The ultrasonic welding is a joining method characterized by sandwiching the current collection foil laminated part and the corresponding current collection terminal of the electrode with are a horn and an anvil of an ultrasonic welding device, and welding the sandwiched current collection foil laminated part and corresponding current collection terminal by applying a pushing load from the horn in the anvil direction while applying vibration. However, in a case where the vibration is applied to the angled portion, the separator adjacent to the current collection foil may be greatly damaged. For this reason, in a case where ultrasonic welding is performed at the time of joining the current collection terminal, the effects of the present disclosure can be suitably exhibited. BRIEF DESCRIPTION OF THE DRAWINGS Features, advantages, and technical and industrial significance of exemplary embodiments of the disclosure will be described below with reference to the accompanying drawings, in which like signs denote like elements, and wherein: FIG. 1 is a cross-sectional view schematically illustrating an outer shape and an internal configuration of a lithium ion secondary battery according to one embodiment; FIG. 2 is a side cross-sectional view schematically illustrating the inside of a lithium ion secondary battery according to one embodiment; FIG. 3 is a perspective view schematically illustrating a wound electrode body according to one embodiment; FIG. 4 is a schematic view illustrating an aspect of foil-bundling of a positive electrode current collection foil laminated part according to the one embodiment; FIG. 5 is a graph showing a relationship between a foil-bundling position (B/A) and a foil-bundling angle (degree) of the positive electrode current collection foil laminated part in FIG. 4 ; FIG. 6 is a graph showing a relationship between the foil-bundling angle in FIG. 4 and a surface pressure applied to a separator; and FIG. 7 is a graph showing a relationship between a change of the surface pressure applied to the separator when the foil-bundling angle is changed, and a change of a depth of a scratch generated in the separator. DETAILED DESCRIPTION OF EMBODIMENTS Hereinafter, embodiments of the present disclosure will be described with reference to the drawings. In the following drawings, the same reference signs are given to the members and sites from which the same actions are obtained, for description. Further, the dimensional relationships (for example, length, width, and thickness) in each drawing do not reflect the actual dimensional relationships. It is noted that matters other than matters particularly referred to in the present specification and necessary for carrying out the present disclosure (for example, a general configuration and manufacturing process of the entire secondary battery that does not characterize the present disclosure) may be understood as a design matter for those skilled in the art based on the related art in the related field. The present disclosure can be carried out based on the contents disclosed in the present specification and the common general technical knowledge in the field. In the present specification, the term “secondary battery” refers to a general electricity storage device that can be repeatedly charged and discharged. Hereinafter, as an example of the secondary battery disclosed herein, a rectangular lithium ion secondary battery having a flat-shaped wound electrode body is described as an example. However, the following description is not intended to limit the present disclosure to the lithium ion secondary battery. For example, a so-called storage battery (that is, a chemical battery) such as a nickel hydrogen battery or a nickel cadmium battery, or an electric double layer capacitor (that is, a physical battery) is also included. A lithium ion secondary battery 100 illustrated in FIG. 1 is constructed by housing a flat-shaped wound electrode body 20 and an electrolytic solution (not shown) in a rectangular battery case (that is, an outer container) 10 . In a lid 12 of the battery case 10 , a positive electrode external terminal 38 and a negative electrode external terminal 48 for external connection, a thin safety valve 14 set to release an internal pressure of the battery case 10 when the internal pressure rises above a predetermined level, and an injection port (not shown) for injecting the electrolytic solution is provided. Parts of the external terminals 38 and 48 are respectively connected to the positive electrode current collection terminal 37 and the negative electrode current collection terminal 47 , at the inside of the case. As a material for the battery case 10 , for example, a lightweight and highly heat-conductive metal material such as aluminum is used. Details of B and C, which are parameters involved in defining the foil-bundling position, will be described later. As illustrated in FIG. 3 , the wound electrode body 20 has a configuration in which a positive electrode sheet 30 having a positive electrode active material layer 34 which is formed on one surface or both surfaces (in FIG. 3 , both surfaces) of an elongated positive electrode current collection foil 32 along the longitudinal direction and a negative electrode sheet 40 having a negative electrode active material layer 44 which is formed on one surface or both surfaces (in FIG. 3 , both surfaces) of an elongated negative electrode current collection foil 42 along the longitudinal direction are wound in the longitudinal direction after being overlapped while two separators 50 interposed therebetween. Further, the positive electrode current collection terminal 37 and the negative electrode current collection terminal 47 are respectively joined to a positive electrode current collection foil laminated part 35 in which a positive electrode current collection foil exposed portion 36 (that is, a portion in which the positive electrode current collection foil 32 is exposed without forming the positive electrode active material layer 34 ) is laminated and a negative electrode current collection foil laminated part 45 in which a negative electrode current collection foil exposed portion 46 (that is, a portion in which the negative electrode current collection foil 42 is exposed without forming the negative electrode active material layer 44 ) is laminated, where the positive electrode current collection foil exposed portion 36 and the negative electrode current collection foil exposed portion 46 are formed so as to be respectively protruded outside of both ends of the wound electrode body 20 in the winding axis direction. As illustrated in FIG. 2 , the above-described joining is performed by foil-bundling the positive or negative electrode current collection foil laminated part (the positive electrode current collection foil laminated part 35 or the negative electrode current collection foil laminated part 45 ) at a predetermined foil-bundling position, followed by arranging a part of the corresponding electrode of the current collection terminal (the positive electrode current collection terminal 37 or the negative electrode current collection terminal 47 ) and joining the arranged part by the welding means such as ultrasonic welding. Details A, which is a parameter involved in defining the foil-bundling position, will be described later. Here, “foil-bundling” refers to bundling the current collection foil laminated part, and “foil-bundling position” refers to a position in which the current collection foil laminated part is bundled. For the positive electrode sheet 30 and the negative electrode sheet 40 , the same materials as those used in the related art of the lithium ion secondary battery can be used without particular limitation. One typical aspect is described below. An example of the positive electrode current collection foil 32 constituting the positive electrode sheet 30 include an aluminum foil. Examples of the positive electrode active material included in the positive electrode active material layer 34 include a lithium transition metal oxide (for example, LiNi 1/3 Co 1/3 Mn 1/3 O 2 , LiNiO 2 , LiCoO 2 , LiFeO 2 , LiMn 2 O 4 , and LiNi 0.5 Mn 1.5 O 4 ) and a lithium transition metal phosphate compound (for example, LiFePO 4 ). The positive electrode active material layer 34 may include components other than the active material, such as a conductive material and a binder. As the conductive material, for example, carbon black such as acetylene black (AB) or other carbon materials (for example, graphite) can be suitably used. As the binder, for example, polyvinylidene fluoride (PVDF) can be used. An example of the negative electrode current collection foil 42 constituting the negative electrode sheet 40 includes a copper foil. As the negative electrode active material included in the negative electrode active material layer 44 , for example, carbon materials such as graphite, hard carbon, and soft carbon can be used. Among them, graphite is preferred. The graphite may be natural graphite or artificial graphite, and may be covered with an amorphous carbon material. The negative electrode active material layer 44 may include components other than the active material, such as a binder and a viscosity improver. As the binder, for example, styrene-butadiene rubber (SBR) may be used. As the viscosity improver, for example, carboxymethyl cellulose (CMC) may be used. As the separator 50 , a porous sheet (film) made of polyolefins such as polyethylene (PE) and polypropylene (PP) may be suitably used. The porous sheet may have a single-layer structure or a laminated structure of two or more layers (for example, a three-layer structure in which PP layers are laminated on both surfaces of a PE layer). A heat resistant layer (HRL) may be provided on the surface of the separator 50 . The air permeability of the separator 50 , which is measured by the Gurley test method, is not particularly limited but is preferably 350 seconds/100 cc or less. The electrolytic solution included in the lithium ion secondary battery disclosed herein usually contains a non-aqueous solvent and a supporting electrolyte. For the non-aqueous solvent, a known one used as a non-aqueous solvent for a lithium ion secondary battery electrolytic solution can be used, and specific examples thereof include a carbonate, an ether, an ester, a nitrile, a sulfone, and a lactone. Among them, a carbonate is preferred. Examples of the carbonate include ethylene carbonate (EC), propylene carbonate (PC), diethyl carbonate (DEC), dimethyl carbonate (DMC), and ethyl methyl carbonate (EMC). These may be used alone or in a combination of two or more thereof. In addition, as the supporting electrolyte, a known supporting electrolyte used as a supporting electrolyte of an electrolytic solution for a lithium ion secondary battery can be used, and specific examples thereof include LiPF 6 , LiBF 4 , and lithium bis(fluorosulfonyl)imide (LiFSI) and lithium bis(trifluoromethane)sulfonimide (LiTFSI). The concentration of the supporting electrolyte in the electrolytic solution is not particularly limited, but is, for example, 0.5 mol/L or more and 5 mol/L or less, preferably 0.7 mol/L or more and 2.5 mol/L or less, and more preferably 0.7 mol/L or more and 1.5 mol/L or less. The electrolytic solution may contain other components as long as the effects of the present disclosure are not significantly impaired. Examples of the other components include gas generating agents such as biphenyl (BP) and cyclohexylbenzene (CHB); a film forming agent; a dispersant; and a viscosity improver. The method for preparing the above-described electrolytic solution may be a conventionally known method, and the above-described electrolytic solution can be used for a lithium ion secondary battery according to a known method. Further, the lithium ion secondary battery disclosed here can be manufactured by a conventionally known method. Since the present disclosure relates to the foil-bundling position in the current collection foil laminated part, detailed descriptions of the methods therefor will be omitted. In the lithium ion secondary battery 100 disclosed herein, in a case where the thickness of the wound electrode body 20 in the lamination direction is denoted by A, and the shortest distance to the foil-bundling position from the vertex of the R portion 70 closest to the foil-bundling position among R portions 70 , 71 of the electrode body is denoted by B, the foil-bundling position illustrated in FIG. 1 satisfies, B≤(1/2) A. Hereinafter, the effects of the present disclosure will be described with reference to FIG. 4 which is a schematic view illustrating an aspect of foil-bundling the positive electrode current collection foil laminated part, but it is not intended that the practice of the present disclosure be limited to the positive electrode current collection foil laminated part. In a case where A and B are defined as described above, of the two current collection foils constituting the outer surface of both the ends of the positive electrode current collection foil laminated part in the lamination direction, one positive electrode current collection foil present at a position relatively far from the foil-bundling position is denoted by 32 a as illustrated in FIG. 4 , an angled portion (that is, a stress concentrated portion in which a high surface pressure is generated) is difficult to be generated between the space from the boundary line of an active material layer forming portion of the positive electrode current collection foil 32 to an end portion of the other the current collection foil facing the positive electrode current collection foil 32 . As a result, the possibility that the separator 50 a adjacent to the one current collection foil is damaged is reduced. Accordingly, the increase in internal resistance in the battery can be reduced. In addition, the foil-bundling angle P illustrated in FIG. 4 (that is, the angle between the plane direction O of the positive electrode 30 a and the foil-bundling direction Q) is preferably 40° or less. In FIG. 4 , the angle P between a current collection foil 32 a present at a position relatively far from the foil-bundling position of two current collection foils constituting an outer surface of both end portions of the positive electrode current collection foil laminated part 35 , and the plane direction O of the positive electrode 30 a is 40° or less. As described will be later in detail, in a case where the foil-bundling angle P is 40° or less, the angled portion is difficult to be generated, and thus the possibility that the separator 50 a is damaged is suitably reduced. As a result, the increase in internal resistance in the battery can be suitably reduced. In addition, the shortest distance between the foil-bundling position and the boundary line of the active material layer laminated portion of the same electrode in the winding axis direction is denoted by C. At this time, it is preferable that the thickness A, the distance B, and the distance C satisfy C≥(1/3) A while satisfying B≤(1/2) A. In this case, the foil-bundling angle P is reduced, the angled portion is difficult to be generated, and thus the possibility that the separator 50 a is damaged is suitably reduced. As a result, the increase in internal resistance in the battery can be further suitably reduced. In addition, the distance C more preferably satisfies C≥(1/2) A. In addition, in a case where the current collection terminal (the positive electrode current collection terminal 37 or the negative electrode current collection terminal 47 ) are joined by ultrasonic welding, the effects of the present disclosure can be suitably exhibited. For example, in the ultrasonic welding of the positive electrode, the welding is performed by sandwiching the positive electrode current collection foil laminated part and the positive electrode current collection terminal of the electrode with a horn and an anvil of an ultrasonic welding device, and welding the sandwiched positive electrode current collection foil laminated part and positive electrode current collection terminal while applying a pushing load from the horn in the anvil direction while applying vibration. However, in a case where the vibration is applied to the angled portion generated in the positive electrode current collection foil 32 a, the separator 50 a adjacent to the positive electrode current collection foil 32 a may be greatly damaged. For this reason, in a case where the current collection terminal is joined by ultrasonic welding, the effects of the present disclosure can be suitably exhibited. In addition, since the positive electrode sheet (positive electrode) is made larger than the negative electrode sheet (negative electrode), in a case where the angled portion is generated when the positive electrode current collection foil 32 a is foil-bundled, the separator 50 a interferes with the end portion of the negative electrode 40 a in the vicinity of the separator 50 a, and thus the separator 50 a may be greatly damaged. Accordingly, in a case where the foil-bundling position is provided in the positive electrode current collection foil laminated part, the effects of the present disclosure can be suitably exhibited. Hereinafter, test results of an evaluation test using a lithium ion secondary battery as one example of the secondary battery disclosed herein will be described with reference to FIG. 4 to FIG. 7 . Production of Lithium Ion Secondary Battery for Evaluation A lithium nickel cobalt manganese composite oxide as a positive electrode active material powder, acetylene black (AB) as a conductive material, and polyvinylidene fluoride (PVdF) as a binder were prepared. The lithium nickel cobalt manganese composite oxide, AB, and PVdF were with N-methylpyrrolidone (NMP) to prepare a slurry for forming a positive electrode active material layer. A positive electrode sheet was produced by applying the slurry to an aluminum foil and then drying the applied slurry. A natural graphite-based carbon material (C) as a negative electrode active material, styrene butadiene rubber (SBR) as a binder, and carboxymethyl cellulose (CMC) as a viscosity improver were prepared. These were mixed with ion exchange water in the mass ratio of C:SBR:CMC=98:1:1 to prepare a slurry for forming a negative electrode active material layer. A negative electrode sheet was produced by applying the slurry to a copper foil and then drying the applied slurry. As a separator, a polyolefin porous film having a three-layer structure of PP/PE/PP was prepared. For producing a non-aqueous electrolytic solution, a mixed solvent containing ethylene carbonate (EC), dimethyl carbonate (DMC), and ethyl methyl carbonate (EMC) in the volume ratio of 30:40:30 was prepared. Then, LiPF 6 as a supporting electrolyte was dissolved in the mixed solvent at a concentration of 1.0 mol/L. The positive electrode sheet and the negative electrode sheet produced as described above were wound a plurality of times while the separator was interposed therebetween and then formed into a flat shape to produce a wound electrode body. After being attached to a current collection terminal, the electrode body was housed together with the electrolytic solution and sealed in a rectangular battery case. In this manner, a lithium ion secondary battery for evaluation was produced. For performing the present evaluation test, two types of lithium ion secondary batteries each having a thickness A of the electrode body of 11.4 mm and 25.4 mm in the lamination direction were produced. Measuring Method for Foil-Bundling Angle Here, the “foil-bundling angle” refers to a foil-bundling angle P (see FIG. 4 ). The foil-bundling angle P was calculated by foil-bundling a positive electrode current collection foil laminated part at a predetermined foil-bundling position, followed by scanning an aspect of the foil-bundling with a 3D scanner manufactured by Keyence Corporation and performing data analysis. The measurement was performed according to the attached manual. Measuring Method for Surface Pressure Applied to Separator Here, the “surface pressure applied to separator” refers to surface pressure applied to a separator 50 a at S in FIG. 4 . The surface pressure was measured using a tactile sensor manufactured by Nitta Corporation, after foil-bundling the positive electrode current collection foil laminated part at a predetermined foil-bundling position. The measurement was performed according to the attached manual. Measuring Method for Scratch depth on Separator Here, “scratch depth on separator” refers to a scratch depth generated on the separator 50 a when the surface pressure is applied to the separator 50 a at the S of FIG. 4 . The scratch depth was measured using a laser microscope manufactured by Keyence Corporation, after foil-bundling the positive electrode current collection foil laminated part at a predetermined foil-bundling position. The measurement was performed according to the attached manual. The graph of FIG. 5 shows the relationship between the foil-bundling position (defined by B/A) and the foil-bundling angle P (degree) in two types of lithium ion secondary batteries each having an A of 11.4 mm and 25.4 mm. From FIG. 5 , it has been confirmed that the foil-bundling angle P is around 40° (hereinafter, “around 40°” means 35° to 45°) in the range which satisfies B/A≤1/2, that is, B≤(1/2) A in a case where the A is 11.4 mm. It has been also confirmed that the foil-bundling angle P is 50° to 70° in the range which satisfies 1/2<B/A<1, that is, (1/2) A<B<A. Similar results were also obtained in a case where the A was 25.4 mm. FIG. 6 and FIG. 7 relate to a lithium ion secondary battery having an A of 11.4 mm. In the graph of FIG. 6 , the relationship between the foil-bundling angle P and the surface pressure applied to the separator 50 a at the S is shown. In the graph of FIG. 7 , the relationship between the surface pressure applied to the separator 50 a at the S and the scratch depth generated in the separator 50 a by the surface pressure is shown. From the FIG. 6 and FIG. 7 , it has been confirmed that in a case where the foil-bundling angle P is around 40°, the surface pressure applied to the separator 50 a at the S is less than 300 kPa, and the scratch depth generated in the separator 50 a is less than 6 μm (In a case where the scratch depth exceeds 8 μm, the internal resistance in the battery may increase, which is not preferable). Further, it has been confirmed that in a case where the foil-bundling angle P is 50° to 70°, the surface pressure applied to the separator 50 a at the S exceeds 500 kPa, and the scratch depth generated in the separator 50 a greatly exceeds 8 μm. From the above results, it can be seen that in a case where the range of B/A≤1/2 is satisfied, the foil-bundling angle P is around 40°, whereby the angled portion is difficult to be generated, and thus the surface pressure applied to the separator 50 a at the S is decreased. As a result, the possibility that the separator 50 a is damaged is reduced, and thus an increase in the internal resistance in the battery can be suppressed. In addition, it can be seen that the above-described effects of the present disclosure are suitably exhibited regardless of the magnitude of the thickness A of the wound electrode body. Further, it can be seen that since the possibility that the separator 50 a is damaged is suitably reduced in a case where the foil-bundling angle is around 40°, a reliable secondary battery in which the increase in the internal resistance is suitably suppressed can be obtained in a case where the foil-bundling angle is defined to be 40° or less. Specific examples of the present disclosure have been described in detail as above, but these are merely examples and do not limit the scope of CLAIMS. The technology described in the scope of CLAIMS includes various modifications and changes of the specific examples exemplified above. The lithium ion secondary battery configured as described above can be used for various applications. A suitable application thereof includes a driving power source mounted in vehicles such as an electric vehicle (EV), a hybrid vehicle (HV), and a plug-in hybrid vehicle (PHV).","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"054-370-484-347-18X","jurisdiction":"US","doc_number":"12367731","kind":"B2","date_published":"2025-07-22","doc_key":"US_12367731_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12367731","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"17533140","date":"2021-11-23"},"priority_claims":{},"invention_title":[{"text":"Electric portion controlled dry food dispenser","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"3753","extracted_name":{"value":"Timothy L Maust"}}},"applicants":[{"residence":"IL","extracted_name":{"value":"Ofer Landau"},"extracted_address":"Ein Vered"},{"residence":"IL","extracted_name":{"value":"Ido Landau"},"extracted_address":"Raanana"}],"inventors":[{"residence":"IL","sequence":1,"extracted_name":{"value":"Ofer Landau"},"extracted_address":"Ein Vered"},{"residence":"IL","sequence":2,"extracted_name":{"value":"Ido Landau"},"extracted_address":"Raanana"}]},"classifications_ipcr":{"classifications":[{"symbol":"G07F11/62","classification_value":"I","classification_symbol_position":"F"},{"symbol":"A47G19/34","classification_value":"I","classification_symbol_position":"L"},{"symbol":"B65D83/06","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06K7/14","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H04N7/18","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"G07F11/62","classification_value":"I","classification_symbol_position":"F"},{"symbol":"A47G19/34","classification_value":"I","classification_symbol_position":"L"},{"symbol":"B65D83/06","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06K7/1413","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06K7/1417","classification_value":"I","classification_symbol_position":"L"},{"symbol":"H04N7/18","classification_value":"A","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"5230300","kind":"A","date":"1993-07-01"},"lens_id":"059-497-350-968-618"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"5466894","kind":"A","date":"1995-11-01"},"lens_id":"190-020-606-327-912"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"5738153","kind":"A","date":"1998-04-01"},"lens_id":"072-029-824-041-157"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"5947336","kind":"A","date":"1999-09-01"},"lens_id":"088-723-952-584-974"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"6367417","kind":"B1","date":"2002-04-01"},"lens_id":"137-628-608-219-716"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"6622655","kind":"B2","date":"2003-09-01"},"lens_id":"091-848-211-916-588"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"8584714","kind":"B2","date":"2013-11-01"},"lens_id":"191-203-386-143-289"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"9549640","kind":"B2","date":"2017-01-01"},"lens_id":"057-083-324-478-671"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2008/0190964","kind":"A1","date":"2008-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0131384","kind":"A1","date":"2014-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2020/0193758","kind":"A1","date":"2020-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"CA","doc_number":"2973161","kind":"A1","date":"2015-02-01"},"lens_id":"090-948-006-541-205"}},{"patcit":{"document_id":{"jurisdiction":"CN","doc_number":"111528716","kind":"A","date":"2020-08-01"},"lens_id":"176-874-261-941-600"}},{"patcit":{"document_id":{"jurisdiction":"EP","doc_number":"2294948","kind":"A1","date":"2011-03-01"},"lens_id":"057-819-950-557-480"}},{"patcit":{"document_id":{"jurisdiction":"JP","doc_number":"2003116393","kind":"A","date":"2003-04-01"},"lens_id":"099-127-590-787-130"}},{"nplcit":{"text":"Design U.S. Appl. No. 29/809,912, filed on titled Electric Food Dispenser filed Sep. 30, 2021."}},{"nplcit":{"text":"European Design Application No. 008710834-0001, filed on Sep. 30, 2021."}}],"npl_count":2,"patent_count":15},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367731","kind":"B2","date":"2025-07-22"},"lens_id":"054-370-484-347-18X"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367731","kind":"B2","date":"2025-07-22"},"lens_id":"054-370-484-347-18X"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"Some embodiments of the current invention relate to an automatic and/or sanitary dry goods dispenser. Optionally, a manual dispenser may be upgraded for automatic dispensing. For example, a motor optionally opens and/or closes a dispensing valve fully and/or partially. For example, the opening and closing may be adjusted to achieve a desired flow rate and/or dispensing volume. Optionally, the device may include a valve biased to a closed configuration. Optionally, a motor that opens the valve for a fixed time and/or for as long as a switch remains in an activated and/or oscillates the valve. Additionally or alternatively, a manual operation option is available. In some embodiments, the opening and/or closing may be preprogrammed. For example, a user will purchase goods and/or a program will be transferred to the dispenser according to his purchase.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A system to dispense dry goods comprising: a receptacle for the dry goods; a spout for dispensing the dry goods via gravity flow from said receptacle; a valve between the receptacle and the spout controlling flow of said dry goods from said receptacle; an actuator driving said valve between open and closed states; a controller configured to command said actuator to open and close said valve according to a program; an activator for said controller; and an adjustment interface for adjusting said program, wherein said adjustment interface includes an interface configured for inputting characteristics of the dry goods and an algorithm for deciding on a program for dispersing the dry goods, and wherein said interface is configured for inputting characteristics includes a camera for taking an image of the dry goods."]},{"claim_text":["2. The system of claim 1 , wherein said flow is a free flow valve."]},{"claim_text":["3. The system of claim 1 , where said activator is a sanitary activator."]},{"claim_text":["4. The system of claim 1 , wherein said adjustment interface includes a wireless receiver."]},{"claim_text":["5. The system of claim 1 , wherein said adjustment interface includes an application running on a personal computing device."]},{"claim_text":["6. The system of claim 1 , wherein said adjustment interface includes a manual regulator to adjust a maximum opening position."]},{"claim_text":["7. The system of claim 1 , wherein said adjustment interface includes a manual regulator to adjust an oscillation rate between a maximum open position and a minimum opening position."]},{"claim_text":["8. The system of claim 1 , wherein said adjustment interface includes a manual regulator to adjust an open time."]},{"claim_text":["9. The system of claim 1 , wherein said interface includes an image processing component for determining a shape and size of said dry goods from said image."]},{"claim_text":["10. The system of claim 1 , wherein said receptacle includes a fiducial marker."]},{"claim_text":["11. The system of claim 1 , further comprising a manual lever for activating dispensing manually."]},{"claim_text":["12. The system of claim 1 , further including an optical reader for reading a code specifying said program."]}],"lang":"en"}],"description":{"text":"RELATED APPLICATION/S This application claims the benefit of priority under 35 USC § 119(e) of U.S. Provisional Patent Application No. 63/122,498 filed 8 Dec. 2020, the contents of which are incorporated herein by reference in their entirety. FIELD AND BACKGROUND OF THE INVENTION The present invention, in some embodiments thereof, relates to an automatic dry goods dispenser and, more particularly, but not exclusively, to a dispenser that dispenses dry goods cleanly, without crushing the product and/or without hand contact. U.S. Pat. No. 9,549,640 to the current inventor appears to disclose, “A dry food dispensing device for controlling the portion size of the dispensed food, comprising a storage receptacle for containing dry foods, wherein the receptacle is seated over a base providing a housing for a dispensing mechanism, the dispensing mechanism comprising: a turnable free flow valve having wings, capable of rotation to an opening angle defined by a position limiter; anda depressible handle for controlling the free flow valve via the position limiter,wherein the dispensing mechanism releases a portion of the dry food, with the portion being determined by a user as a function of time the turnable free flow valve is held at the opening angle.” European Patent Application Publication no. EP2294948 appears to disclose, “A dispensing actuator locking assembly for a bulk inventory dispenser. The dispenser includes a housing, a lockable dispensing actuator pivotally connected to the housing, and a gate connected to the dispensing actuator and adapted to pivot between a closed position and an open position to selectively dispense the bulk product through an opening in the housing when the dispensing actuator is in an unlocked condition. The dispensing actuator cannot be accidentally actuated unless and until the locking assembly is purposefully disengaged by the user of the dispenser.” US Patent Application Publication no. US20080190964 appears to disclose, “A device is provided for holding dispensing and conveying substances such as dry foods such as, for example, flour, breakfast cereal or granola. The device may include a stand holding a possibly hermetically sealed container which may include a conveyor, having a flexible paddle belt mounted on at least two axles and possibly at least one connector. The conveyor is connected to a handle which when rotated may cause the conveyor to rotate and dispense the dry substances such as food from the container into, for example, an outside bowl.” U.S. Pat. No. 5,947,336 appears to disclose, “A dry food dispenser having a cylindrical container with a removable top or cap for covering a central storage area holding dry baby formula or other dry food commodity. The mid-section of the container includes a tapered funnel terminating in an opening. A rotatable cylinder is operably carried on the funnel having a pre-measured receptacle or cavity co-extensive with the funnel opening for collecting a quantity of the dry food product. Upon rotation of the cylinder, the receptacle carries the product from the funnel for external dispensing into a utility container for usage. A second pre-measured receptacle or cavity may be provided in the cylinder and a releasable retainer interconnects the container with the cylinder for holding the cylinder in a fixed position.” U.S. Pat. No. 5,230,300 appears to disclose, “An automatic dry food feeder for animals is described. The feeder consists of a housing with a hopper fitted in the housing having sloping members terminating in a rectangular section at the bottom of the hopper. An electric motor having a gearbox attached thereto is located outside the rectangular portion of the hopper. The gearbox shaft extends into the rectangular portion with a sleeve fitted over the shaft. Attached to the sleeve are segmented flexible vanes that rotate in accordance with the signal provided by an electronic programmable controller. Rotating the segmented flexible vanes a prescribed amount in response to a programmed timer dispenses a measured amount of dry animal food into a tray.” SUMMARY OF THE INVENTION According to an aspect of some embodiments of the invention, there is provided a system to dispense dry goods including: a receptacle for the dry goods; a spout for dispensing the dry goods via gravity flow from the receptacle; a valve between the receptacle and the spout controlling flow of the dry goods from the receptacle; an actuator driving the valve between open and closed states; a controller configured to command the actuator to open and close the valve according to a program; and an activator for the controller. According to some embodiments of the invention, the flow is a free flow valve. According to some embodiments of the invention, the system where the activator is a sanitary activator. According to some embodiments of the invention, the system further includes: an adjustment interface for adjusting the program. According to some embodiments of the invention, the adjustment interface includes a wireless receiver. According to some embodiments of the invention, the adjustment interface includes an application running on a personal computing device. According to some embodiments of the invention, the adjustment interface includes a manual regulator to adjust a maximum opening position. According to some embodiments of the invention, the adjustment interface includes a manual regulator to adjust an oscillation rate between a maximum open position and a minimum opening position. According to some embodiments of the invention, the adjustment interface includes a manual regulator to adjust an open time. According to some embodiments of the invention, the adjustment interface includes an interface configured for inputting characteristics of the dry goods and an algorithm for deciding on a program for dispersing the dry goods. According to some embodiments of the invention, the interface is configured for inputting characteristics includes a camera for taking an image of the dry goods. According to some embodiments of the invention, the interface includes an image processing component for determining a shape and size of the dry goods from the image. According to some embodiments of the invention, the receptacle includes a fiducial marker. According to some embodiments of the invention, the system further includes a manual lever for activating dispensing manually. According to some embodiments of the invention, the system further includes an optical reader for reading a code specifying the program. According to an aspect of some embodiments of the invention, there is provided a method for dispensing thy goods including: supplying an automatic dry goods dispenser with a receptacle for the dry goods, a sanitary activator, a spout through which the dry goods pass, a valve between the receptacle and the spout and a motor responsive to the activator and driving the valve; placing a container under the spout; activating the motor via the sanitary activator; and driving the valve with the motor to facilitate passing of the dry goods through the spout into the container. According to some embodiments of the invention, the driving includes oscillating the valve between an open and closed position. According to some embodiments of the invention, the method further includes adjusting a rate of the oscillating to avoid crushing the dry goods. According to some embodiments of the invention, the driving is according a program and further including reading the program from a visual code. According to some embodiments of the invention, the driving is according a program and wherein the program is configured to dispense a predefined quantity of the dry goods. BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWING(S) Some embodiments of the invention are herein described, by way of example only, with reference to the accompanying drawings. With specific reference now to the drawings in detail, it is stressed that the particulars shown are by way of example and for purposes of illustrative discussion of embodiments of the invention. In this regard, the description taken with the drawings makes apparent to those skilled in the art how embodiments of the invention may be practiced. In the drawings: FIGS. 1A, 1B and 2 illustrated a valve of a previous art dry goods dispenser from US Patent FIG. U.S. Pat. No. 9,549,640 to the current inventor; FIG. 3 illustrates a cutaway view of a front of a dry goods dispenser in accordance with an embodiment of the current invention; FIG. 4 is an exploded perspective view of a dry goods dispenser in accordance with an embodiment of the current invention; FIG. 5 is a perspective view illustration of a dry goods dispenser in accordance with an embodiment of the current invention; FIG. 6 is a schematic perspective view illustration of a dispenser with an optional manual actuator in accordance with an embodiment of the current invention; FIG. 7 is a block diagram of a dispenser in accordance with an embodiment of the current invention; FIG. 8 is a flow chart illustration of a method of dispensing in accordance with an embodiment of current invention; FIGS. 9A and 9B are flow chart illustrations of a method of adjusting a dispenser in accordance with an embodiment of the current invention; FIG. 10 illustrates use of a dispenser in accordance with an embodiment of the current invention; FIG. 11 illustrates dispensing in accordance with an embodiment of the current invention; FIG. 12A illustrates front view of a dispenser in accordance with an embodiment of the current invention; FIG. 12B illustrates front view of a dispenser with an open front cover in accordance with an embodiment of the current invention; FIG. 13 illustrates front view of a dispenser in accordance with an embodiment of the current invention; FIG. 14 is a schematic rear view of a dispenser with a rear cover removed in accordance with an embodiment of the current invention; FIG. 15 is a schematic rear view of a dispenser with a rear cover, rear portion of the casing and battery removed in accordance with an embodiment of the current invention; FIG. 16 illustrates a dispenser having a large receptacle in accordance with an embodiment of the current invention; and FIG. 17 illustrates a front perspective view of a dispenser having a large receptacle in accordance with an embodiment of the current invention. Unless otherwise defined, all technical and/or scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which the invention pertains. Although methods and materials similar or equivalent to those described herein can be used in the practice or testing of embodiments of the invention, exemplary methods and/or materials are described below. In case of conflict, the patent specification, including definitions, will control. In addition, the materials, methods, and examples are illustrative only and are not intended to be necessarily limiting. As will be appreciated by one skilled in the art, some embodiments of the present invention may be embodied as a system, method or computer program product. Accordingly, some embodiments of the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a “circuit,” “module” or “system.” Furthermore, some embodiments of the present invention may take the form of a computer program product embodied in one or more computer readable medium(s) having computer readable program code embodied thereon. Implementation of the method and/or system of some embodiments of the invention can involve performing and/or completing selected tasks manually, automatically, or a combination thereof. Moreover, according to actual instrumentation and equipment of some embodiments of the method and/or system of the invention, several selected tasks could be implemented by hardware, by software or by firmware and/or by a combination thereof, e.g., using an operating system. For example, hardware for performing selected tasks according to some embodiments of the invention could be implemented as a chip or a circuit. As software, selected tasks according to some embodiments of the invention could be implemented as a plurality of software instructions being executed by a computer using any suitable operating system. In an exemplary embodiment of the invention, one or more tasks according to some exemplary embodiments of method and/or system as described herein are performed by a data processor, such as a computing platform for executing a plurality of instructions. Optionally, the data processor includes a volatile memory for storing instructions and/or data and/or a non-volatile storage, for example, a magnetic hard-disk and/or removable media, for storing instructions and/or data. Optionally, a network connection is provided as well. A display and/or a user input device such as a keyboard or mouse are optionally provided as well. Any combination of one or more computer readable medium(s) may be utilized for some embodiments of the invention. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device, or any suitable combination of the foregoing. More specific examples (a non-exhaustive list) of the computer readable storage medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a computer readable storage medium may be any tangible medium that can contain, or store a program for use by or in connection with an instruction execution system, apparatus, or device. A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein, for example, in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms, including, but not limited to, electro-magnetic, optical, or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate, propagate, or transport a program for use by or in connection with an instruction execution system, apparatus, or device. Program code embodied on a computer readable medium and/or data used thereby may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, RF, etc., or any suitable combination of the foregoing. Computer program code for carrying out operations for some embodiments of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as Java, Smalltalk, C++ or the like and conventional procedural programming languages, such as the “C” programming language or similar programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) and/or a mesh network (meshnet, emesh) and/or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider). Some embodiments of the present invention may be described below with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems) and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks. These computer program instructions may also be stored in a computer readable medium that can direct a computer, other programmable data processing apparatus, or other devices to function in a particular manner, such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function/act specified in the flowchart and/or block diagram block or blocks. The computer program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other devices to cause a series of operational steps to be performed on the computer, other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks. Some of the methods described herein are generally designed only for use by a computer, and may not be feasible or practical for performing purely manually, by a human expert. A human expert who wanted to manually perform similar tasks might be expected to use completely different methods, e.g., making use of expert knowledge and/or the pattern recognition capabilities of the human brain, which would be vastly more efficient than manually going through the steps of the methods described herein. Data and/or program code may be accessed and/or shared over a network, for example the Internet. For example, data may be shared and/or accessed using a social network. A processor may include remote processing capabilities for example available over a network (e.g., the Internet). For example, resources may be accessed via cloud computing. The term “cloud computing” refers to the use of computational resources that are available remotely over a public network, such as the internet, and that may be provided for example at a low cost and/or on an hourly basis. Any virtual or physical computer that is in electronic communication with such a public network could potentially be available as a computational resource. To provide computational resources via the cloud network on a secure basis, computers that access the cloud network may employ standard security encryption protocols such as SSL and PUP, which are well known in the industry. DESCRIPTION OF SPECIFIC EMBODIMENTS OF THE INVENTION The present invention, in some embodiments thereof, relates to an automatic dry goods dispenser and, more particularly, but not exclusively, to a dispenser that dispenses dry goods cleanly, without crushing the product and/or without hand contact. For purposes of better understanding some embodiments of the present invention, as illustrated in FIGS. 3 to 11 of the drawings, reference is first made to the construction and operation of a valve of a manual dry goods dispenser as illustrated in FIGS. 1A, 1B and 2 . FIGS. 1A, 1B and 2 illustrated a valve of a previous art dry goods dispenser from US Patent FIG. U.S. Pat. No. 9,549,640 to the current inventor, 1 A shows valve 114 in a leveled position, having wings 116 a - b blocking the stored food from exiting dispenser 200 . FIG. 1B shows valve 114 tilted counter-clockwise, such that wings 116 a - b are no longer blocking the food, and as shown by arrow A, the food is now allowed to bypass valve 114 in order to flow through dispensing aperture 112 , to the user. The overall product design for the inventive dispenser can be such that a simply constructed, easy-to-use dispenser is provided, featuring an adjustable valve 114 opening angle, to accommodate different types of dry food, whether they be in fine or coarse granular form, flakes or chunky-type food pieces, including toppings, powders and the like. Referring now to FIG. 2 , there is shown a perspective exploded view of free-flow dispenser 200 , showing optional components. Depressible handle 130 and valve 114 are connected via handle actuator 150 having a square shaft 128 inserted into each of its components (described below). Each of the ends of shaft 128 are inserted into one of handle 130 or valve 114 , so that when depressing handle 130 , valve 114 turns. Valve 114 has two identical rounded wings 116 a - b disposed on each side of valve 114 in the same plane, such that they fit into the internal circumference of base 110 , and when maintained at a level position, they block the exit of the stored dry food. Valve 114 has a third wing 118 which is slightly longer than wings 116 a - b , and is disposed beneath wing 116 b at an angle, for the purpose of blocking any food from leaking out of aperture 112 and maintaining the freshness of the stored dry food. When handle 130 is depressed, valve 114 rotates counter-clockwise to an opening angle, thereby allowing food to pass through base 110 and out of dispenser 200 through aperture 112 . For determining the maximum opening angle that valve 114 will be allowed to turn, there is provided as part of handle actuator 150 , position limiting means in the form of a rotatable handle-position stop 126 having a circumferential shoulder 127 which fits into a fixed handle-position stop 124 having an internal truncated rim 125 . Rotatable stop 126 rotates counter-clockwise along with handle 130 when it is depressed, inside of fixed handle-position stop 124 along its internal truncated rim 125 . When circumferential shoulder 127 hits the edge of truncated rim 125 , stop 126 cannot rotate anymore, and handle 130 cannot continue to be depressed further. Rotatable handle-position stop 126 may be designed with a variation in the length of circumferential shoulder 127 , in order to determine the maximum opening angle to which valve 114 can rotate. For example, if shoulder 127 is longer, then handle position stop 126 can rotate less before it hits the edge of truncated rim 125 , thereby reducing the opening angle to which handle 130 can become depressed. Alternatively, with a shorter shoulder 127 , more rotation of handle position stop 126 is possible. On the reverse side of fixed handle position stop 124 , there is attached spring 122 which is connected to a spring base 120 having a flat portion 121 which fits, from behind, into the center of fixed handle position stop 124 , and the center of rotatable handle position stop 126 . Spring base 120 is positioned within base socket 119 that is embedded in base 110 . When handle 130 is released after being depressed, spring 122 twists handle actuator 150 clockwise back to its original position, thereby rotating valve 114 back to its original position and blocking the exit of the stored food. Overview An aspect of some embodiments of the current invention relates to an automatic dry goods dispenser. In some embodiments a manual dispenser may be upgraded for automatic and/or sanitary dispensing (e.g., avoiding touching the dispenser with the hands). For example, a motor may be mounted to the dispenser. The motor optionally opens and/or closes a valve for dispensing the goods. Optionally, the opening and/or closing is adjustable to function efficiently for different types of dry goods (for example having different densities and/or shapes). For example, the opening and closing may be adjusted to achieve a desired flow rate and/or dispensing volume. In some embodiments, the dispenser is designed to avoid grinding and/or damaging the goods. In some embodiments, the device in designed to achieved controlled flow and/or avoid spilling of goods. For example, the valve and/or actuator may be designed to avoid dispensing and/or leaking of goods when there is no container to receive the goods. For example, the device may include a valve biased to a closed configuration and/or a motor that opens the valve for a fixed time and/or that opens the valve for as long as a switch remains in an activated position and/or oscillates the valve between a maximum and minimum opening for as long as the switch is activated and/or oscillates the valve between a maximum and minimum opening for a fixed time and then closes the valve each time switch is activated. Optionally, a manual operation option is available. In some embodiments, the opening and/or closing may be preprogrammed. Optionally, a user will purchase goods and/or a program will be transferred to the dispenser according to his purchase. For example, according to the amount that was purchased, upon pushing the actuator, the valve will be opened and/or oscillated in a way to dispense the purchased quantity of goods and/or will then close. In some embodiments, pushing the actuator switch may trigger the preprogrammed opening and closing program which will then continue till its finish regardless of activity of the switch. Alternatively or additionally, pushing the actuator switch may trigger the preprogrammed opening and closing, releasing the switch may interrupt the opening and closing (e.g., by closing the valve) and/or pushing the switch again may trigger continuation of the program. Optionally, the program may be interrupted and/or resumed multiple times until the programs finishes and/or until a new program is entered into a controller of the dispenser. For example, when a customer pays for a certain quantity of product he may receive a receipt with a visual code (e.g., a barcode and/or a QR code). The dispenser optionally includes a code reader (e.g., a camera and/or software) that reads the quantity to dispense from the codes. The controller is optionally preprogrammed to open and/or close the valve is a way that will dispense the proper quantity. In some embodiments, dry goods may have various physical characteristics causing them to flow and/or jam and/or crush under various conditions. A dispenser for dry goods may include features to foster clean controlled flow without damaging the goods. Optionally, the device may be configured and/or adjusted to foster a desired flow for a particular product. For example, a dispenser for cornflakes may be adjusted to encourage flow and/or avoid jamming while avoiding grinding the fragile flakes. For example, a container for dispensing lentils may be adjusted to limit flow and/or achieve a reliable slow flow. For example, using the setting of cornflakes with lentils may result in an uncontrolled flood of lentils and/or lots of spilled material. For example, using the setting for lentils with cornflakes may result in uneven and/or blocked flow and/or grinding and/or ruining the flakes. In some embodiments, a dispenser is supplied with a hygienic actuator. For example, the actuator may be designed to activate dispensing without hand contact. Alternatively or additionally, the actuator may be designed to avoid mis-dispensing of the product. For example, the actuator may include a lever that is activated by pushing with a container under the spout of the dispenser. Alternatively or additionally, a sensor (for example a light source and/or a light sensor) may prevent activation when there is no container and/or may activate the valve when there is a container. In some embodiments, an electric motor drives a free flow valve of a dry goods dispenser. For the sake of the current disclosure, a free flow valve is a valve that when open allows flow (e.g., gravity flow). For example, various aspects of the opening of the valve may be adjustable. For example, the maximum opening and/or the time of opening. In some embodiments the valve may oscillate between a maximum open state in which the value may be fully and/or partially opened and/or a minimal opened state wherein the valve may be fully and/or partially closed and/or less open than the maximum open state. Optionally, the rate of oscillation, the size and/or angle of the maximum opened position and/or the size and/or angle of the closed portion of the oscillation cycle may be adjustable. Exemplary Embodiments Before explaining at least one embodiment of the invention in detail, it is to be understood that the invention is not necessarily limited in its application to the details of construction and the arrangement of the components and/or methods set forth in the following description and/or illustrated in the drawings and/or the Examples. The invention is capable of other embodiments or of being practiced or carried out in various ways. Referring now to the drawings, FIG. 3 illustrates a cut away view of a dry goods dispenser in accordance with an embodiment of the current invention. In some embodiments, a motor drives a shaft to open and/or close a valve releasing city goods from a receptacle. Optionally, a controller (for example a microprocessor mounted on a printed circuit board (PCB)) determines a mode and/or cycle of motor actuation. For example, an actuator handle may activate the controller to command to the motor to open and/or close the valve according to a preset cycle and/or mode. According to the opening and/or closing of the valve, goods from the receptacle are dispensed out a spout (for example under gravitational flow). Optionally, the dispenser is connected to an electricity power grid and/or runs off of alternating current. Alternatively or additionally, the dispenser may run from a DC power source e.g., a battery and/or a solar cell etc.). In some embodiments, a manual thy goods dispenser (for example as pictured in FIGS. 1-3 ) may be retrofit for automatic and/or touch free operation. For example, the system may include one or more of a motor 344 , controller 348 , transmission 346 and/or hands-free actuator switch 352 the motor 344 and transmission 346 may be installed onto a manual dry goods dispenser. Alternatively, a dry goods dispenser may be built originally for automatic operation with a receptacle 342 , free flow valve (e.g., as described in FIGS. 1 to 3 ) a motor 344 , a transmission 346 and/or a controller 348 . Referring now to FIG. 3 , in some embodiments, the motor 344 , for example, an AC motor, a brushless motor and/or a DC motor. For example, the motor 344 may turn a transmission 346 that turns a shaft 328 that opens and/or closes a valve. Alternatively or additionally, the valve may include a linear actuator and/or a brushless motor and/or another sort of actuator that opens and closes the valve in response to commands of the controller 348 . Optionally, the valve is biased closed (e.g., such that if there is a system failure and/or power failure, the valve will default to a closed state). For example, there may be a mechanical biasing element (for example an elastic element such as a spring (e.g., spring 122 as illustrated in FIG. that biases the valve to the closed configuration. In some embodiments, an actuator switch 352 is designed for sanitary use. Optionally, a user may activate dispensing of the goods without touching a shared surface (e.g., a handle and/or an activation button). For example, an actuator switch 352 may be designed to activate dispensing when a container is pushed into position under a dispensing spout 312 . Alternatively or additionally, dispensing may be activated when an actuator 352 switch is pushed by a wall of the vessel. Alternatively or additionally, a sensor (such as a light detector and/or light source) may be used to detect the presence of a container under the spout 312 . Additionally or alternatively, a digital communication system may give instructions to unlock dispensing and/or determine how much and/or how fast dispensing should occur. For example, a user may have an application on a personal computing device (e.g., his cell phone and/or a digital self-checkout scanner) to instruct the controller of a dispenser to dispense a predetermined amount of goods into a container when the container is placed under the spout. Alternatively or additionally, a dispenser may include a reader (such as a bar code reader and/or a QR code scanner and/or a magnetic strip reader) such to receive digital instructions. Alternatively or additionally, a dispenser may include a identity detector (for example receiving a signal from a personal computing device of a user and/or an RF tag) and/or estimate the quantity of goods taken by user and/or bill the user (for example, by charging a credit card and/or charging an account and/or adding a charge to a self-check out system). Alternatively or additionally, the dispenser may include a printer and/or a screen for displaying a barcode that can be attached to the container and/or read by a self-checkout device. In some embodiments, the dispenser may be designed for first in, first out operation. For example, goods are added to the top of the receptacle 342 and/or removed through a spout (e.g., by gravity flow) from the bottom of the receptacle 342 . FIG. 4 is an exploded perspective view of a dry goods dispenser in accordance with an embodiment of the current invention. For example, a flap of valve 416 may be mounted along its axis 460 and/or on a shaft. Turning the shall may rotate the flaps of valve 416 around its axis. For example, rotating the flaps of valve 416 may open and/or close a passage between a receptacle 342 for goods and a dispensing spout 312 . A controller 348 may include a processor, memory, software and/or a user interface (for example, an operating and/or signaling light 454 ). For example, the processor may signal a motor 344 to open the valve 416 , close the valve 416 and/or oscillate the valve 416 back and forth between maximally open positions (e.g., fully open or partially open) and/or a minimally open position (fully or partially, closed position) and/or a closed position. In some embodiments, the system has a cover 458 and/or a front plate 462 . For example, the front plate 462 may be removed and a manual handle installed for manual operation. FIG. 5 is a perspective view illustration of a dry goods dispenser in accordance with an embodiment of the current invention. In some embodiments, a dispenser may include a sensor. For example, a light source 570 and/or light sensor 572 may be used to determine if there is a vessel under the spout 312 of the dispenser. For example, when light travels uninterrupted between the light source 570 and the sensor 572 the device may be inhibited from dispensing. Optionally, this will prevent spillage of food, for example when kids play with the actuator switch 352 and/or if the actuator switch 352 gets jammed in the activated position. Alternatively or additionally, the system may only dispense goods after receiving instructions and/or confirmation of payment. For example, the dispenser may limit dispensing to a quantity specified in the instructions. For example, the instructions may be communicated over a wireless channel and/or a network. In some embodiments a dispenser may include an adjustment interface. For example, there may be adjusting screws 568 . For example, a screw 568 may be turned one way to increase that maximum opening of the valve and/or another direction to decrease the maximum opening during oscillation of the valve. In some embodiments, the adjustments may be implemented mechanically. For example, the size of the valve opening may be limited by a valve stop (e.g., there may be stop ring 126 and shoulder 127 and truncated rim 125 for example as described in FIG. 2 and/or screws 568 may move a physical valve stop similar to truncated rim 125 allowing the valve to open larger or smaller). Alternatively or additionally, the user interface may change performance of the electric actuator. For example, screws 568 may change a potentiometer and/or an adjustable resistor that may control power to the motor 344 . Alternatively or additionally, the interface may be connected to the controller (e.g., controller 348 ). For example, turning a screw 568 may indicate to the controller 348 to change the program of the motor 344 . Additionally or alternatively, another screw 568 may adjust a rate of oscillation of a valve 416 between a minimum opening and a maximum opening. Additionally or alternatively, another screw 568 may be turned one way to increase that maximum opening of the valve 416 and/or another direction to decrease the maximum opening. Additionally or alternatively, another screw 568 may be supplied to adjust a time before the valve 416 closes after activation. Alternatively or additionally, a valve 416 may stay open and/or continue to oscillate as long as a user holds the actuator switch 352 activated. Alternatively or additionally, a user interface may facilitate a user defining an amount of product desired and/or the amount time that the valve remains in the open and/or oscillating state may be adjusted according to a quantity of product requested. In some embodiments, the adjustments of the dispenser may be made by a technician based on the goods to be dispensed. In some embodiments, the dispensing may be adjusted automatically. For example, an app may be run on a personal computing device of an operator (e.g., an operator may include a vendor and/or store owner who supplies the machine for use by customers who are users of the dispenser) and/or a technician. Optionally, the app requests details about the product being sold. For example, the app may receive as input the shape of the product (e.g., spheres, jagged shaped, smooth, flakes, cylinders) and/or the density (for example the operator may give a measured density and/or report how much of the receptacle is filled with a specific mass of goods (e.g., 5 kg half fills the receptacle 342 )). Alternatively or additionally, an operator may fill the receptacle 342 with a specified mass of product and take a picture of the receptacle 342 . The receptacle optionally includes a window and/or is transparent and/or includes fiducial marker 566 . For example, an image processing program and/or an artificial intelligence routine based on the image determines the size and shape and density of the goods and/or an appropriate adjustment for the opening program of the valve 416 . For example, for a larger and/or more jagged and/or more non-uniform and/or less dense goods the valve 416 may open larger. For thinner goods, the valve 416 may oscillate more slows (e.g., to reduce grinding). Optionally, the system will facilitate corrective adjustment. For example, an operator may specify in an app that the goods are exiting too fast and/or too slow. For example, when the dispensing is too fast system may automatically reduce the flow rate, for example by reducing the maximum and/or minimum valve opening. For example, an operator may specify in an app that the goods are getting ground up and/or the system will automatically reduce the grinding effect, for example by reducing the oscillation rate. For example, an operator may specify in an app that too much of goods are dispensed. Optionally the system will automatically reduce the quantity dispensed, for example by decreasing the amount of time that the valve 416 is held open and/or oscillating. FIG. 6 is a schematic perspective view illustration of a dispenser with an optional manual actuator 674 in accordance with an embodiment of the current invention. In some embodiments, an automatic dispenser includes a manual operation option. For example, a face plate (e.g., face plate 462 illustrated in FIG. 5 ) may be removed from the device and/or a manual actuator 674 may be attached to the dispenser. For example, the manual actuator 674 may be attached to a valve shaft (e.g., shaft 128 as illustrated in FIG. 2 ) and/or the manual actuator 674 may be turned to open a valve. The manual actuator 674 may allow the system to be used where there is no electrical power and/or when there is a malfunction and/or a power outage. Alternatively or additionally, the manual activator 674 may facilitate emptying and/or cleaning the dispenser when and/or where there is no electricity. For example, a face plate of the dispenser may be removed and/or a manual handle 674 connected to a shaft of a valve and/or the handle may be turned to open the valve. FIG. 7 is a block diagram of a dispenser in accordance with an embodiment of the current invention. For example, an activator switch 752 may connect to a spout 712 such that a dispensing of goods (e.g., freely and/or according to a program) may be activated when a receptacle 742 is placed under the spout 712 . For example, dispensing may be activated by a motor 744 . The motor 744 optionally opens a valve 716 that intervenes between a receptacle 742 (e.g., containing dry goods to be dispensed) and the spout 712 . Alternatively or additionally, the motor 744 may cause the valve to oscillate, for example, between a maximum opening and a minimum opening (the maximum and/or minimum opening may be fully open, fully closed and/or partially open). In some embodiments, the opening and/or closing of the valve 716 is controlled by a controller 748 . For example, the controller 748 may include a user interface 768 . For example, the user interface 768 may include a physical interface (e.g., a knob and/or a button and/or a switch) Alternatively or additionally the user interface 768 may include a wireless communication interface (for example facilitating control of the dispenser via an app on a personal computing device). Alternatively or additionally, the user interface may 768 include an optical reader and/or magnetic reader (for example a bar code reader, a QR reader, a RF tag reader, a magnetic strip reader). Alternatively or additionally, the user interface 768 may include a network interface. For example, the device may be controlled remotely and/or adjusted remotely (e.g., by a remote technician and/or dispensing may be dependent on approval by a credit authority). Alternatively or additionally, the user interface 768 may include a digital interface such as a keyboard, a touch screen, a view screen etc. Optionally, the dispenser is integrated into a self check out system (for example, reporting a quantity, type and/or cost of a dispensed product to a billing system and/or printing a code identifying goods and/or displaying a code identifying goods to a check out scanner and dispensing goods according to a prepaid quantity). FIG. 8 is a flow chart illustration of a method of dispensing in accordance with an embodiment of current invention. In some embodiments the dispenser is activated 842 to dispense goods. For example, activation 842 may include pushing a physical activation switch (for example by means of pushing a container under a dispensing spout). For example, a valve may open 816 (e.g., in a static and/or oscillating 844 position) as long as the switch is activated. Alternatively or additionally, pushing the switch once may cause a programmed and/or timed opening 816 , closing 817 and/or oscillation 844 of the valve. Alternatively or additionally, activation 842 may include giving more complex instructions and/or may be dependent on sensors and/or may be dependent on approval of a payment system. Optionally when the activation 842 stops and/or when the programmed dispensing is finished, the valve is closed 817 until the next activation. In some embodiments, the dispenser is integrated into an automatic checkout system. For example, the dispenser may dispense according to instructions received from the checkout system and/or approval for dispensing for the system. Alternatively or additionally, the dispenser may report what was dispensed and/or produce labels to be read by the checkout system. For example, the system may receive instructions (e.g., over a network from an automatic checkout system and/or via a signal from a user's computing device and/or from reading a code (e.g., a bar code and/or a QR code)) to dispense a preselected quantity of goods. Optionally, until the preselected quantity has been dispensed, the system will release goods (e.g., by opening 816 and oscillating 844 a valve) in response to a user activating 842 a switch. Once the predetermined quantity has been dispensed, the valve is optionally closed 817 until new instructions are received. In some embodiments a valve may oscillate 844 between a maximum opening and minimum opening. For example, the maximum opening may range between 90 to 100% and/or between 70 to 90% and/or between 50 to 70% and/or between 30 to 50% of fully open. For example, the minimum opening may range between 90 to 100% and/or between 70 to 90% and/or between 50 to 70% and/or between 30 to 50% of fully closed. For example, the oscillation 844 rate may range between 1 to 10 oscillations a minute and/or between 10 to 30 oscillations a minute and/or between 30 to 100 oscillations a minute and/or between 100 to 1000 oscillations a minute. For example, the maximum opening may range between 1 to 5 square cm and/or between 5 to 20 square cm. Optionally a valve gate (e.g., wings 116 a , 116 b ) may be of soft material, for example, silicon and/or elastomer. FIGS. 9A and 9B are flow chart illustrations of a method of adjusting a dispenser in accordance with an embodiment of the current invention. For example, an operator of the dispenser may select 876 what contents will be dispensed. He may input 877 the contents of the device, for example by informing a technician and/or an automatic adjustment app what are the contents. For example, the system may have preset settings for common products (e.g., rice, cornflakes, oatmeal, raw popcorn, cooked popcorn, chips, beans, lentils, pasta, cereal etc.) and/or the operator may input the kind of product and/or a set of preliminary adjustments are selected automatically. Alternatively or additionally, the user may input 877 characteristics of the goods (e.g., size, density, hardness, shape etc.). For example, the user may input characteristics such as density, shape, size etc. manually (e.g., as described above) and/or via a measuring routine (e.g., as described above, an optical routine that estimates the properties from an image). Optionally, the machine is used to dispense 812 the product. While in use, the performance may be evaluated. For example, if the dispenser is correctly 813 (dispenses the proper amount of product in good condition) then dispensing is allowed to continue. Alternatively or additionally, if dispensing is not correct 813 then the dispenser may be readjusted 868 (e.g., as described herein above and/or corrections when the dispensing is not as desired. Optionally, a technician may adjust 868 the dispenser before it is deployed. Alternatively, or additionally, the technician may adjust 868 the dispenser after it is deployed (e.g., by the technician coming to service the device in situ and/or remotely for example programming a controller of the dispenser over a network connection). Alternatively, or additionally an operator of the dispenser may, adjust 686 the dispenser, for example using an application on a computing device and/or via images of the goods etc. for example as described above. Either before or after the dispenser is adjusted 868 is may be filled 843 with the product and/or used to dispense 812 the product. FIG. 10 illustrates use of a dispenser in accordance with an embodiment of the current invention, Optionally, instructions may be conveyed to and/or received 1068 by the device. For example, a user may make a payment and/or get approval for dispensing and/or the approval may be for a particular quantity of product. For example, the instructions may be conveyed by an automatic check out machine over a network and/or the user may receive a token (for example, a physical object with a bar code and/or QR code printed thereon which is read by the dispenser and/or a code on a personal computing device that may be read by the dispenser (e.g., as a barcode and/or QR code on a screen of the device and/or via a wireless connection e.g., Bluetooth)). For example, instructions may be received 1068 from a personal computing device of a user and/or over a wireless communication. For example, instructions may be received over a local user interface. For example, instructions and/or approval may be received 1068 from a network and/or from a credit authority and/or from an automatic checkout system. Optionally, after instructions are received 1068 , a user may activate 1069 the dispenser to dispense 1012 according to the instructions (for example, by putting a vessel under the spout of the dispenser and/or pushing an activator switch). FIG. 11 illustrates dispensing in accordance with an embodiment of the current invention. For example, a user may activate a dispenser to dispense 1112 a quantity of product. Optionally, the dispenser may report 1178 details of the dispensing 1112 . For example, reporting may to a personal computing device of a user and/or over a wireless communication and/or by printing a code (e.g., a barcode and/or a QR code). For example, the details may be sent to automated checkout station and/or read by an automatic checkout station. For example, reporting 1178 may be to a network and/or to a credit authority and/or to an automatic checkout system. FIGS. 12A and 12B illustrate front views of a dispenser in accordance with an embodiment of the current invention. Optionally, a dispenser includes a motor 1244 connected to a valve to actuate a valve. Optionally, the motor 1244 and/or valve are inside a housing 1256 . Optionally, the housing 1256 includes a receptacle adapter 1213 configured for holding a receptacle of dry goods for dispensing. For example, the adapter 1213 may be used with a large receptacle (e.g., for user in a retail establishment selling bulk dry goods) and/or a smaller receptacle (e.g., for use in a food service establishment such as a restaurant and/or salad bar). Optionally, opposite the receptacle adapter 1213 (with the valve therebetween) housing 1256 includes a dispensing spout 1212 . Optionally, an activator 1252 facilitates activating dispensing when a user puts a vessel under the spout 1212 . Optionally, activator 1252 may include a lever. Alternatively, or additionally activator 1252 may include a sensor (e.g., a light sensor that senses when a vessel is placed under spout 1212 ). In some embodiments a front cover 1262 covers and/or allows access to the internal parts of the dispenser and/or can be removed to allow access to the internal parts and/or to activate the dispenser manually. Optionally, the dispenser may include an indicator. For example, an indicator light 1254 may glow and/or blink and/or change colors to various functions or states of the dispenser, for example, ready, finished, locked, fault, FIG. 13 illustrates front view of a dispenser in accordance with an embodiment of the current invention. In some embodiments, there may be a rear cover 1263 . For example, rear cover 1263 may cover and/or allow access to electronic components of the dispenser. Optionally, the dispenser includes a power input jack 1284 and/or an on-off switch 1282 . FIG. 14 is a schematic rear view of a dispenser with a rear cover removed in accordance with an embodiment of the current invention. In some embodiments, under the dispenser includes adjustment controls 1292 a and 1292 b . For example, a control 1292 a may include a toggle button for switching modes of a valve (for example, between static opening, rotation and/or oscillation) and/or a control 1292 b (e.g., a toggle button) for determining a maximum and/or minimum opening value for a valve. Alternatively or additionally controls could include a switch and/or a dial. Alternatively or additionally, adjustments may be made using a remote device, for example, over a wireless connection (e.g., Bluetooth) and/or over a network connection. In some embodiments, the dispenser will include a battery 1294 . For example, the battery 1294 may be used to hold a valve in a closed when there is a power outage. Optionally, the controls 1292 a 1292 b may be covered, for example, by rear cover 1263 . FIG. 15 is a schematic rear view of a dispenser with a rear cover, rear portion of the casing and battery removed in accordance with an embodiment of the current invention. In some embodiments, a dispenser includes a controller 1248 . For example, the controller 1248 may be embodied on a printed circuit board (PCB). Optionally, the PCB includes a valve angle indicator 1296 and/or sensors 1298 , for example, for sensing the angle of the valve wings (for example wings of valve 416 ). Controller 1248 optionally includes wireless and/or network communication hardware and/or software and/or a code reader (e.g., barcode and/or OR code), Controller 1248 is optionally programmable for various dispensing programs. FIG. 16 illustrates a dispenser having a large receptacle in accordance with an embodiment of the current invention. In some embodiments, a receptacle 1642 supplying dry goods 1641 to a valve assembly 1601 may extend beyond an adapter 1613 and/or the valve assembly 1601 , for example, the receptacle 1642 may be supported by a base 1699 separate from the valve assembly 1601 . For example, the receptacle may have a large capacity (e.g., between 2 to 5 liters and/or between 10 to 20 liters and/or between 20 to 50 liters. Optionally, the receptacle may include a fiduciary marker 1666 (e.g., to indicate the volume of good 1641 in the receptacle. Optionally, the dispenser may be configured (e.g., via programming of a controller) to receive data on how much goods 1641 are placed into the receptacle and/or how much remains and/or how much is dispensed. Optionally, the dispenser will signal when the receptacle needs to be refilled. Optionally, a receptacle includes an exhibition area 1698 for example, to display the product regardless of how much is left in the receptacle. For example, the exhibition area may an area for storing good 1641 that does not empty to the valve 1601 . FIG. 17 illustrates a front perspective view of a dispenser having a large receptacle in accordance with an embodiment of the current invention. In some embodiments, the receptacle 1642 may include an extended 1743 section that extends outward to the sides beyond the valve assembly 1601 . For example, the bottom of the the extended section 1743 may be inclined towards the valve assembly 1601 for example to funnel the contents of the receptacle 1642 towards the valve assembly 1601 . It is expected that during the life of a patent maturing from this application many relevant technologies will be developed and the scope of the terms is intended to include all such new technologies a priori. As used herein the term “about” refers to ±15% The terms “comprises”, “comprising”, “includes”, “including”, “having” and their conjugates mean “including but not limited to”. The term “consisting of” means “including and limited to”. The term “consisting essentially of” means that the composition, method or structure may include additional ingredients, steps and/or parts, but only if the additional ingredients, steps and/or parts do not materially alter the basic and novel characteristics of the claimed composition, method or structure. As used herein, the singular form “a”, “an” and “the” include plural references unless the context clearly dictates otherwise. For example, the term “a compound” or “at least one compound” may include a plurality of compounds, including mixtures thereof. Throughout this application, various embodiments of this invention may be presented in a range format. It should be understood that the description in range format is merely for convenience and brevity and should not be construed as an inflexible limitation on the scope of the invention. Accordingly, the description of a range should be considered to have specifically disclosed all the possible subranges as well as individual numerical values within that range. For example, description of a range such as from 1 to 6 should be considered to have specifically disclosed subranges such as from 1 to 3, from 1 to 4, from 1 to 5, from 2 to 4, from 2 to 6, from 3 to 6 etc., as well as individual numbers within that range, for example, 1, 2, 3, 4, 5, and 6. This applies regardless of the breadth of the range. Whenever a numerical range is indicated herein, it is meant to include any cited numeral (fractional or integral) within the indicated range. The phrases “ranging/ranges between” a first indicate number and a second indicate number and “ranging/ranges from” a first indicate number “to” a second indicate number are used herein interchangeably and are meant to include the first and second indicated numbers and all the fractional and integral numerals therebetween. When multiple ranges are listed for a single variable, a combination of the ranges is also included (for example the ranges from 1 to 2 and/or from 2 to 4 also includes the combined range from 1 to 4). It is appreciated that certain features of the invention, which are, for clarity, described in the context of separate embodiments, may also be provided in combination in a single embodiment. Conversely, various features of the invention, which are, for brevity, described in the context of a single embodiment, may also be provided separately or in any suitable subcombination or as suitable in any other described embodiment of the invention. Certain features described in the context of various embodiments are not to be considered essential features of those embodiments, unless the embodiment is inoperative without those elements. Although the invention has been described in conjunction with specific embodiments thereof, it is evident that many alternatives, modifications and variations will be apparent to those skilled in the art. Accordingly, it is intended to embrace all such alternatives, modifications and variations that fall within the spirit and broad scope of the appended claims. All publications, patents and patent applications mentioned in this specification are herein incorporated in their entirety by reference into the specification, to the same extent as if each individual publication, patent or patent application was specifically and individually indicated to be incorporated herein by reference. In addition, citation or identification of any reference in this application shall not be construed as an admission that such reference is available as prior art to the present invention. To the extent that section headings are used, they should not be construed as necessarily limiting.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"016-830-529-101-500","jurisdiction":"US","doc_number":"12367476","kind":"B2","date_published":"2025-07-22","doc_key":"US_12367476_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12367476","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"17649376","date":"2022-01-31"},"priority_claims":{},"invention_title":[{"text":"Programmable card for token payment and systems and methods for using programmable card","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"3696","extracted_name":{"value":"Slade E Smith"}}},"applicants":[{"residence":"US","extracted_name":{"value":"Capital One Services, LLC"},"extracted_address":"McLean, VA"}],"inventors":[{"residence":"US","sequence":1,"extracted_name":{"value":"Daniel Tesser"},"extracted_address":"McLean, VA"},{"residence":"US","sequence":2,"extracted_name":{"value":"Luis De La Rosa"},"extracted_address":"Falls Church, VA"},{"residence":"US","sequence":3,"extracted_name":{"value":"Jeffrey Wieker"},"extracted_address":"Fairfax, VA"},{"residence":"US","sequence":4,"extracted_name":{"value":"Clayton Johnson"},"extracted_address":"Edgewood, MD"}],"agents":[{"extracted_name":{"value":"Bookoff McAndrews, PLLC"}}]},"classifications_ipcr":{"classifications":[{"symbol":"G06Q20/32","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G06Q20/20","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/36","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/38","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/40","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"G06Q20/3278","classification_value":"I","classification_symbol_position":"F"},{"symbol":"G06Q20/204","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/322","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/3674","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/3825","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/385","classification_value":"I","classification_symbol_position":"L"},{"symbol":"G06Q20/40","classification_value":"I","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"6705520","kind":"B1","date":"2004-03-01"},"lens_id":"085-352-751-884-250"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"8818867","kind":"B2","date":"2014-08-01"},"lens_id":"015-348-865-308-445"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"9218624","kind":"B2","date":"2015-12-01"},"lens_id":"020-847-204-204-427"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"9275386","kind":"B2","date":"2016-03-01"},"lens_id":"095-215-918-571-988"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"10068217","kind":"B1","date":"2018-09-01"},"lens_id":"146-773-227-023-952"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"10134026","kind":"B1","date":"2018-11-01"},"lens_id":"032-214-380-433-435"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2002/0017568","kind":"A1","date":"2002-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2004/0039694","kind":"A1","date":"2004-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2005/0109841","kind":"A1","date":"2005-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2006/0208066","kind":"A1","date":"2006-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2007/0262138","kind":"A1","date":"2007-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2007/0282740","kind":"A1","date":"2007-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2009/0240594","kind":"A1","date":"2009-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2011/0140841","kind":"A1","date":"2011-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2011/0238579","kind":"A1","date":"2011-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2011/0246317","kind":"A1","date":"2011-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2012/0150669","kind":"A1","date":"2012-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2012/0150687","kind":"A1","date":"2012-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2012/0203700","kind":"A1","date":"2012-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2013/0080276","kind":"A1","date":"2013-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2013/0146661","kind":"A1","date":"2013-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2013/0152185","kind":"A1","date":"2013-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2013/0159178","kind":"A1","date":"2013-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2013/0200146","kind":"A1","date":"2013-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0114780","kind":"A1","date":"2014-04-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0172700","kind":"A1","date":"2014-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0195425","kind":"A1","date":"2014-07-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0291392","kind":"A1","date":"2014-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0365374","kind":"A1","date":"2014-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0073983","kind":"A1","date":"2015-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0073999","kind":"A1","date":"2015-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0134540","kind":"A1","date":"2015-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0170014","kind":"A1","date":"2015-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0206136","kind":"A1","date":"2015-07-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0262164","kind":"A1","date":"2015-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2015/0339663","kind":"A1","date":"2015-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0019449","kind":"A1","date":"2016-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0048833","kind":"A1","date":"2016-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0098708","kind":"A1","date":"2016-04-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0125396","kind":"A1","date":"2016-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0162883","kind":"A1","date":"2016-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0203471","kind":"A1","date":"2016-07-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0253686","kind":"A1","date":"2016-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0292667","kind":"A9","date":"2016-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0314458","kind":"A1","date":"2016-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0321651","kind":"A1","date":"2016-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0350746","kind":"A1","date":"2016-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2016/0379101","kind":"A1","date":"2016-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0046679","kind":"A1","date":"2017-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0061272","kind":"A1","date":"2017-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0249628","kind":"A1","date":"2017-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0300904","kind":"A1","date":"2017-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0364905","kind":"A1","date":"2017-12-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0068293","kind":"A1","date":"2018-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0121925","kind":"A1","date":"2018-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0276935","kind":"A1","date":"2018-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0278619","kind":"A1","date":"2018-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2018/0288166","kind":"A1","date":"2018-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0066078","kind":"A1","date":"2019-02-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0073696","kind":"A1","date":"2019-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0087823","kind":"A1","date":"2019-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0095655","kind":"A1","date":"2019-03-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0139023","kind":"A1","date":"2019-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0156326","kind":"A1","date":"2019-05-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0190717","kind":"A1","date":"2019-06-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0236585","kind":"A1","date":"2019-08-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0318345","kind":"A1","date":"2019-10-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0362334","kind":"A1","date":"2019-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2019/0362341","kind":"A1","date":"2019-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2020/0058024","kind":"A1","date":"2020-02-01"}}}],"patent_count":70},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367476","kind":"B2","date":"2025-07-22"},"lens_id":"016-830-529-101-500"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12367476","kind":"B2","date":"2025-07-22"},"lens_id":"016-830-529-101-500"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"Programmable cards, computer-readable media, and systems are disclosed for token payment. For example, a programmable card for token payment, according to some embodiments, may include an antenna and a contact interface. The card may be configured to store, in the rewritable memory, a token transmitted from a user device via a first near field communication (NFC) signal received by the antenna, and provide the stored token to a point of sales terminal via a second NFC signal transmitted by the antenna or via the contact interface.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. A programmable card for token payment, comprising: a rewritable memory; and a processor configured to: store, in the rewritable memory, a first token transmitted from a user device via a first signal, the first token representing a primary account number of a user of the user device and defining a first usage restriction; when the programmable card is connected to a point of sales terminal and the first token is stored in the rewritable memory, provide the stored first token to the point of sales terminal via a second signal; and overwrite the stored first token in the rewritable memory with a second token transmitted from the user device via a third signal, the second token representing the primary account number of the user of the user device and defining a second usage restriction such that the second token is different than the first token."]},{"claim_text":["2. The programmable card of claim 1 , wherein the first usage restriction includes at least one of: an identity of a merchant at which the first token is usable; a time frame during which the first token is usable; a geographical area in which the first token is usable; or a spending amount limitation."]},{"claim_text":["3. The programmable card of claim 1 , wherein the second usage restriction includes at least one of: an identity of a merchant at which the second token is usable; a time frame during which the second token is usable; a geographical area in which the second token is usable; or a spending amount limitation."]},{"claim_text":["4. The programmable card of claim 1 , wherein the stored first token is encrypted."]},{"claim_text":["5. The programmable card of claim 4 , wherein the processor is further configured to encrypt the first token prior to storing the first token in the rewritable memory."]},{"claim_text":["6. The programmable card of claim 1 , wherein the stored first token is a one-time-use token."]},{"claim_text":["7. The programmable card of claim 1 , wherein the processor is further configured to authenticate the user device prior to storing the first token in the rewritable memory."]},{"claim_text":["8. The programmable card of claim 1 , wherein the processor is further configured to authenticate the point of sales terminal prior to providing the stored first token to the point of sales terminal."]},{"claim_text":["9. The programmable card of claim 1 , wherein the processor is further configured to: delete the stored first token from the rewritable memory."]},{"claim_text":["10. The programmable card of claim 1 , further comprising a chip that includes the rewritable memory and the processor."]},{"claim_text":["11. The programmable card of claim 1 , further comprising one or more communication interfaces communicatively connected to the processor, wherein the processor is further configured to operate at least one of the one or more communication interfaces to receive the first signal and the third signal transmitted by the user device and transmit the second signal to the point of sales terminal, and wherein the one or more communication interfaces include at least one of an antenna or a contact interface."]},{"claim_text":["12. The programmable card of claim 1 , wherein the programmable card does not include a magnetic stripe."]},{"claim_text":["13. A method for token payment, comprising: receiving, by a programmable card, a first token transmitted from a user device via a first signal, the first token representing a primary account number of a user of the user device and defining a first usage restriction; storing the first token in a rewritable memory of the programmable card; when the programmable card is connected to a point of sales terminal and the first token is stored in the rewritable memory, providing the stored first token from the programmable card to the point of sales terminal via a second signal; receiving, by the programmable card, a second token transmitted from the user device via a third signal, the second token representing the primary account number of the user of the user device and defining a second usage restriction such that the second token is different than the first token; and overwriting the stored first token in the rewritable memory of the programmable card with the second token."]},{"claim_text":["14. The method of claim 13 , wherein each of the first usage restriction defined by the first token and the second usage restriction defined by the second token include at least one of: an identity of a merchant at which the respective token is usable; a time frame during which the respective token is usable; a geographical area in which the respective token is usable; or a spending amount limitation."]},{"claim_text":["15. The method of claim 13 , further comprising one of: receiving and storing the first token in an encrypted format in the rewritable memory; or encrypting the first token prior to storing the first token in the rewritable memory."]},{"claim_text":["16. The method of claim 13 , further comprising: establishing the connection of the programmable card to the point of sales terminal via at least one of an antenna of the programmable card or a contact interface of the programmable card."]},{"claim_text":["17. The method of claim 13 , further comprising: receiving one or more of the first signal or the third signal by at least one of an antenna of the programmable card or a contact interface of the programmable card."]},{"claim_text":["18. The method of claim 13 , further comprising: authenticating the user device prior to storing the first token in the rewritable memory."]},{"claim_text":["19. The method of claim 13 , further comprising: authenticating the point of sales terminal prior to providing the stored first token to the point of sales terminal."]},{"claim_text":["20. A programmable card for token payment, comprising: a communication interface; a rewritable memory; and a processor configured to: operate the communication interface to receive a first token transmitted from a user device via a first signal, the first token representing a primary account number of a user of the user device and defining a first usage restriction; store the first token in the rewritable memory; when the programmable card is connected to a point of sales terminal and the first token is stored in the rewritable memory, operate the communication interface to provide the stored first token to the point of sales terminal via a second signal; operate the communication interface to receive a second token transmitted from the user device via a third signal, the second token representing the primary account number of the user of the user device and defining a second usage restriction such that the second token is different than the first token; and overwrite the stored first token in the rewritable memory with the second token."]}],"lang":"en"}],"description":{"text":"CROSS-REFERENCE TO RELATED APPLICATION(S) This patent application is a continuation of and claims the benefit of priority to U.S. Nonprovisional patent application Ser. No. 16/693,460, filed on Nov. 25, 2019, the entirety of which is incorporated herein by reference. TECHNICAL FIELD Various embodiments of the present disclosure relate generally to payment system technologies and, more particularly, to programmable cards with wireless communication capabilities for token payment and methods and systems for using such programmable cards. BACKGROUND A customer may desire the ability to make payments from a credit card account or other financial account in a manner that minimizes the risk of fraudulent usage of the account by unauthorized parties. A token may be used to represent the account of the customer without exposing the account number. Therefore, there is a need for products and techniques that facilitate the usage of tokens, and, more generally, safety in payment making. The present disclosure is directed to addressing one or more of these above-referenced challenges. The background description provided herein is for the purpose of generally presenting the context of the disclosure. Unless otherwise indicated herein, the materials described in this section are not prior art to the claims in this application and are not admitted to be prior art, or suggestions of the prior art, by inclusion in this section. SUMMARY OF THE DISCLOSURE According to certain aspects of the disclosure, a programmable card and non-transitory computer-readable media are disclosed. For example, a programmable card for token payment may include: an antenna; a contact interface; and a chip communicatively connected to the antenna and the contact interface, the chip including a processor and a rewritable memory. The processor may be configured to store, in the rewritable memory, a token transmitted from a user device via a first near field communication (NFC) signal received by the antenna, the token representing a primary account number (PAN) of a user of the user device, when the programmable card is connected to a point of sales terminal via NFC and the token is stored in the rewritable memory, provide the stored token to the point of sales terminal via a second NFC signal transmitted by the antenna, and when the programmable card is connected to the point of sales terminal via the contact interface and the token is stored in the rewritable memory, provide the stored token to the point of sales terminal via the contact interface. Furthermore, a non-transitory computer-readable medium may store instructions that, when executed by one or more processors, cause the one or more processors of a user device to perform operations for configuring a programmable card to perform token payment. The operations may include: connecting to a computer system of a financial services provider; transmitting, to the computer system, a request for a token usable for payment, the token representing a primary account number of a user of the user device; receiving, from the computer system, a response indicative of the token; establishing a near-field communication (NFC) link with the programmable card, the programmable card having an NFC interface and a rewritable memory; and transmitting the token to the programmable card via NFC, so that the token is stored in the rewritable memory of the programmable card and the programmable card is usable for token payment. Furthermore, a non-transitory computer-readable medium may store instructions that, when executed by one or more processors, cause the one or more processors of a user device to perform operations for configuring a programmable card to perform token payment. The operations may include: connecting to a computer system of a financial services provider so as to access an online banking service, the online banking service providing access to manage a payment card account having a primary account number; receiving a user input indicative of a command to request a token usable for payment, the token representing the primary account number; transmitting, to the computer system, a request for the online banking service to provide the token; receiving, from the computer system, a response indicative of the token; establishing a near-field communication (NFC) link with the programmable card, the programmable card having an NFC interface and a rewritable memory; transmitting the token to the programmable card via NFC, so that the token is stored in the rewritable memory of the programmable card and the programmable card is usable for token payment; and displaying a notification indicating that the token has been written onto the programmable card. It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory only and are not restrictive of the disclosed embodiments, as claimed. BRIEF DESCRIPTION OF THE DRAWINGS The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate various exemplary embodiments and together with the description, serve to explain the principles of the disclosed embodiments. FIG. 1 depicts a system environment for a programmable card, according to one or more embodiments. FIGS. 2A-2B respectively depict the front and back of a programmable card, according to one or more embodiments. FIG. 3 depicts a method for using a programmable card, according to one or more embodiments. FIG. 4 depicts a computer system, according to one or more embodiments. DETAILED DESCRIPTION OF EMBODIMENTS The terminology used below may be interpreted in its broadest reasonable manner, even though it is being used in conjunction with a detailed description of certain specific examples of the present disclosure. Indeed, certain terms may even be emphasized below; however, any terminology intended to be interpreted in any restricted manner will be overtly and specifically defined as such in this Detailed Description section. Both the foregoing general description and the following detailed description are exemplary and explanatory only and are not restrictive of the features, as claimed. In this disclosure, the term “based on” means “based at least in part on.” The singular forms “a,” “an,” and “the” include plural referents unless the context dictates otherwise. The term “exemplary” is used in the sense of “example” rather than “ideal.” The terms “comprises,” “comprising,” “includes,” “including,” or other variations thereof, are intended to cover a non-exclusive inclusion such that a process, method, or product that comprises a list of elements does not necessarily include only those elements, but may include other elements not expressly listed or inherent to such a process, method, article, or apparatus. Relative terms, such as, “substantially” and “generally,” are used to indicate a possible variation of ±10% of a stated or understood value. In the following description, embodiments will be described with reference to the accompanying drawings. As will be discussed in more detail below, a mobile device such as a smartphone may receive a token from a remote computer system. The mobile device may then transmit the received token to a programmable card via near-field communication (NFC) so that the token is stored in a memory of the programmable card. To make a payment using the card, the user may bring the card into proximity with a point-of-sales terminal of a merchant, so that the token may be transmitted to the point-of-sales terminal via NFC. The card may have the form of a standard credit card but may have no magnetic stripe. FIG. 1 illustrates a system environment 100 for payment transactions, according to one or more embodiments. The system environment 100 may include a user 102 , an issuer system 110 , a token service provider 112 , a user device 120 operated by the user 102 , a programmable card 130 , a merchant 140 , and an acquirer system 150 . Issuer system 110 , token service provider 112 , and acquirer system 150 may be part of financial services systems 104 . It is noted that these elements of financial services systems 104 do not necessarily need to be separate systems. For example, the issuer system 110 and the acquirer system 150 may be the same system operated by the same bank. Issuer system 110 may be a computer system of an issuer. An issuer may be a financial institution, such as a bank, that maintains a financial account for user 102 . Examples of financial accounts include credit card accounts, checking accounts, and other types of payment accounts. As will be described in greater detail below, user 102 may operate user device 120 to request a token 115 from issuer system 110 , so that token 115 may be stored on programmable card 130 for purposes of making a payment to merchant 140 . The token 115 may represent a primary account number (PAN) of the user 102 's financial account. Accordingly, when used at merchant 140 , the token 115 may serve as a surrogate for the PAN. Token 115 may be a one-time-use token, and may have use restrictions as described below. User device 120 may be any suitable computer system operated by user 102 to perform various functionalities described in this disclosure, including the requesting and receiving of token 115 . Upon receiving token 115 from the issuer system 110 , user device 120 may transmit the token 115 to programmable card 130 for payment use. In some embodiments, user device 120 may be a mobile computing device such as a smartphone, tablet computer, or wearable computing device. However, the present disclosure is not so limited, and it is understood that the user device 120 may be a computing device of any type, including a desktop or laptop computer, that is configured to perform the associated functionalities described in this disclosure. User device 120 may communicate with issuer system 110 through a communication network, such as the Internet. For example, user device 120 may be a smartphone that is capable of accessing the communication network through Wi-Fi or a cellular network. User device 120 may include a memory 122 storing a user device application 124 . User device application 124 may be stored in the form of computer-executable instructions that, when executed by one or more processors of the user device 120 , configures the user device 120 to perform various functionalities described in this disclosure. User device application 124 may be, for example, an online banking application, such as a mobile banking app or a browser-executed web application, that is serviced by issuer system 110 . User device application 124 may enable user 102 to access a financial account of the user 102 that is maintained by the issuer. User device application 124 may additionally enable the user 102 to request a token from issuer system 110 . For example, the user device application 124 may display a graphical user interface by which the user 102 , when logged into the financial account, may specify and submit a token request to the issuer system 110 . The token request may be recognized by issuer system 110 as a request to generate or otherwise obtain a token 115 to be transmitted to user device 120 . The token request may specify restrictions on the usage of the token 115 requested by the user 102 . Such usage restrictions may be include, for example: an identity of a merchant at which the requested token 115 may be used (specified so that the token 115 is not usable at any other merchant); a time frame during which the token 115 is usable (specified so that the token 115 is not usable outside the timeframe); a geographical area in which the token 115 is usable (defining a restriction that the token 115 is not usable at merchant POS terminals outside of the geographical area); and/or a spending amount limitation specifying a maximum spending limit for the token 115 . Such restrictions on the usage of token 115 may be maintained in a database of token service provider 112 or other suitable system. Additionally, as noted above, token 115 may be one-time-use. That is, the token 115 may be deleted from the database of the token service provider 112 , or otherwise rendered unusable, once it has been used. Token 115 may be generated based on the relevant financial account of the user 102 , and may be generated by token service provider 112 . For example, issuer system 110 may provide token service provider 112 with the primary account number (PAN) of the user 102 's financial account. The token service provider 112 may generate the token 115 , and store the token 115 in a database such that the token 115 is associated with the PAN. The token service provider 112 may be a computer system operated by a financial services institution that is different from the issuer operating issuer system 110 , in which case the token service provider 112 may transmit the token 115 to the issuer system 110 when the token 115 has been generated. However, it is also possible for issuer system 110 and the token service provider 112 to be part of the same computer system operated by the same financial services institution. User device 120 may include communication device(s) configured to communicate using communication protocol(s), such as Near-Field Communication (NFC), Universal Serial Bus (USB), Bluetooth, and/or WiFi. In various embodiments, the aforementioned communication device(s) may include a short-range communication device 126 configured to communicate wirelessly using a short-range wireless communication protocol. In some embodiments, short-range communication device 126 may be configured to communicate using NFC, in which case user device 120 may be referred to as an NFC-enabled user device. Short-range communication device 126 may be configured to read and write NFC tags via a signal generated by the short-range communication device 126 . Therefore, short-range communication device 126 may also be referred to as an NFC tag reader and writer. After receiving token 115 from issuer system 110 , user device 120 may transmit token 115 to programmable card 130 using short-range communication device 126 . For example, the user device application 124 may include a functionality enabling the user 102 to input a command indicative of a desire to write token 115 onto the programmable card 130 . The user 102 may, for example, activate the functionality and bring the programmable card 130 near an antenna of the short-range communication device 126 (e.g., by tapping the programmable card 130 on the user device 120 ) to form a communication link between the user device and the programmable card 130 . The user device 120 may then write token 115 onto the programmable card 130 via the communication link. Once token 115 has been written onto programmable card 130 , the token 115 may then be used to make a payment to merchant 140 . To do so, the programmable card 130 may transmit token 115 to a point of sale (POS) device 142 of the merchant 140 . While short-range communication such as NFC is described herein as an example of a method by which user device 120 may communicate with programmable card 130 , the present disclosure is not so limited. In general, user device 120 may communicate with programmable card 130 (e.g., to transmit token 115 to programmable card 130 , and to transmit and/or receive data to perform any other interactions, such as authentication) using any suitable method. For example, user device 120 may interface with programmable card 130 directly through USB in order to transmit token 115 and/or other data to programmable card 130 . In such implementations, programmable card 130 may have a USB port or connector. Additionally or alternatively, user device 120 may communicate with programmable card 130 through a contact interface of the programmable card 130 (e.g., contact interface 138 described below). In such implementations, user device 120 may interface with a card chip reader through a USB port or other interface, wherein the card chip reader may serve as an intermediary between user device 120 and the programmable card 130 . It is noted that the different methods of communication between user device 120 and programmable card 130 described in this disclosure are not intended to be mutually exclusive. That is, user device 120 may be capable of communicating with programmable card 130 through multiple forms of communication. Additionally, the user device 120 and/or programmable card 130 may have any necessary hardware components to implement the communication method(s). For example, the programmable card 130 may have a power source (e.g., a battery), if needed to implement a communication method, and user device 120 may have a USB port or connector, if needed. As shown in FIG. 1 , programmable card 130 may include a memory 133 , a processor 134 , an antenna 136 , and a contact interface 138 . Memory 133 may be a rewritable memory used to store token 115 received from user device 120 . Memory 133 and processor 134 may be part of a chip 132 . Processor 134 may be, for example, a microcontroller, and may be configured to perform payment operations in compliance with a suitable payment standard, such as Eurocard, MasterCard, Visa (EMV). Antenna 136 may be part of a short-range wireless communication interface used for communication (e.g., NFC) between the programmable card 130 and external devices such as the short-range communication device 126 of user device 120 and a contactless smart card reader of POS terminal 142 . In addition to antenna 136 , the short-range wireless communication interface of the programmable card 130 may include any circuitry coupling the antenna 136 and the chip 132 to one another. Antenna 136 may be coupled to a controller (e.g., an NFC controller), which may be processor 134 or be included in processor 134 . The combination of antenna 136 and the controller may be collectively referred to as a tag, such as an NFC tag. Using antenna 136 , programmable card 130 may receive token 115 from user device 120 . In some embodiments, encryption may be performed on the token 115 by the user device 120 and/or processor 134 , so that the token 115 may be stored in memory 133 in an encrypted form. Memory 133 may be rewritable, such that short-range communication device 126 may delete token 115 and/or replace with a different token. For example, the processor 134 may be configured to overwrite the stored token 115 with a second token received from the user device. Since memory 113 may be reprogrammed to carry different information (e.g., different tokens) at different times, programmable card 130 may also be referred to as a reprogrammable card. Contact interface 138 may include a plurality of electrically conductive contact pads that are configured to couple to a card reader of POS terminal 142 when the programmable card 130 is inserted into the card reader. Contact interface 138 and antenna 136 may serve as alternative interfaces of one another for communication with external devices. That is, the programmable card 130 may be capable of receiving data (e.g., token 115 ) through both contact interface 138 and antenna 136 , and may be capable of transmitting data through both contact interface 138 and antenna 136 . It is noted that in various embodiments discussed herein, token 115 is received from user device 120 through antenna 136 . However, it is also possible for the token 115 to be received from contact interface 138 , from a device capable of transmitting token 115 to programmable card 130 in such a manner. Chip 132 may be communicatively connected to both antenna 136 and contact interface 138 . Processor 134 may be configured to operate both antenna 136 and contact interface 138 to receive and/or transmit information. Accordingly, chip 132 may be a dual-interface chip having both contact and contactless interfaces for communication with external devices. FIGS. 2A and 2B illustrate an example of programmable card 130 . FIG. 2A illustrates an example of the front side of the programmable card 130 . FIG. 2B illustrates an example of the back side of the programmable card 130 . Programmable card 130 may have the shape and/or size of a standard credit card. Therefore, programmable card 130 may have dimensions of 85.60×53.98 mm, as specified by the ISO/IEC 7810 ID-1 standard, or substantially such dimensions. Programmable card 130 may have rounded corners. Additionally, the contact pads of the contact interface 138 may be located at a standard position used in chip cards (e.g., a centralized area on a left-hand side as viewed from the front side of the programmable card 130 ). Antenna 136 may be embedded inside programmable card 130 , as shown in FIG. 2B . Antenna 136 may be a conductive coil having any suitable physical form (e.g., a rectangular or circular form), and may have any suitable size and number of turns. Chip 132 may be positioned at any suitable location. In some embodiments, chip 132 may directly underlay contact interface 138 , for purposes of ease of connection with contact interface 138 . Antenna 136 and contact interface 138 may be the only functional payment mechanisms of programmable card 130 for purposes of electronically interfacing with POS terminal 142 . For example, while credits cards in general may include a magnetic stripe used to store data, programmable card 130 according to the present disclosure may include no magnetic stripe. As shown in FIG. 2B , the back side of programmable card 130 does not have a magnetic stripe. While programmable card 130 may display a name and corporate logos, programmable card 130 may have no financial account numbers (e.g., PAN) printed or otherwise visible on any surface of programmable card 130 . In some embodiments, token 115 , stored in memory 133 , may be the only information that is used to conduct payment using programmable card 130 . In such embodiments, no credit card number may be stored in memory 133 . By storing token 115 for payment and omitting a magnetic stripe, programmable card 130 may provide the benefits of safety and security. For example, by substituting for an actual credit card, use of programmable card 130 may avoid loss of the actual credit card. Additionally, due to the token payment system as described above, the effects of a data breach at merchant 140 may be minimized, and unintentional over-spending may be eliminated. User 102 may have the option of using either antenna 136 or contact interface 138 to communicatively couple to POS terminal 142 . For example, the processor 134 may be configured to provide token 115 to POS terminal 142 via an NFC signal transmitted by antenna 136 if the programmable card 130 is connected to POS terminal 142 via NFC, and provide the token 115 to the POS terminal 142 via the contact interface 138 if the programmable card 130 is connected to POS terminal 142 via the contact interface 138 . That is, the processor 134 may transmit the token 115 through the appropriate interface, depending on how the user 102 interfaces the programmable card 130 with the POS terminal 142 . During communication between the programmable card 130 and the POS terminal 142 via antenna 136 or contact interface 138 , the POS terminal 142 may read the token 115 stored in memory 133 . Financial services systems 104 may then process the payment transaction using the token 115 read from programmable card 133 . Programmable card 130 may be configured to perform all processes necessary to comply with transaction processes of a payment standard, such as standards used for EMV payment. For example, the EMV transaction flow may include a “read application data” step in which the chip 132 of the programmable card 130 supplies the POS terminal 142 with an Application File Locator (AFL) indicative of records that the POS terminal 142 is to read from the memory 133 of the programmable card 130 . Such records may include the token 115 . Based on the AFL, the POS terminal 142 may read the token 115 stored in the memory 133 . POS terminal 142 may be any device that receives payment instructions from programmable card 130 . POS terminal 142 may have any suitable structure and configuration for interfacing with programmable card 130 . For example, POS terminal may include hardware configured to receive data through short-range wireless communication (e.g., NFC) and direct contact with a contact interface such as contact interface 138 . POS terminal 142 may communicate with Financial services systems 104 to process the payment. For example, POS terminal 142 may transmit the token 115 to acquirer system 150 , which may communicate with issuer system 110 and/or token service provider 112 to receive authorization to complete the payment. In some embodiments, the processor 134 of programmable card 130 may be configured to delete the token 115 upon providing the stored token 115 to the point of sales terminal 142 . This deletion may be automatically performed by the programmable card 130 , or performed in response to a command from the POS terminal 142 to delete the token 115 . In some embodiments, the programmable card 130 may be configured perform authentication of an external component. For example, the processor 134 of the programmable card 130 may be configured to authenticate the user device 120 prior to storing the token 115 in the memory 133 . The processor 134 may also be further configured to authenticate the POS terminal 142 prior to providing the token 115 to the POS terminal 142 . Authentication may be performed using any suitable method. FIG. 3 is a flowchart illustrating a method for token payment. The method may be performed by a computer system such as user device 120 . In some embodiments, the user device application 124 may provide the user device 120 with the functionality of performing the method of FIG. 3 . For example, the memory 122 of the user device 120 may store user device application 124 in the form of instructions that, when executed by one or more processors of the user device 120 , cause the one or more processors of a user device to perform the method of FIG. 3 . Step 301 may include connecting to a computer system. Such a computer system may be issuer system 110 , or other computer system of a financial services provider, and may provide an online banking service accessible via the user device 120 once the user device 120 is connected to the computer system. The user device 120 may transmit credentials to the issuer system 110 in order to log into the online banking service. Step 302 may include transmitting, to the computer system, a request for a token (e.g., token 115 ) usable for payment. The token 115 may represent a primary account number of a user 102 of the user device 120 . For example, user device 120 may receive a user input, generated as a result of an action performed by user 102 on the user device application, that is indicative of a command to request a token (e.g., token 115 ) usable for payment. The online banking service may provide a service of managing or accessing features of a payment card account with which the aforementioned primary account number is associated. The user 102 , upon having logged into the online banking service, may request the token 115 such that the token 115 represents the primary account number. Step 302 may be performed in response to receiving such a user input. User device 120 may additionally receive a user input indicative of one or more use limitations of the token 115 , such as a spending amount limitation of the token 115 , a merchant to which use of the token 115 is to be to be limited, and/or a time frame during which the token 115 is usable. The request transmitted in step 302 may be indicative of such spending amount limitation. For example, the user device 120 may display a graphical user interface enabling the user 102 to specify one or more use limitations of the token. Once the use limitations have been specified, the user interface may also enable the user 102 to input the aforementioned command to request the token 115 from the issuer system (e.g., issuer system 110 ). Step 303 may include receiving, from the computer system, a response indicative of the token. The response may include the token in any suitable form or format, including encrypted formats, that permits the token to be used for storage on programmable 130 or for payment at POS terminal 142 . Step 304 may include establishing a near-field communication (NFC) link with the programmable card 130 , which may have an NFC interface and a rewritable memory (e.g., memory 133 ). For example, user device 120 may establish an NFC link using short-range communication device 126 . Once the NFC link has been established, user device 120 may receive a user input indicative of a command to transfer the token 115 to programmable card 130 . Prior to the transmitting the token 115 to the programmable card 130 , the user device 120 may authenticate the programmable card 130 through the NFC link. Successful authentication may be, for example, a determination that the programmable card 130 is a suitable article on which the token 115 is to be stored. This determination may be, for example, based on information stored on the programmable card 130 . Step 305 may include transmitting the token 115 to the programmable card 130 via NFC. Accordingly, the token 115 may store in the rewritable memory of the programmable card 130 and the programmable card 130 may be usable for token payment, as described above in connection with the usage of token 115 for payment at POS terminal 142 . The method of FIG. 3 may include additional steps. For example, a further step may include displaying a notification indicating that the token 115 has been written onto the programmable card 130 . The programmable cards, methods and systems described in this disclosure may realize benefits such as safety of not having a credit card number or other financial account number stolen. Even if there is a breach at a merchant, the risk of loss may be minimized by the use of tokens. Additionally, the spending limitations for the tokens stored on the programmable cards, for example, may prevent unintentional over-spending. In general, any method discussed in this disclosure that is understood to be computer-implementable, such as the method described in connection with FIG. 3 , may be performed by one or more processors of a computer system, such as issuer system 110 and user device 120 , as described above. A method or method step performed by one or more processors may also be referred to as an operation. The one or more processors may be configured to perform such processes by having access to instructions (e.g., software or computer-readable code) that, when executed by the one or more processors, cause the one or more processors to perform the processes. The instructions may be stored in a memory of the computer system. A processor may be a central processing unit (CPU), a graphics processing unit (GPU), or another type of processing unit. A computer system, such as user device 120 , issuer system 110 , token service provider 112 , acquirer system 150 , and POS terminal 142 , may include one or more computing devices. If the one or more processors of the computer system is implemented as a plurality of processors, the plurality of processors may be included in a single computing device or distributed among a plurality of computing devices. If a computer system comprises a plurality of computing devices, the memory of the computer system may include the respective memory of each computing device of the plurality of computing devices. FIG. 4 illustrates an example of a computing device 400 of a computer system. The computing device 400 may include processor(s) 410 (e.g., CPU, GPU, or other processing unit), a memory 420 , and communication interface(s) 440 (e.g., a network interface) to communicate with other devices. Memory 420 may include volatile memory, such as RAM, and/or non-volatile memory, such as ROM and storage media. Examples of storage media include solid-state storage media (e.g., solid state drives and/or removable flash memory), optical storage media (e.g., optical discs), and/or magnetic storage media (e.g., hard disk drives). The aforementioned instructions (e.g., software or computer-readable code) may be stored in any volatile and/or non-volatile memory component of memory 420 . The computing device 400 may, in some embodiments, further include input device(s) 450 (e.g., a keyboard, mouse, or touchscreen) and output device(s) 460 (e.g., a display, printer). The aforementioned elements of the computing device 400 may be connected to one another through a bus 430 , which represents one or more busses. Instructions executable by one or more processors may be stored on a non-transitory computer-readable medium. Therefore, whenever a computer-implemented method is described in this disclosure, this disclosure shall also be understood as describing a non-transitory computer-readable medium storing instructions that, when executed by one or more processors, configure and/or cause the one or more processors to perform the computer-implemented method. Examples of non-transitory computer-readable medium include RAM, ROM, solid-state storage media (e.g., solid state drives), optical storage media (e.g., optical discs), and magnetic storage media (e.g., hard disk drives). A non-transitory computer-readable medium may be part of the memory of a computer system or separate from any computer system. It should be appreciated that in the above description of exemplary embodiments, various features are sometimes grouped together in a single embodiment, figure, or description thereof for the purpose of streamlining the disclosure and aiding in the understanding of one or more of the various inventive aspects. This method of disclosure, however, is not to be interpreted as reflecting an intention that the claimed invention requires more features than are expressly recited in each claim. Rather, as the following claims reflect, inventive aspects lie in less than all features of a single foregoing disclosed embodiment. Thus, the claims following the Detailed Description are hereby expressly incorporated into this Detailed Description, with each claim standing on its own as a separate embodiment of this disclosure. Furthermore, while some embodiments described herein include some but not other features included in other embodiments, combinations of features of different embodiments are meant to be within the scope of the disclosure, and form different embodiments, as would be understood by those skilled in the art. For example, in the following claims, any of the claimed embodiments can be used in any combination. Thus, while certain embodiments have been described, those skilled in the art will recognize that other and further modifications may be made thereto without departing from the spirit of the disclosure, and it is intended to claim all such changes and modifications as falling within the scope of the disclosure. For example, functionality may be added or deleted from the block diagrams and operations may be interchanged among functional blocks. Steps may be added or deleted to methods described within the scope of the present disclosure. The above disclosed subject matter is to be considered illustrative, and not restrictive, and the appended claims are intended to cover all such modifications, enhancements, and other implementations, which fall within the true spirit and scope of the present disclosure. Thus, to the maximum extent allowed by law, the scope of the present disclosure is to be determined by the broadest permissible interpretation of the following claims and their equivalents, and shall not be restricted or limited by the foregoing detailed description. While various implementations of the disclosure have been described, it will be apparent to those of ordinary skill in the art that many more implementations and implementations are possible within the scope of the disclosure. Accordingly, the disclosure is not to be restricted.","lang":"en"},"publication_type":"GRANTED_PATENT"}
{"lens_id":"036-949-091-063-207","jurisdiction":"US","doc_number":"12366251","kind":"B2","date_published":"2025-07-22","doc_key":"US_12366251_B2_20250722","lang":"en","biblio":{"publication_reference":{"jurisdiction":"US","doc_number":"12366251","kind":"B2","date":"2025-07-22"},"application_reference":{"jurisdiction":"US","doc_number":"18547340","date":"2022-02-22"},"priority_claims":{"claims":[{"jurisdiction":"SG","doc_number":"10202101753Y","date":"2021-02-22","sequence":1}],"earliest_claim":{"date":"2021-02-22"}},"invention_title":[{"text":"Seals for electric submersible pumps","lang":"en"}],"parties":{"examiners":{"primary_examiner":{"department":"3746","extracted_name":{"value":"Nathan C Zollinger"}},"assistant_examiner":{"extracted_name":{"value":"Chirag Jariwala"}}},"applicants":[{"residence":"US","extracted_name":{"value":"Schlumberger Technology Corporation"},"extracted_address":"Sugar Land, TX"}],"inventors":[{"residence":"SG","sequence":1,"extracted_name":{"value":"Raju Ekambaram"},"extracted_address":"Singapore"},{"residence":"SG","sequence":2,"extracted_name":{"value":"Teng Fei Wang"},"extracted_address":"Singapore"}],"agents":[{"extracted_name":{"value":"Jeffrey D. Frantz"}}]},"classifications_ipcr":{"classifications":[{"symbol":"F04D29/08","classification_value":"I","classification_symbol_position":"F"},{"symbol":"E21B43/12","classification_value":"I","classification_symbol_position":"L"},{"symbol":"F04D13/10","classification_value":"I","classification_symbol_position":"L"},{"symbol":"F04D29/44","classification_value":"I","classification_symbol_position":"L"},{"symbol":"F04D29/54","classification_value":"I","classification_symbol_position":"L"}]},"classifications_cpc":{"classifications":[{"symbol":"F04D29/086","classification_value":"I","classification_symbol_position":"F"},{"symbol":"E21B43/128","classification_value":"I","classification_symbol_position":"L"},{"symbol":"F04D13/10","classification_value":"I","classification_symbol_position":"L"},{"symbol":"F04D29/445","classification_value":"I","classification_symbol_position":"L"},{"symbol":"F04D29/548","classification_value":"I","classification_symbol_position":"L"}]},"references_cited":{"citations":[{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"3851899","kind":"A","date":"1974-12-01"},"lens_id":"013-787-721-327-403"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"6439835","kind":"B1","date":"2002-08-01"},"lens_id":"015-987-252-463-558"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"8043051","kind":"B2","date":"2011-10-01"},"lens_id":"136-229-409-252-21X"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"8944168","kind":"B2","date":"2015-02-01"},"lens_id":"141-934-504-519-108"}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2008/0292454","kind":"A1","date":"2008-11-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2014/0271107","kind":"A1","date":"2014-09-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2017/0102009","kind":"A1","date":"2017-04-01"}}},{"patcit":{"document_id":{"jurisdiction":"US","doc_number":"2023/0012388","kind":"A1","date":"2023-01-01"}}},{"patcit":{"document_id":{"jurisdiction":"JP","doc_number":"07019350","kind":"A","date":"1995-01-01"}}},{"nplcit":{"text":"International Search Report and Written Opinion issued in the PCT Application PCT/US2022/017235, dated Jun. 2, 2022 (12 Pages)."}}],"npl_count":1,"patent_count":9},"cited_by":{}},"families":{"simple_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12366251","kind":"B2","date":"2025-07-22"},"lens_id":"036-949-091-063-207"}],"size":1},"extended_family":{"members":[{"document_id":{"jurisdiction":"US","doc_number":"12366251","kind":"B2","date":"2025-07-22"},"lens_id":"036-949-091-063-207"}],"size":1}},"legal_status":{"patent_status":"UNKNOWN","next_status_change_date":"9999-12-31"},"abstract":[{"text":"Electric submersible pump systems, and more particularly, seals for ESPs, are provided. An electric submersible pump includes a plurality of impellers; a plurality of diffusers; at least one sealing ring positioned axially between two consecutive diffusers of the plurality of diffusers; and at least one O-ring positioned axially between the at least one sealing ring and a lower of the two consecutive diffusers.","lang":"en"}],"claims":[{"claims":[{"claim_text":["1. An electric submersible pump comprising: a plurality of impellers; a plurality of diffusers including a first diffuser and a second diffuser, the second diffuser being lower than the first diffuser in an axial direction; a sealing ring positioned axially between the first diffuser and the second diffuser, the sealing ring including: a first surface disposed on an upper side of the sealing ring, wherein the first surface contacts a lower side of the first diffuser; a second surface disposed on a lower side of the sealing ring, wherein the second surface contacts an upper side of the second diffuser; and a third surface disposed on the lower side of the sealing ring, wherein the third surface is angled with respect to the second surface; and an O-ring positioned axially between the third surface of the sealing ring and the upper side of the second diffuser."]},{"claim_text":["2. The electric submersible pump of claim 1 , wherein the plurality of impellers, the first and second diffusers, the sealing ring, and the O-ring are disposed in a housing of the electric submersible pump."]},{"claim_text":["3. The electric submersible pump of claim 2 , wherein the O-ring is compressed against an inner surface of the housing and the O-ring seals against the inner surface of the housing to reduce stress on the second diffuser."]},{"claim_text":["4. The electric submersible pump of claim 1 , comprising a second sealing ring positioned axially between a third diffuser and a fourth diffuser, the fourth diffuser being lower than the third diffuser in the axial direction, and a second O-ring positioned axially between second sealing ring and the fourth diffuser."]},{"claim_text":["5. The electric submersible pump of claim 1 , wherein the sealing ring comprises a radially inner portion and a radially outer portion."]},{"claim_text":["6. The electric submersible pump of claim 5 , the radially outer portion includes the third surface."]},{"claim_text":["7. A method of assembling an electric submersible pump, the method comprising: positioning a sealing ring axially between a first diffuser and a second diffuser such that a first surface disposed on an upper side of the sealing ring contacts a lower side of the first diffuser, and a gap is formed axially between a second surface disposed on a lower side of the sealing ring and an upper side of the second diffuser; positioning an uncompressed O-ring axially between a third surface of the sealing ring and the second diffuser, wherein the third surface is disposed on the lower side of the sealing ring and is angled with respect to the second surface; sliding the first and second diffusers, the sealing ring, and the uncompressed O-ring into a housing to a desired position; and applying stage compression to close the gap, thereby compressing the uncompressed O-ring to create a seal that prevents or inhibits leakage of fluid."]},{"claim_text":["8. The method of claim 7 , comprising: positioning a second sealing ring axially between a third diffuser and a fourth diffuser, wherein the fourth diffuser is lower than the third diffuser; positioning a second uncompressed O-ring axially between the second sealing ring and the fourth diffuser; and sliding the third and fourth diffusers, the second sealing ring, and the second uncompressed O-ring into the housing to the desired position."]},{"claim_text":["9. A electric submersible pump system comprising: an electric submersible pump comprising: a housing; a plurality of impellers; a plurality of diffusers including a first diffuser and a second diffuser, the second diffuser being lower than the first diffuser in an axial direction; a sealing ring positioned axially between the first diffuser and the second diffuser, the sealing ring including: a first surface disposed on an upper side of the sealing ring, wherein the first surface contacts a lower side of the first diffuser; a second surface disposed on a lower side of the sealing ring, wherein the second surface contacts an upper side of the second diffuser; and a third surface disposed on the lower side of the sealing ring, wherein the third surface is angled with respect to the second surface; an O-ring positioned axially between the third surface of the sealing ring and the upper side of the second diffuser; a shaft extending axially through the electric submersible pump; a protector; and a motor."]},{"claim_text":["10. The system of claim 9 , wherein the O-ring is in an uncompressed state as the plurality of impellers, the first and second diffusers, the sealing ring, and the O-ring are slid into the housing during assembly."]},{"claim_text":["11. The system of claim 10 , wherein the O-ring is compressed against an inner surface of the housing."]},{"claim_text":["12. The system of claim 9 , wherein the sealing ring comprises a radially inner portion and a radially outer portion."]}],"lang":"en"}],"description":{"text":"CROSS-REFERENCE TO RELATED APPLICATIONS Any and all applications for which a foreign or domestic priority claim is identified in the Application Data Sheet as filed with the present application are hereby incorporated by reference under 37 CFR 1.57. The present application is a national stage entry under 35 U.S.C. 371 of International Application No. PCT/US2022/017235, filed Feb. 22, 2022, which claims priority of Singapore Application No. SG 10202101753Y, filed Feb. 22, 2021, the entirety of which is incorporated by reference herein and should be considered part of this specification. BACKGROUND Field The present disclosure generally relates to electric submersible pumps (ESPs), and more particularly to seals for use in ESPs. Description of the Related Art Various types of artificial lift equipment and methods are available, for example, electric submersible pumps (ESPs). An ESP includes multiple centrifugal pump stages mounted in series, each stage including a rotating impeller and a stationary diffuser mounted on a shaft, which is coupled to a motor. In use, the motor rotates the shaft, which in turn rotates the impellers within the diffusers. Well fluid flows into the lowest stage and passes through the first impeller, which centrifuges the fluid radially outward such that the fluid gains energy in the form of velocity. Upon exiting the impeller, the fluid flows into the associated diffuser, where fluid velocity is converted to pressure. As the fluid moves through the pump stages, the fluid incrementally gains pressure until the fluid has sufficient energy to travel to the well surface. SUMMARY In some configurations, an electric submersible pump includes a plurality of impellers; a plurality of diffusers; at least one sealing ring positioned axially between two consecutive diffusers of the plurality of diffusers; and at least one O-ring positioned axially between the at least one sealing ring and a lower of the two consecutive diffusers. The impellers, diffusers, sealing ring, and O-ring can be disposed in a housing of the electric submersible pump. As the impellers, diffusers, sealing ring, and O-ring are slid into the housing during assembly, a gap is formed axially between a portion of the at least one sealing ring and an upward facing surface of the lower of the two consecutive diffusers. Once the impellers, diffusers, sealing ring, and O-ring are positioned at a desired location within the housing, stage compression is applied, thereby closing the gap such that the sealing ring contacts the upward facing surface of the lower of the two consecutive diffusers and the O-ring becomes compressed against an inner surface of the housing. When the O-ring is compressed against the inner surface of the housing, the O-ring seals against the inner surface of the housing to reduce housing-diffuser annular pressure and therefore stress on the diffusers below the seal. The pump can include a plurality of sealing rings, each positioned axially between two consecutive diffusers, and a plurality of O-rings, each positioned axially between an associated sealing ring and the lower of the two consecutive diffusers between which the associated sealing ring is positioned. The sealing ring can have a radially inner portion and a radially outer portion. The O-ring is positioned axially between the radially outer portion and the lower of the two consecutive diffusers. A lower surface of the radially inner portion contacts an upward facing surface of the lower of the two consecutive diffusers in use. A lower edge of the radially outer portion can be angled or inclined. In some configurations, a method of assembling an electric submersible pump includes positioning a sealing ring axially between two diffusers such that a gap is formed axially between the sealing ring and an upward facing surface of a lower diffuser of the two diffusers; positioning an uncompressed O-ring axially between the sealing ring and the lower diffuser of the two diffusers; sliding the diffusers, sealing ring, and O-ring into a housing to a desired position; and applying stage compression to close the gap, thereby compressing the O-ring to create a seal that prevents or inhibits leakage of fluid. The method can include positioning a plurality of sealing rings each axially between two consecutive diffusers of a plurality of diffusers, positioning a plurality of uncompressed O-rings each axially between an associated sealing ring and the lower diffuser of the two consecutive diffusers between which the associated sealing ring is positioned, and sliding the plurality of diffusers, plurality of sealing rings, and plurality of O-rings into the housing to a desired position. In some configurations, an electric submersible pump system includes an electric submersible pump, a shaft extending axially through the pump, a protector, and a motor. The pump includes a housing, a plurality of impellers, a plurality of diffusers, and at least one O-ring positioned axially between two consecutive diffusers of the plurality of diffusers. The system can include at least one sealing ring positioned axially between the two consecutive diffusers of the plurality of diffusers. The at least one O-ring can be positioned axially between the at least one sealing ring and a lower of the two consecutive diffusers. The O-ring can be in an uncompressed state as the impellers, diffusers, sealing ring, and O-ring are slid into the housing during assembly. A gap can be formed axially between a portion of the at least one sealing ring and an upward facing surface of the lower of the two consecutive diffusers during assembly as the impellers, diffusers, sealing ring, and O-ring are slid into the housing during assembly. The sealing ring can contact the upward facing surface of the lower of the two consecutive diffusers and the O-ring can be compressed against an inner surface of the housing when the impellers, diffusers, sealing ring, and O-ring are positioned at a desired location within the housing and stage compression is applied. The sealing ring can have a radially inner portion and a radially outer portion. The O-ring can be positioned axially between the radially outer portion and the lower of the two consecutive diffusers. A lower surface of the radially inner portion can contact an upward facing surface of the lower of the two consecutive diffusers in use. BRIEF DESCRIPTION OF THE FIGURES Certain embodiments, features, aspects, and advantages of the disclosure will hereafter be described with reference to the accompanying drawings, wherein like reference numerals denote like elements. It should be understood that the accompanying figures illustrate the various implementations described herein and are not meant to limit the scope of various technologies described herein. FIG. 1 shows a schematic of an electric submersible pump (ESP) system. FIG. 2 shows a cross-section of a portion of a pump section of the ESP system of FIG. 1 . FIG. 3 shows a partial cross-section of a portion of a pump section of an ESP. FIG. 4 shows a partial cross-section of a portion of a pump section of an ESP including an O-ring according to the present disclosure. FIG. 5 shows a partial cross-section of the portion of the pump of FIG. 4 with the O-ring in a compressed state. DETAILED DESCRIPTION In the following description, numerous details are set forth to provide an understanding of some embodiments of the present disclosure. It is to be understood that the following disclosure provides many different embodiments, or examples, for implementing different features of various embodiments. Specific examples of components and arrangements are described below to simplify the disclosure. These are, of course, merely examples and are not intended to be limiting. However, it will be understood by those of ordinary skill in the art that the system and/or methodology may be practiced without these details and that numerous variations or modifications from the described embodiments are possible. This description is not to be taken in a limiting sense, but rather made merely for the purpose of describing general principles of the implementations. The scope of the described implementations should be ascertained with reference to the issued claims. As used herein, the terms “connect”, “connection”, “connected”, “in connection with”, and “connecting” are used to mean “in direct connection with” or “in connection with via one or more elements”; and the term “set” is used to mean “one element” or “more than one element”. Further, the terms “couple”, “coupling”, “coupled”, “coupled together”, and “coupled with” are used to mean “directly coupled together” or “coupled together via one or more elements”. As used herein, the terms “up” and “down”; “upper” and “lower”; “top” and “bottom”; and other like terms indicating relative positions to a given point or element are utilized to more clearly describe some elements. Commonly, these terms relate to a reference point at the surface from which drilling operations are initiated as being the top point and the total depth being the lowest point, wherein the well (e.g., wellbore, borehole) is vertical, horizontal or slanted relative to the surface. Various types of artificial lift equipment and methods are available, for example, electric submersible pumps (ESP). As shown in the example embodiment of FIG. 1 , an ESP 110 typically includes a motor 116 , a protector 115 , a pump 112 , a pump intake 114 , and one or more cables 111 , which can include an electric power cable. The motor 116 can be powered and controlled by a surface power supply and controller, respectively, via the cables 111 . In some configurations, the ESP 110 also includes gas handling features 113 and/or one or more sensors 117 (e.g., for temperature, pressure, current leakage, vibration, etc.). As shown, the well 103 may include one or more well sensors 120 . The pump 112 includes multiple centrifugal pump stages mounted in series within a housing 230 , as shown in FIG. 2 . Each stage includes a rotating impeller 210 and a stationary diffuser 220 . One or more spacers 204 can be disposed axially between sequential impellers 210 . A shaft 202 extends through the pump 112 (e.g., through central hubs or bores or the impellers 210 and diffusers 220 ) and is operatively coupled to the motor 116 . The shaft 202 can be coupled to the protector 115 (e.g., a shaft of the protector), which in turn can be coupled to the motor 116 (e.g., a shaft of the motor). The impellers 210 are rotationally coupled, e.g., keyed, to the shaft 202 . The diffusers 220 are coupled, e.g., rotationally fixed, to the housing 230 . In use, the motor 116 causes rotation of the shaft 202 (for example, by rotating the protector 115 shaft, which rotates the pump shaft 202 ), which in turn rotates the impellers 210 relative to and within the stationary diffusers 220 . In use, well fluid flows into the first (lowest) stage of the ESP 110 and passes through an impeller 210 , which centrifuges the fluid radially outward such that the fluid gains energy in the form of velocity. Upon exiting the impeller 210 , the fluid makes a sharp turn to enter a diffuser 220 , where the fluid's velocity is converted to pressure. The fluid then enters the next impeller 210 and diffuser 220 stage to repeat the process. As the fluid passes through the pump stages, the fluid incrementally gains pressure until the fluid has sufficient energy to travel to the well surface. As shown in FIG. 2 , a bearing assembly can be disposed between, e.g., at least partially radially between, the shaft 202 and a diffuser 220 and/or between, e.g., at least partially axially between, an impeller 210 and its associated diffuser 220 . A portion of the diffuser 220 can act as a bearing housing 260 . In the illustrated embodiment, the bearing assembly includes a bearing sleeve 252 disposed about the shaft 202 and a bushing 254 disposed about the bearing sleeve 252 and radially between the bearing sleeve 252 and a portion of the diffuser 220 . One or more o-rings 258 can be disposed about the bushing 254 , for example, radially between the bushing 254 and the diffuser 220 or bearing housing 260 . The illustrated bearing assembly also includes an anti-rotation upthrust ring 256 disposed about the bearing sleeve 252 . As shown, the anti-rotation upthrust ring 256 can be disposed adjacent an upstream end of the bushing 254 . The bearing sleeve 252 is keyed or rotationally coupled to the shaft 202 such that the bearing sleeve 252 rotates with the shaft 202 in use. The anti-rotation upthrust ring 256 prevents or inhibits the bushing 254 from rotating such that the bushing 254 is stationary or rotationally fixed relative to the diffuser 220 . The anti-rotation upthrust ring 256 can also help prevent or inhibit axial movement of the bushing 254 and/or the bushing 254 from dropping out of place from the bearing housing 260 . In use, the bearing assembly can help absorb thrust and/or accommodate the rotation of the shaft relative to the diffuser. The pump 112 can also include one or more thrust assemblies, for example, upthrust assemblies and/or downthrust assemblies, disposed axially between portions of and/or operatively connecting an impeller 210 and its associated diffuser 220 . A thrust assembly can include a thrust washer and a thrust pad, which may be a portion of the impeller 210 or diffuser 220 . In the configuration of FIG. 2 , an upthrust washer 270 is disposed on, adjacent, or proximate an upper surface, or upwardly facing surface, of the impeller 210 . In the illustrated configuration, the upthrust washer 270 is positioned adjacent a central hub 214 or portion of the impeller 210 having a bore through which the shaft 202 extends and radially between the hub 214 and a balance ring 212 of the impeller 210 . In use, the illustrated upthrust washer 270 contacts the anti-rotation upthrust ring 256 when the pump 112 is operating in an upthrust condition, for example, during HPTS testing at a wide open condition, improper or over shimming at a well site, and/or operating beyond maximum operating range in the field. In some configurations, the pump 112 also includes one or more downthrust assemblies. In the configuration of FIG. 2 , a downthrust washer 280 is disposed on or adjacent a lower, or downwardly facing surface, of the impeller 210 , and is disposed axially between a portion of the impeller 210 and a portion of an adjacent diffuser 220 . In a typical downhole pump, the maximum number of stages within a section of the pump is typically limited because the first, or lowest, set of diffusers at the pump inlet 114 are not able to withstand the combined axial thrust and radial pressure loads generated by the stages stacked on top of them. Therefore, multiple short sections must be used instead of a single long section pump, which can increase the cost per foot of lift. To address this lower diffuser collapse issue, O-ring seals 290 are often used to seal the annular region between the OD of the diffuser 220 and the ID of the housing 230 , for example as shown in FIG. 3 . The O-ring seals 290 prevent or inhibit high pressure fluid from the top section of the pump migrating to the lower section of the pump, thereby reducing the stress induced within the lower diffuser. However, pumps including O-ring seals 290 can be difficult to manufacture. During assembly, the O-ring 290 is installed on the OD of the diffuser 220 . Then the diffuser 220 and O-ring 290 in a compressed state are pushed through the threads at the end of the housing 230 and must travel through the ID of the housing 230 until the diffuser 220 reaches its desired position within the pump housing 230 . In some cases, the diffuser 220 and O-ring 290 must travel a distance in the range of 10-20 feet to reach the desired position. To properly function as a seal, the O-ring 290 must be squeezed against the ID of the housing 230 . The O-ring 290 can therefore be damaged by sharp threads on the housing 230 or rubbed and/or extruded against the ID of the housing 230 during assembly. Assembly can become more complicated and/or have a higher likelihood of damage to the O-rings 290 if multiple stages include O-rings 290 . The process of pushing multiple sets of compressed O-rings 290 through long sections of the housing 230 can generate significant friction force, making the manual assembly operation difficult. The present disclosure provides a crush type seal design and an independent sealing ring stacking along with the pump stages, for example as shown in FIG. 5 . With designs according to the present disclosure, it is advantageously not necessary for O-rings to be squeezed or compressed prior to pushing the stages within the pump housing 230 . Instead, the seals are activated once set in their desired locations when the stages are compressed. FIG. 4 shows a portion of a pump according to the present disclosure. As shown, a sealing ring 215 is disposed axially between adjacent or sequential diffusers 220 and adjacent and/or in contact with the ID of the housing 230 . In some configurations, the sealing ring 215 has a radially inner portion 215 a and a radially outer portion 215 b . The radially inner portion 215 a has a lower surface 218 . The radially outer portion 215 b has a flat upper edge or surface 216 (in other words, edge 216 extends perpendicularly to the longitudinal axis of the pump) and an angled or inclined lower edge or surface 217 . The lower edge 217 can be angled such that a radially inner corner or side of the radially outer portion 215 b extends lower, or further upstream, than a radially outer corner or side of the radially outer portion 215 b. An O-ring 295 is positioned axially between the sealing ring 215 and the adjacent or next lower diffuser 220 . In the illustrated configuration, the O-ring 295 is positioned axially between the lower edge 217 and an upward facing surface or top face 222 of the adjacent or next lower diffuser 220 . In some configurations, a pump includes a plurality of sealing rings 215 , each positioned axially between a pair of consecutive diffusers, and a plurality of O-rings 295 , each positioned axially between one of the sealing rings 215 and the next lower adjacent or consecutive diffuser 220 . In an initial, uncompressed state, the O-ring 295 is uncompressed, and a gap 213 is formed between the lower surface 218 of the radially inner portion 215 a of the sealing ring 215 and an upward facing surface 224 of the adjacent, next lower diffuser 220 . During assembly, there may be a relatively small amount of friction generated due to the axial force of pushing the stage stack into the housing 230 . However, the O-ring 295 remains generally or mostly free from any compression or squeeze, and any friction generated is considerably lower than the friction force generated during assembly of pumps such as shown in FIG. 3 . Once the diffuser 220 and sealing ring 215 are pushed into the correct or desired position within the housing 230 , stage compression is applied. Stage compression can bring surface 218 into contact with surface 224 , closing the gap 213 , as shown in FIG. 5 . Stage compression also compresses the O-ring 295 , as also shown in FIG. 5 . As the O-ring 295 has a constant volume, the outer diameter of the O-ring 295 will expand or morph until the O-ring 295 OD squeezes against the ID of the housing 230 , the diffuser top face 222 , and the sealing ring 215 lower edge or inclined bottom face 217 . The O-ring 295 sealing against the inner surface of the housing 230 prevents or inhibits pressure from above the seal from leaking below the seal through the diffuser-housing annulus. This sealing and pressure leak inhibition will eventually reduce radial pressure and/or stress on the diffusers below the seal location. With the design of FIGS. 4-5 , it is advantageously easier to manually push the diffuser stack with the O-rings 295 into the housing 230 as there is no, or reduced, friction force due to the O-rings 295 not being squeezed or compressed against the housing ID while pushing into the housing 230 . The lack of or reduced friction due to absence of O-ring compression/squeeze reduces the likelihood of damage to the O-rings 295 . The O-rings 295 are also less likely to be damaged by threads on the housing 230 , even if the minor thread diameter is the same as or close to the housing inner diameter, as the O-rings 295 are not squeezed against the housing ID during assembly prior to compression. Designs according to the present disclosure also advantageously allow for the use of larger cross-section O-rings, thereby improving the sealing reliability. Designs according to the present disclosure can advantageously allow for longer section pumps, which can in turn generate higher lift and help decrease the cost per foot of lift. Language of degree used herein, such as the terms “approximately,” “about,” “generally,” and “substantially” as used herein represent a value, amount, or characteristic close to the stated value, amount, or characteristic that still performs a desired function or achieves a desired result. For example, the terms “approximately,” “about,” “generally,” and “substantially” may refer to an amount that is within less than 10% of, within less than 5% of, within less than 1% of, within less than 0.1% of, and/or within less than 0.01% of the stated amount. As another example, in certain embodiments, the terms “generally parallel” and “substantially parallel” or “generally perpendicular” and “substantially perpendicular” refer to a value, amount, or characteristic that departs from exactly parallel or perpendicular, respectively, by less than or equal to 15 degrees, 10 degrees, 5 degrees, 3 degrees, 1 degree, or 0.1 degree. Although a few embodiments of the disclosure have been described in detail above, those of ordinary skill in the art will readily appreciate that many modifications are possible without materially departing from the teachings of this disclosure. Accordingly, such modifications are intended to be included within the scope of this disclosure as defined in the claims. It is also contemplated that various combinations or sub-combinations of the specific features and aspects of the embodiments described may be made and still fall within the scope of the disclosure. It should be understood that various features and aspects of the disclosed embodiments can be combined with, or substituted for, one another in order to form varying modes of the embodiments of the disclosure. Thus, it is intended that the scope of the disclosure herein should not be limited by the particular embodiments described above.","lang":"en"},"publication_type":"GRANTED_PATENT"}